{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0219d472",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a098050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ped\n",
      "1\n",
      "Number of car\n",
      "2\n",
      "Number of lines\n",
      "2\n",
      "Load model for continuous part?(input number)\n",
      "0\n",
      "Load model for discrete part?(input number)\n",
      "0\n",
      "Number steps\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "#1) Import libraries\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple, deque\n",
    "import Environments\n",
    "from collections import OrderedDict\n",
    "from torch.distributions import MultivariateNormal, Categorical, Binomial\n",
    "from torch.nn import Softmax\n",
    "#import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "# I use the work of Eric Yu to help me build this algorithm. Link: https://github.com/ericyangyu/PPO-for-Beginners\n",
    "#https://github.com/nikhilbarhate99/PPO-PyTorch/blob/master/PPO.py\n",
    "\n",
    "#2) Set up Neural Network functions and classes\n",
    "\n",
    "class Model_SD(nn.Module):\n",
    "    \"\"\"\n",
    "        Class: scenario distribution\n",
    "        :param noise: random value (size state)\n",
    "        :param nb_outputs: size output of the NN (size action)\n",
    "    \"\"\"  \n",
    "    def __init__(self, noise, nb_outputs, nb_car, nb_ped):\n",
    "        super(Model_SD, self).__init__()\n",
    "        self.layer1 = nn.Linear(noise, 16)\n",
    "        self.layer2 = nn.Linear(16, 32)\n",
    "        self.layer3 = nn.Linear(32, 64)\n",
    "        self.layer4 = nn.Linear(64, nb_outputs)\n",
    "        self.bornes=[]\n",
    "        for i in range(nb_ped):\n",
    "            self.bornes.append([-0.05,0.05])\n",
    "            self.bornes.append([0.75,1.75])\n",
    "            self.bornes.append([0.,4.])\n",
    "            self.bornes.append([-3.,-0.5])\n",
    "            self.bornes.append([-1.,1.])\n",
    "        for i in range(nb_car):\n",
    "            self.bornes.append([-50.,-10.])\n",
    "        self.bornes.append([2.5,3.5])\n",
    "        #self.bornes=[[-0.05,0.05],[0.75,1.75],[0.,4.],[-3.,-0.5],[-1,1],[-50.,-10.],[2.5,3.5]]#,[0.05,1.75,4.,-0.5,1,-10.,3.5]] \n",
    "        self.std=torch.tensor([(b[1]-b[0])/2 for b in self.bornes])\n",
    "        self.mean=torch.tensor([(b[0]+b[1])/2 for b in self.bornes])\n",
    "        self.return_layer=nn.Tanh()\n",
    "        # ped speed x y , ped pos x y , direction , poscar , env_size\n",
    "        \n",
    "    def forward(self, input1):\n",
    "        \"\"\"\n",
    "        Forward NN : compute the NN with respect the current state\n",
    "        :param input1: state\n",
    "        :return: output of the NN, action\n",
    "        \"\"\" \n",
    "        if isinstance(input1, np.ndarray):\n",
    "            input1 = torch.tensor(input1, dtype=torch.float)\n",
    "        activation1 = F.relu(self.layer1(input1))\n",
    "        activation2 = F.relu(self.layer2(activation1))\n",
    "        activation3 = F.relu(self.layer3(activation2))\n",
    "        output = self.layer4(activation3)\n",
    "        output=torch.add(torch.mul(self.return_layer(output), self.std),self.mean)\n",
    "        #output[4]=1.*(output[4]>=0)-1.*(output[4]<0)\n",
    "        #output[3]=output[3]+output[4]*output[6]\n",
    "        return output\n",
    "\n",
    "class Model_PPO(nn.Module):\n",
    "    \"\"\"\n",
    "        Class: actor NN\n",
    "        :param np_inputs: size input of the NN (size state)\n",
    "        :param nb_outputs: size output of the NN (size action)\n",
    "    \"\"\"  \n",
    "    def __init__(self, np_inputs, nb_outputs, model_type=0, nb_car=1, mean=0, std=1):\n",
    "        super(Model_PPO, self).__init__()\n",
    "        self.model_type=model_type\n",
    "        self.nb_car=nb_car\n",
    "        self.mean=mean\n",
    "        self.std=std\n",
    "        self.layer1 = nn.Linear(np_inputs, 32)\n",
    "        self.layer2 = nn.Linear(32, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, nb_outputs)\n",
    "        if(self.model_type==2):\n",
    "            self.layer4 = nn.Linear(32, nb_outputs)\n",
    "            #self.layers_d = [nn.Linear(32, nb_outputs) for i in range(self.nb_car)]\n",
    "            self.return_layer=Softmax(dim=-1)\n",
    "        if(self.model_type==1):\n",
    "            self.layer4 = nn.Linear(32, nb_outputs)\n",
    "            self.return_layer=nn.Tanh()\n",
    "        else: #self.model_type==0\n",
    "            pass\n",
    "        #torch.nn.init.uniform_(self.layer4.weight,0.003, 0.006)\n",
    "        torch.nn.init.orthogonal_(self.layer4.weight)\n",
    "\n",
    "    def forward(self, input1):\n",
    "        \"\"\"\n",
    "        Forward NN : compute the NN with respect the current state\n",
    "        :param input1: state\n",
    "        :r(eturn: output of the NN, action\n",
    "        \"\"\" \n",
    "        if isinstance(input1, np.ndarray):\n",
    "            input1 = torch.tensor(input1, dtype=torch.float)\n",
    "        activation1 = F.relu(self.layer1(input1))\n",
    "        activation2 = F.relu(self.layer2(activation1))\n",
    "        activation3 = F.relu(self.layer3(activation2))\n",
    "        if(self.model_type==2):\n",
    "            output_d = self.layer4(activation3)\n",
    "            output_d=output_d.reshape(-1,2)\n",
    "            output_d=self.return_layer(output_d)\n",
    "            output=torch.flatten(output_d)\n",
    "                #output_f=torch.tensor([])\n",
    "                #for layer in self.layers_d:\n",
    "                    #output_d=layer(activation4)\n",
    "                    #output_d=output_d.reshape(-1,2)\n",
    "                    #output_d=self.return_layer(output_d)\n",
    "                #output_f=torch.cat((output_f,output_d), 0)\n",
    "        elif(self.model_type==1):\n",
    "            output = self.layer4(activation3)\n",
    "            output=torch.add(torch.mul(self.return_layer(output), self.std),self.mean)\n",
    "            #output_f=torch.tensor([])\n",
    "            #for layer4 in self.layer_list:\n",
    "            #    output = layer4(activation3)\n",
    "            #    output=torch.add(torch.mul(self.return_layer(output), self.std),self.mean)\n",
    "            #    output_f=torch.cat((output_f,output), 0)\n",
    "            #output=torch.flatten(output_f)\n",
    "        else:#self.model_type==0\n",
    "            output = self.layer4(activation3)\n",
    "        return output\n",
    "\n",
    "#3) Rollout on the environment:\n",
    "from collections import deque\n",
    "class Env_rollout:\n",
    "    \"\"\" \n",
    "        Class : iterate on the environment\n",
    "        :param env: our environment\n",
    "        :param max_steps: max steps per episode\n",
    "    \"\"\"\n",
    "    def __init__(self, env, nb_cars, max_steps, dt):\n",
    "        self.env = env\n",
    "        self.nb_cars=nb_cars\n",
    "        self.dt=dt\n",
    "        self.max_steps = max_steps\n",
    "        self.prev_state, _ = env.reset()\n",
    "        self.shape_env=2+9+2\n",
    "        #int(self.prev_state['car'].shape[0]/env.nb_car)+int(self.prev_state['ped'].shape[0]/env.nb_ped)+(self.prev_state['env'].shape[0])\n",
    "        self.shape_env_d=2+(5*(nb_cars-1))+8+2\n",
    "        #6+5*env.nb_ped#int(self.prev_state['car'].shape[0]/env.nb_car)+int(self.prev_state['ped'].shape[0])+(self.prev_state['env'].shape[0])\n",
    "        self.batch_obs_choice=[]\n",
    "        self.batch_obs_cross=[]\n",
    "        self.batch_obs_wait=[]\n",
    "        self.batch_obs_distrib=[]\n",
    "        self.batch_acts_choice=[] # changer par shape(-1,2)\n",
    "        self.batch_acts_cross=[]\n",
    "        self.batch_acts_wait=[]\n",
    "        self.batch_acts_distrib=[]\n",
    "        self.batch_log_probs_choice=[]\n",
    "        self.batch_log_probs_cross=[]\n",
    "        self.batch_log_probs_wait=[]\n",
    "        self.batch_rews_choice = []\n",
    "        self.batch_rews_cross = []\n",
    "        self.batch_rews_wait = []\n",
    "        self.return_softmax=Softmax(dim=-1)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset: reinitilization (lists et environment).\n",
    "        \"\"\"\n",
    "        self.prev_state, _ = env.reset()\n",
    "        self.batch_obs_choice=[]\n",
    "        self.batch_obs_cross=[]\n",
    "        self.batch_obs_wait=[]\n",
    "        self.batch_obs_distrib=[]\n",
    "        self.batch_acts_choice=[]\n",
    "        self.batch_acts_cross=[]\n",
    "        self.batch_acts_wait=[]\n",
    "        self.batch_acts_distrib=[]\n",
    "        self.batch_log_probs_choice=[]\n",
    "        self.batch_log_probs_cross=[]\n",
    "        self.batch_log_probs_wait=[]\n",
    "        self.batch_rews_choice = []\n",
    "        self.batch_rews_cross = []\n",
    "        self.batch_rews_wait = []\n",
    "    \n",
    "    def reward_choice(self, reward_light):\n",
    "        \"\"\"\n",
    "        Reward of the discrete NN\n",
    "        \"\"\"\n",
    "        return reward_light\n",
    "\n",
    "    def iterations(self, actor_net_cross, actor_net_wait, actor_net_choice, actor_distrib, nbr_episodes, select_param=False):\n",
    "        \"\"\"\n",
    "        Iterate on the environment.\n",
    "        :param actor_net: current policy (actor NN)\n",
    "        :param nbr_episodes: episode number\n",
    "        :return: Tensors; state batch, action batch\n",
    "        \"\"\"\n",
    "        batch_obs=[]\n",
    "        batch_acts=[]\n",
    "        batch_rews_d=[]\n",
    "        batch_rews_c=[]\n",
    "        batch_waiting_time=[]\n",
    "        self.discount_array = [0.7,0.3]\n",
    "        action_d=np.array([0] *self.env.nb_car* self.env.nb_ped)\n",
    "        action_d_light=np.array([0] *self.env.nb_car)\n",
    "        #prev_action_c=np.array([0.]*self.nb_cars)\n",
    "        for ep in range(nbr_episodes):\n",
    "            need_new_d=True\n",
    "            save_batch=False\n",
    "            state,_ = self.env.reset()\n",
    "            #if(select_param):\n",
    "            #    parameters_state = torch.squeeze(actor_distrib(torch.rand(1)).float())\n",
    "            #    self.env.reset_distrib(parameters_state)\n",
    "            state = self.env.get_state()\n",
    "            prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "            nb_ped=state[\"env\"][1]\n",
    "            for step_ep in range(self.max_steps): \n",
    "\n",
    "                if(need_new_d):\n",
    "                    ep_rews = []\n",
    "                    episodic_reward = np.array([0.]*self.nb_cars)\n",
    "                    action_all_d=np.array([])\n",
    "                    action_all_d_light=np.array([])\n",
    "                    for i in range(self.nb_cars):\n",
    "                        for j in range(self.env.nb_ped):\n",
    "                            new_prev_state = self.obs_car_ped_d(prev_state,i,j)\n",
    "                            parameters_based = torch.squeeze(actor_net_choice(torch.unsqueeze(torch.tensor(new_prev_state),\n",
    "                                                                                              dim=0).float()))\n",
    "                            parameters_based=torch.squeeze(parameters_based)\n",
    "                            parameters_based=parameters_based.reshape(-1,2)\n",
    "                            action_d2 = torch.argmax(self.return_softmax(parameters_based),axis=1)\n",
    "                            action_all_d = np.append(action_all_d, action_d2.detach().numpy())\n",
    "                        action_all_d_light=np.append(action_all_d_light,action_all_d[i*self.env.nb_ped+self.closest_ped_d(prev_state,i)])\n",
    "\n",
    "                action_d=(2*action_all_d-1)\n",
    "                action_d_light=(2*action_all_d-1)\n",
    "                need_new_d=False\n",
    "                action_all_c=np.array([])\n",
    "                with torch.no_grad():\n",
    "                    for i in range(self.nb_cars):\n",
    "                        action_c_numpy=np.array(self.env.car_b[1,0])\n",
    "                        for p in range(self.env.nb_ped):\n",
    "                            new_prev_state=self.obs_car_ped(prev_state,i,p)\n",
    "                            if(new_prev_state[7]):\n",
    "                                new_action_c=torch.tensor(max(min((self.env.speed_limit-new_prev_state[0])/self.env.dt,self.env.car_b[1,0]),self.env.car_b[0,0]))\n",
    "                            else:\n",
    "                                if(action_d[i*self.env.nb_ped+p]<=0):\n",
    "                                    new_action_c = torch.squeeze(actor_net_cross(torch.unsqueeze(torch.tensor(new_prev_state), dim=0).float()))\n",
    "                                else:\n",
    "                                    new_action_c = torch.squeeze(actor_net_wait(torch.unsqueeze(torch.tensor(new_prev_state), dim=0).float()))\n",
    "                            if(new_action_c.dim()==0):\n",
    "                                new_action_c=torch.unsqueeze(new_action_c,dim=0)\n",
    "                            action_c_numpy=min(action_c_numpy,new_action_c.detach().numpy())\n",
    "                            action_c_numpy=min(action_c_numpy,(10.0-new_prev_state[0])/(self.dt))\n",
    "                            #action_c_numpy=action_c_numpy_new*self.discount_array[0]+prev_action_c[i]*self.discount_array[1]\n",
    "                        action_all_c=np.append(action_all_c, action_c_numpy)\n",
    "                        #prev_action_c=action_all_c\n",
    "                    action_all=np.append(action_all_c, action_d_light)\n",
    "                    \n",
    "                    state, reward, done, trunc, _ = self.env.step(action_all)\n",
    "                    batch_obs.append(prev_state)\n",
    "                    batch_acts.append(action_all_c) #2 actions\n",
    "                    episodic_reward = np.minimum(episodic_reward,self.env.reward_light)\n",
    "                    ep_rews.append(reward)\n",
    "                    if(state[\"env\"][1]!=nb_ped):\n",
    "                        need_new_d=True\n",
    "                        save_batch=True\n",
    "                    prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "                    nb_ped=state[\"env\"][1]\n",
    "                \n",
    "                if(save_batch or done):\n",
    "                    for ped in self.env.pedestrian:\n",
    "                        batch_waiting_time.append(ped.waiting_time)\n",
    "                    batch_rews_c.append(ep_rews)\n",
    "                    batch_rews_d.append(episodic_reward)\n",
    "                save_batch=False\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "        batch_rews_c_final=[]\n",
    "        for ep_rews in reversed(batch_rews_c):\n",
    "            for rew in reversed(ep_rews):\n",
    "                batch_rews_c_final.insert(0,rew)\n",
    "        t_batch_obs=torch.tensor(np.array(batch_obs), dtype=torch.float)\n",
    "        t_batch_acts=torch.tensor(np.array(batch_acts), dtype=torch.float)\n",
    "        t_batch_rews_c=torch.tensor(batch_rews_c_final, dtype=torch.float)\n",
    "        t_batch_rews_d=torch.tensor(batch_rews_d, dtype=torch.float)\n",
    "        t_batch_waiting_time=torch.tensor(batch_waiting_time, dtype=torch.float)\n",
    "        return t_batch_obs, t_batch_acts, t_batch_rews_c, t_batch_rews_d, t_batch_waiting_time\n",
    "\n",
    "    \n",
    "    def iterations_dataset(self, actor_net_cross, actor_net_wait, actor_net_choice, nbr_episodes):\n",
    "        \"\"\"\n",
    "        Iterate on the environment.\n",
    "        :param actor_net: current policy (actor NN)\n",
    "        :param nbr_episodes: episode number\n",
    "        :return: Tensors; state batch, action batch\n",
    "        \"\"\"\n",
    "        batch_obs=[]\n",
    "        batch_acts=[]\n",
    "        batch_acts_d=[]\n",
    "        batch_rews_d=[]\n",
    "        batch_rews_c=[]\n",
    "        batch_waiting_time=[]\n",
    "        self.discount_array = [0.7,0.3]\n",
    "        action_d=np.array([0] *self.env.nb_car* self.env.nb_ped)\n",
    "        action_d_light=np.array([0] *self.env.nb_car)\n",
    "        #prev_action_c=np.array([0.]*self.nb_cars)\n",
    "        file = open(\"test_data_acc6.pickle\",'rb')\n",
    "        env_dataset = pickle.load(file)\n",
    "        for ep in range(nbr_episodes):\n",
    "            need_new_d=True\n",
    "            save_batch=False\n",
    "            self.env=env_dataset[ep]\n",
    "            state = self.env.get_state()#state,_ = self.env.reset()\n",
    "            prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "            nb_ped=state[\"env\"][1]\n",
    "            for step_ep in range(self.max_steps): \n",
    "\n",
    "                if(need_new_d):\n",
    "                    ep_rews = []\n",
    "                    episodic_reward = np.array([0.]*self.nb_cars)\n",
    "                    action_all_d=np.array([])\n",
    "                    action_all_d_light=np.array([])\n",
    "                    for i in range(self.nb_cars):\n",
    "                        for j in range(self.env.nb_ped):\n",
    "                            new_prev_state = self.obs_car_ped_d(prev_state,i,j)\n",
    "                            parameters_based = torch.squeeze(actor_net_choice(torch.unsqueeze(torch.tensor(new_prev_state),\n",
    "                                                                                              dim=0).float()))\n",
    "                            parameters_based=torch.squeeze(parameters_based)\n",
    "                            parameters_based=parameters_based.reshape(-1,2)\n",
    "                            action_d2 = torch.argmax(self.return_softmax(parameters_based),axis=1)\n",
    "                            action_all_d = np.append(action_all_d, action_d2.detach().numpy())\n",
    "                        action_all_d_light=np.append(action_all_d_light,action_all_d[i*self.env.nb_ped+self.closest_ped_d(prev_state,i)])\n",
    "                action_d=(2*action_all_d-1)\n",
    "                action_d_light=(2*action_all_d_light-1)\n",
    "                need_new_d=False\n",
    "                action_all_c=np.array([])\n",
    "                with torch.no_grad():\n",
    "                    for i in range(self.nb_cars):\n",
    "                        action_c_numpy=np.array(self.env.car_b[1,0])\n",
    "                        for p in range(self.env.nb_ped):\n",
    "                            new_prev_state=self.obs_car_ped(prev_state,i,p)\n",
    "                            if(action_d[i*self.env.nb_ped+p]<=0):\n",
    "                                new_action_c = torch.squeeze(actor_net_cross(torch.unsqueeze(torch.tensor(new_prev_state), dim=0).float()))\n",
    "                            else:\n",
    "                                new_action_c = torch.squeeze(actor_net_wait(torch.unsqueeze(torch.tensor(new_prev_state), dim=0).float()))\n",
    "                            if(new_action_c.dim()==0):\n",
    "                                new_action_c=torch.unsqueeze(new_action_c,dim=0)\n",
    "                            action_c_numpy=min(action_c_numpy,new_action_c.detach().numpy())\n",
    "                            action_c_numpy=min(action_c_numpy,(10.0-new_prev_state[0])/(self.dt))\n",
    "                            #action_c_numpy=action_c_numpy_new*self.discount_array[0]+prev_action_c[i]*self.discount_array[1]\n",
    "                        action_all_c=np.append(action_all_c, action_c_numpy)\n",
    "                        #prev_action_c=action_all_c\n",
    "                    action_all=np.append(action_all_c, action_d_light)\n",
    "                    \n",
    "                    state, reward, done, trunc, _ = self.env.step(action_all)\n",
    "                    batch_obs.append(prev_state)\n",
    "                    batch_acts.append(action_all_c) #2 actions\n",
    "                    episodic_reward = np.minimum(episodic_reward,self.env.reward_light)\n",
    "                    ep_rews.append(reward)\n",
    "                    if(state[\"env\"][1]!=nb_ped):\n",
    "                        need_new_d=True\n",
    "                        save_batch=True\n",
    "                    prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "                    nb_ped=state[\"env\"][1]\n",
    "                \n",
    "                if(save_batch or done):\n",
    "                    for ped in self.env.pedestrian:\n",
    "                        batch_waiting_time.append(ped.waiting_time)\n",
    "                    batch_rews_c.append(ep_rews)\n",
    "                    batch_rews_d.append(episodic_reward)\n",
    "                    batch_acts_d.append(action_d)\n",
    "                save_batch=False\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "        batch_rews_c_final=[]\n",
    "        for ep_rews in reversed(batch_rews_c):\n",
    "            for rew in reversed(ep_rews):\n",
    "                batch_rews_c_final.insert(0,rew)\n",
    "        t_batch_obs=torch.tensor(np.array(batch_obs), dtype=torch.float)\n",
    "        t_batch_acts=torch.tensor(np.array(batch_acts), dtype=torch.float)\n",
    "        t_batch_acts_d=torch.tensor(np.array(batch_acts_d), dtype=torch.float)\n",
    "        t_batch_rews_c=torch.tensor(batch_rews_c_final, dtype=torch.float)\n",
    "        t_batch_rews_d=torch.tensor(batch_rews_d, dtype=torch.float)\n",
    "        t_batch_waiting_time=torch.tensor(batch_waiting_time, dtype=torch.float)\n",
    "        #torch.save(t_batch_acts_d, 'decisions.pt')\n",
    "        np.savetxt('decisions_d_dataset.txt', np.array(t_batch_acts_d), fmt='%d')\n",
    "        return t_batch_obs, t_batch_acts, t_batch_rews_c, t_batch_rews_d, t_batch_waiting_time\n",
    "\n",
    "    def iterations_rand(self, actor_net_cross, actor_net_wait, actor_net_choice, actor_distrib,\n",
    "                        cov_mat, cov_mat_d, batch_size, random_rate=0.05, select_param=True):\n",
    "        \"\"\"\n",
    "        Iterate on the environment.\n",
    "        :param actor_net: current policy (actor NN)\n",
    "        :param cov_mat: covariance matrix used for exploration\n",
    "        :param batch_size: batch size\n",
    "        :return: Tensors; state batch, action batch, log_proba batch\n",
    "        \"\"\"\n",
    "        t = 0\n",
    "        error=False\n",
    "        ep_rews = []\n",
    "        ep_probas=[]\n",
    "        ep_actions=[]\n",
    "        ep_obs=[]\n",
    "        ep_probas_d=[]\n",
    "        ep_actions_d=[]\n",
    "        ep_obs_d=[]\n",
    "        #ep_param_state=[]\n",
    "        action_d=np.array([0] *self.env.nb_car* self.env.nb_ped)\n",
    "        action_d_light=np.array([0] *self.env.nb_car)\n",
    "        episodic_reward = np.array([0.]*self.nb_cars)\n",
    "        while t<batch_size:\n",
    "            need_new_d=True\n",
    "            save_batch=False\n",
    "            state,_ = self.env.reset()\n",
    "            if(select_param):\n",
    "                parameters_state = torch.squeeze(actor_distrib(torch.rand(1)).float())\n",
    "                #self.batch_obs_distrib.extend(parameters_state)\n",
    "                self.env.reset_distrib(parameters_state)\n",
    "                #modify_fullstate(parameters_state,self.env.nb_ped,self.env.nb_car,self.env.nb_lines)\n",
    "                #self.batch_obs_distrib.extend(prev_state.unsqueeze(0))\n",
    "            state = self.env.get_state()\n",
    "            prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "            for step_ep in range(self.max_steps): \n",
    "                if(need_new_d):\n",
    "                    ep_rews = []\n",
    "                    ep_probas=[]\n",
    "                    ep_actions=[]\n",
    "                    ep_obs=[]\n",
    "                    ep_obs_d=[]\n",
    "                    ep_obs_distrib=[]\n",
    "                    ep_probas_d=[]\n",
    "                    ep_actions_d=[]\n",
    "                    nb_ped = self.env.nb_ped#state[\"env\"][1]\n",
    "                    episodic_reward = np.array([0.]*self.nb_cars)\n",
    "                    #state_all_d=np.array([])\n",
    "                    action_all_d=np.array([])\n",
    "                    action_all_d_light=np.array([])\n",
    "                    log_proba_all_d=np.array([])\n",
    "                    log_proba_all_d_light=np.array([])\n",
    "                    new_prev_state_all_d=np.array([])\n",
    "                    new_prev_state_all_d_light=np.array([])\n",
    "                    for i in range(self.env.nb_car):\n",
    "                        for j in range(self.env.nb_ped):\n",
    "                            new_prev_state = self.obs_car_ped_d(prev_state,i,j) # for 1 ped and 1 vehicule+info other vehicle\n",
    "                            parameters_based = torch.squeeze(actor_net_choice(torch.unsqueeze(torch.tensor(new_prev_state),\n",
    "                                                                                              dim=0).float()))\n",
    "                            #action_all_d=torch.cat((action_all_d,parameters_based),dim=0)\n",
    "                            distribution_d=Categorical(parameters_based)\n",
    "                            action_d=distribution_d.sample()\n",
    "                            log_proba_d=distribution_d.log_prob(action_d)\n",
    "                            log_proba_all_d = np.append(log_proba_all_d,log_proba_d.detach().numpy())\n",
    "                            action_all_d = np.append(action_all_d, action_d.detach().numpy())\n",
    "                            new_prev_state_all_d = np.append(new_prev_state_all_d, new_prev_state)\n",
    "                        \n",
    "                        new_prev_state_all_d=new_prev_state_all_d.reshape(-1,self.shape_env_d)\n",
    "                        closest_ped=self.closest_ped_d(prev_state,i)\n",
    "                        new_action_light=action_all_d[i*self.env.nb_ped+self.closest_ped_d(prev_state,i)]\n",
    "                        action_all_d_light = np.append(action_all_d_light,\n",
    "                                                     action_all_d[i*self.env.nb_ped+closest_ped])\n",
    "                        log_proba_all_d_light = np.append(log_proba_all_d_light,\n",
    "                                                          log_proba_all_d[i*self.env.nb_ped+closest_ped])\n",
    "                        new_prev_state_all_d_light=np.append(new_prev_state_all_d_light,\n",
    "                                                             new_prev_state_all_d[i*self.env.nb_ped+closest_ped])\n",
    "                        if(select_param):\n",
    "                            prev_state_distrib = modify(parameters_state,self.env.nb_ped,self.env.nb_car,self.env.nb_lines,i,closest_ped)\n",
    "                            self.batch_obs_distrib.extend(prev_state_distrib.unsqueeze(0))\n",
    "                    action_d=(2*action_all_d-1)\n",
    "                    action_d_light=(2*action_all_d_light-1)\n",
    "                    ep_actions_d.append(action_all_d_light)\n",
    "                    ep_probas_d.append(log_proba_all_d_light)\n",
    "                    ep_obs_d.append(new_prev_state_all_d_light)\n",
    "                    #ep_obs_distrib.append(new_prev_state_all_d)\n",
    "                    need_new_d=False\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    action_all_c=np.array([])\n",
    "                    log_proba_all_c=np.array([])\n",
    "                    new_prev_state_all_c=np.array([])\n",
    "                    for i in range(self.nb_cars):\n",
    "                        action_c_tensor=torch.tensor(self.env.car_b[1,0])\n",
    "                        state_c_tensor=self.obs_car_ped(prev_state,i,0)\n",
    "                        for p in range(self.env.nb_ped):\n",
    "                            new_prev_state=self.obs_car_ped(prev_state,i,p)\n",
    "                            if(action_d[i*self.env.nb_ped+p]<=0):\n",
    "                                parameters_based_c=torch.squeeze(actor_net_cross(torch.unsqueeze(torch.tensor(new_prev_state),\n",
    "                                                                                                   dim=0).float()))\n",
    "                            else:\n",
    "                                parameters_based_c = torch.squeeze(actor_net_wait(torch.unsqueeze(torch.tensor(new_prev_state),\n",
    "                                                                                                  dim=0).float()))\n",
    "                            if(parameters_based_c.dim()==0):\n",
    "                                parameters_based_c=torch.unsqueeze(parameters_based_c,dim=0)\n",
    "                            action_c_tensor=torch.min(action_c_tensor,parameters_based_c) # need to remove passed pedestrian in the decision?\n",
    "                            if (parameters_based_c==action_c_tensor):\n",
    "                                state_c_tensor=new_prev_state\n",
    "                        distribution_p = MultivariateNormal(action_c_tensor, cov_mat)\n",
    "                        action_c = distribution_p.sample()\n",
    "                        log_proba = distribution_p.log_prob(action_c)\n",
    "                        action_c_numpy = action_c.detach().numpy()\n",
    "                        log_proba_all_c = np.append(log_proba_all_c,log_proba.detach().numpy())\n",
    "                        action_all_c = np.append(action_all_c, action_c_numpy)\n",
    "                        new_prev_state_all_c = np.append(new_prev_state_all_c, state_c_tensor)\n",
    "                        \n",
    "                    action_all=np.append(action_all_c, action_d_light)\n",
    "                    state, rewards, done, trunc, _ = self.env.step(action_all)\n",
    "                    episodic_reward = np.minimum(episodic_reward,self.env.reward_light)\n",
    "                    #min(episodic_reward,self.reward_choice(self.env.reward_light))\n",
    "                    #print(episodic_reward)\n",
    "                    #action_all_trained=np.append(action_all_trained,action_all_c)\n",
    "                    ep_obs.append(new_prev_state_all_c)\n",
    "                    ep_actions.append(action_all_c)\n",
    "                    ep_probas.append(log_proba_all_c)\n",
    "                    ep_rews.append(rewards)\n",
    "                    if(state[\"env\"][1]!=nb_ped):# or (not error and self.env.error_scenario)):\n",
    "                        if(not error and self.env.error_scenario):\n",
    "                            error=True\n",
    "                            self.env.error_scenario=False\n",
    "                            \n",
    "                        #print(\"Rebuild plan: \",error)\n",
    "                        need_new_d=True\n",
    "                        save_batch=True\n",
    "                    prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "                    nb_ped=state[\"env\"][1]\n",
    "                if(save_batch + done):\n",
    "                    ep_probas=np.array(ep_probas).reshape(-1,self.nb_cars)\n",
    "                    ep_actions=np.array(ep_actions).reshape(-1,self.nb_cars)\n",
    "                    ep_obs=np.array(ep_obs).reshape(-1,self.nb_cars,self.shape_env)\n",
    "                    ep_rews=np.array(ep_rews).reshape(-1,self.nb_cars)\n",
    "                    ep_probas_d=np.array(ep_probas_d).reshape(-1,self.nb_cars)#.reshape(-1,self.nb_cars)\n",
    "                    ep_actions_d=np.array(ep_actions_d).reshape(-1,self.nb_cars)#.reshape(-1,self.nb_cars)\n",
    "                    ep_obs_d=np.array(ep_obs_d).reshape(-1,self.nb_cars,self.shape_env_d)\n",
    "                    #.reshape(-1,self.shape_env)#.reshape(-1,self.nb_cars,self.shape_env)\n",
    "                    #print(\"EP_rew is \",len(ep_rews[:,i]))\n",
    "                    for i in range(self.nb_cars):  \n",
    "                        if(action_d[i]<=0):\n",
    "                            self.batch_rews_cross.append(ep_rews[:,i])\n",
    "                            #print(self.batch_rews_cross)\n",
    "                            self.batch_log_probs_cross.extend(ep_probas[:,i])\n",
    "                            self.batch_acts_cross.extend(ep_actions[:,i:i+1])\n",
    "                            self.batch_obs_cross.extend(ep_obs[:,i])\n",
    "                        else:\n",
    "                            self.batch_rews_wait.append(ep_rews[:,i])\n",
    "                            self.batch_log_probs_wait.extend(ep_probas[:,i])\n",
    "                            self.batch_acts_wait.extend(ep_actions[:,i:i+1])\n",
    "                            self.batch_obs_wait.extend(ep_obs[:,i])\n",
    "                            \n",
    "                        self.batch_rews_choice.append(episodic_reward[i:i+1])\n",
    "                        self.batch_log_probs_choice.extend(ep_probas_d[:,i])\n",
    "                        self.batch_acts_choice.extend(ep_actions_d[:,i:i+1])\n",
    "                        self.batch_obs_choice.extend(ep_obs_d[:,i])\n",
    "                        \n",
    "                save_batch=False\n",
    "                t += 1\n",
    "                if done:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "    def change_obs(self, obs, num_car):\n",
    "        size_cardata=int(self.env.observation_space[\"car\"].shape[0]/self.nb_cars)\n",
    "        new_obs=np.copy(obs)\n",
    "        new_obs[:size_cardata]=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        new_obs[num_car*size_cardata:(num_car+1)*size_cardata]=obs[:size_cardata]\n",
    "        return new_obs\n",
    "    \n",
    "    def is_in_cross(self, car_line, ped_pos, ped_dir, cross_lines, lines):\n",
    "        cross= (cross_lines*2) /lines\n",
    "        line_start, line_end = (-cross_lines)+cross*(car_line), (-cross_lines)+cross*(car_line+1)\n",
    "        dist_to_start=(ped_pos-line_start)*(ped_dir>0) + (line_end-ped_pos)*(ped_dir<0)\n",
    "        return (ped_pos>line_start and ped_pos<line_end),dist_to_start\n",
    "        \n",
    "    def leave_cross(self,  car_line, ped_pos, ped_dir, cross_lines, lines):\n",
    "        cross= (cross_lines*2) /lines\n",
    "        line_start, line_end = (-cross_lines)+cross*(car_line), (-cross_lines)+cross*(car_line+1)\n",
    "        #dist_to_end=(ped_pos-line_end)*(ped_dir>0) + (line_start-ped_pos)*(ped_dir<0)\n",
    "        if(ped_dir==-1):\n",
    "            return (ped_pos<line_start) , (line_start-ped_pos)\n",
    "        else:\n",
    "            return (ped_pos>line_end) , (ped_pos-line_end)\n",
    "\n",
    "    def obs_car_ped(self, obs, num_car, num_ped): #11\n",
    "        new_obs=np.array([])\n",
    "        size_car=int(self.env.observation_space[\"car\"].shape[0])\n",
    "        size_cardata=int(self.env.observation_space[\"car\"].shape[0]/self.env.nb_car)\n",
    "        size_ped=int(self.env.observation_space[\"ped\"].shape[0])\n",
    "        size_peddata=int(self.env.observation_space[\"ped\"].shape[0]/self.env.nb_ped)\n",
    "        size_env=int(self.env.observation_space[\"env\"].shape[0])\n",
    "        # respectively car acceleration (0), car_speed(1), car speed diff (2), car position (3), light(4), line (5)\n",
    "        car_data=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        # respectively  pedestrian speed x (0), pedestrian speed y (1), pedestrian position x(2)\n",
    "        #                position y (3), dl(4), leave CZ(5), in CZ (6), exist(7), direction(8)\n",
    "        ped_data=obs[size_car+size_env+num_ped*size_peddata:size_car+size_env+(num_ped+1)*size_peddata]\n",
    "        #sizealllines (0), nb_ped (1), lines \n",
    "        env_data=obs[size_car:size_car+size_env]\n",
    "        new_obs=np.append(new_obs,[car_data[1],car_data[2]])#car_data[0], a voir pour avoir un numero de ligne % position du pieton\n",
    "        #acc speed, diff speed, car speed diff , line (4 data)\n",
    "        crossing, dist_start=self.is_in_cross(car_data[5],ped_data[3],ped_data[8],env_data[0],env_data[2])\n",
    "        end_cross, dist_end=self.leave_cross(car_data[5],ped_data[3],ped_data[8],env_data[0],env_data[2])\n",
    "        time_to_collision=min(10.0,(ped_data[2]-car_data[3])/max(car_data[1]-ped_data[0],0.01))*(ped_data[2]>car_data[3])\n",
    "        time_to_collision=10.0*(ped_data[2]<=car_data[3])\n",
    "        new_obs=np.append(new_obs,[ped_data[1],ped_data[2]>car_data[3], ped_data[2]-car_data[3], ped_data[4],\n",
    "                                   crossing, end_cross, dist_start, dist_end, time_to_collision])#(9 data)\n",
    "        # speed y, is in front, distance ped-AV, safety factor,  ped in CZ or finished,\n",
    "        # distance to start, distance to end cross, time to collision\n",
    "        new_obs=np.append(new_obs,[env_data[0],env_data[2]])\n",
    "        # crossing size , lines (2 data)\n",
    "        #obs[size_car+size_env+num_ped*size_peddata:size_car+size_env+(num_ped+1)*size_peddata],\n",
    "        #obs[size_car:size_car+size_env]))#,dim=1)\n",
    "        #new_obs[:size_cardata]=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        #new_obs[num_car*size_cardata:(num_car+1)*size_cardata]=obs[:size_cardata]\n",
    "        \n",
    "        #add time to collision: min(10.0,(ped_data[2]-car_data[3])/(car_data[1]-ped_data[0])\n",
    "        return new_obs.flatten()\n",
    "    \n",
    "    def obs_car_ped_d(self, obs, num_car, num_ped):\n",
    "        new_obs=torch.tensor([])\n",
    "        size_car=int(self.env.observation_space[\"car\"].shape[0])\n",
    "        size_cardata=int(self.env.observation_space[\"car\"].shape[0]/self.env.nb_car)\n",
    "        size_ped=int(self.env.observation_space[\"ped\"].shape[0])\n",
    "        size_peddata=int(self.env.observation_space[\"ped\"].shape[0]/self.env.nb_ped)\n",
    "        size_env=int(self.env.observation_space[\"env\"].shape[0])\n",
    "        car_data=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        #ped_data=obs[size_car+size_env:size_car+size_env+size_ped]\n",
    "        env_data=obs[size_car:size_car+size_env]\n",
    "        new_obs=torch.cat((new_obs,torch.tensor([car_data[1],car_data[2]])),dim=0)#car_data[0],\n",
    "        #acc speed, diff speed, car speed diff , line (4 data)\n",
    "        ped_data=obs[size_car+size_env+num_ped*size_peddata:size_car+size_env+(num_ped+1)*size_peddata]\n",
    "        for num_car_i in range(self.env.nb_car):\n",
    "            if(num_car_i!=num_car):\n",
    "                car_data2=obs[num_car_i*size_cardata:(num_car_i+1)*size_cardata]\n",
    "                new_obs=torch.cat((new_obs,torch.tensor([car_data2[1],ped_data[2]>car_data2[3],(ped_data[2]-car_data2[3]),\n",
    "                                           car_data2[4], car_data2[5]-car_data[5]])) ,dim=0)\n",
    "                # speed, is in front,diff position, light, line (5 data) manque position relative % au vehicule?\n",
    "                \n",
    "        car_data=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        crossing, dist_start=self.is_in_cross(car_data[5],ped_data[3],ped_data[8],env_data[0],env_data[2])\n",
    "        end_cross, dist_end=self.leave_cross(car_data[5],ped_data[3],ped_data[8],env_data[0],env_data[2])\n",
    "        \n",
    "        new_obs=torch.cat((new_obs,torch.tensor([ped_data[1], ped_data[2]>car_data[3], (ped_data[2]-car_data[3]), ped_data[4],\n",
    "                                   crossing, end_cross, dist_start, dist_end])), dim=0)\n",
    "        # speed y, is in front, distance to ped, safety factor, ped in CZ or finished,\n",
    "        #distance to start, distance to end cross #(8 data)\n",
    "        new_obs=torch.cat((new_obs,torch.tensor([env_data[0],env_data[2]])), dim=0)\n",
    "        #size of the road, number of lines (2 data)\n",
    "        #obs[size_car+size_env+num_ped*size_peddata:size_car+size_env+(num_ped+1)*size_peddata],\n",
    "        #obs[size_car:size_car+size_env]))#,dim=1)\n",
    "        \n",
    "        #new_obs[:size_cardata]=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        #new_obs[num_car*size_cardata:(num_car+1)*size_cardata]=obs[:size_cardata]\n",
    "        return new_obs.flatten()\n",
    "    \n",
    "    #decision for light\n",
    "    def closest_ped_d(self, obs, num_car):\n",
    "        size_env=int(self.env.observation_space[\"env\"].shape[0])\n",
    "        size_car=int(self.env.observation_space[\"car\"].shape[0])\n",
    "        size_cardata=int(self.env.observation_space[\"car\"].shape[0]/self.env.nb_car)\n",
    "        size_peddata=int(self.env.observation_space[\"ped\"].shape[0]/self.env.nb_ped)\n",
    "        min_ped=0\n",
    "        car_data=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        min_dist_ped=obs[size_car+size_env+2]-car_data[3]\n",
    "        for num_ped in range(self.env.nb_ped):\n",
    "            ped_data=obs[size_car+size_env+num_ped*size_peddata:size_car+size_env+(num_ped+1)*size_peddata]\n",
    "            if(ped_data[2]-car_data[3]<min_dist_ped):\n",
    "                min_dist_ped=ped_data[2]-car_data[3]\n",
    "                min_ped=num_ped\n",
    "        return min_ped        \n",
    "        \n",
    "    def immediate_rewards(self):\n",
    "        \"\"\"\n",
    "        Immediate rewards\n",
    "        :return: Tensor; batch reward\n",
    "        \"\"\"\n",
    "        batch_rew_cross = []\n",
    "        batch_rew_wait = []\n",
    "        batch_rew_choice= []\n",
    "        for ep_rews in reversed(self.batch_rews_cross):\n",
    "            for rew in reversed(ep_rews):\n",
    "                batch_rew_cross.insert(0,rew)\n",
    "        for ep_rews in reversed(self.batch_rews_wait):\n",
    "            for rew in reversed(ep_rews):\n",
    "                batch_rew_wait.insert(0,rew)\n",
    "        batch_rew_choice=self.batch_rews_choice\n",
    "        batch_rew_choice=np.array(batch_rew_choice)\n",
    "        batch_rew_wait=np.array(batch_rew_wait)\n",
    "        batch_rew_cross=np.array(batch_rew_cross)\n",
    "        #print((batch_rew_choice).shape)\n",
    "        #print((batch_rew_wait).shape)\n",
    "        #print((batch_rew_cross).shape)\n",
    "        return torch.tensor(batch_rew_cross, dtype=torch.float),torch.tensor(batch_rew_wait, dtype=torch.float), torch.tensor(batch_rew_choice, dtype=torch.float)\n",
    "    \n",
    "    def futur_rewards(self):\n",
    "        \"\"\"\n",
    "        Expected futures rewards\n",
    "        :return: Tensor; batch reward-to-go\n",
    "        \"\"\"\n",
    "        batch_rtgs_cross = []\n",
    "        batch_rtgs_wait = []\n",
    "        batch_rtgs_choice= []\n",
    "        #print(len(self.batch_rews_cross))\n",
    "        #print(len(self.batch_rews_wait))\n",
    "        for ep_rews in reversed(self.batch_rews_cross):\n",
    "            episodic_reward=0.0\n",
    "            for rew in reversed(ep_rews):\n",
    "                episodic_reward= rew + 0.99*episodic_reward\n",
    "                batch_rtgs_cross.insert(0,episodic_reward)\n",
    "        for ep_rews in reversed(self.batch_rews_wait):\n",
    "            episodic_reward=0.0\n",
    "            for rew in reversed(ep_rews):\n",
    "                episodic_reward= rew + 0.99*episodic_reward\n",
    "                batch_rtgs_wait.insert(0,episodic_reward)\n",
    "        batch_rtgs_choice=self.batch_rews_choice\n",
    "        #print(len(batch_rtgs_cross))\n",
    "        #print(len(batch_rtgs_wait))\n",
    "        batch_rtgs_choice=np.array(batch_rtgs_choice)\n",
    "        batch_rtgs_wait=np.array(batch_rtgs_wait)\n",
    "        batch_rtgs_cross=np.array(batch_rtgs_cross)\n",
    "        return torch.tensor(batch_rtgs_cross, dtype=torch.float), torch.tensor(batch_rtgs_wait, dtype=torch.float), torch.tensor(batch_rtgs_choice, dtype=torch.float)\n",
    "\n",
    "#4) Algorithm PPO\n",
    "\n",
    "def multiply(action, param):\n",
    "    res=torch.tensor(1.)\n",
    "    for i in range(len(action)):\n",
    "        distrib= Categorical(param[i])\n",
    "        res=res*distrib.log_prob(action)\n",
    "    return res.detach().numpy()\n",
    "\n",
    "def delta_l( car_pos, car_speed, ped_pos):\n",
    "    return torch.abs(car_pos - ped_pos) - (car_speed * car_speed / (-2.0 *-4.0))-  1.0 *(car_speed)\n",
    "\n",
    "def delta_l_all(car_pos, car_speed, ped_pos):\n",
    "        delta_l=0.0\n",
    "        for i in range(len(car_speed)):\n",
    "            new_delta=abs(car_pos[i]-ped_pos)-(car_speed[i]*car_speed[i]/(-2.0*-4.0)) - 1.0 * (car_speed[i])#+0.5)\n",
    "            delta_l= min(delta_l,new_delta)\n",
    "        return delta_l\n",
    "\n",
    "def is_in_cross(car_line, ped_pos, ped_dir, cross_lines, lines):\n",
    "    cross= (cross_lines*2) /lines\n",
    "    line_start, line_end = (-cross_lines)+cross*(car_line), (-cross_lines)+cross*(car_line+1)\n",
    "    dist_to_start=(ped_pos-line_start)*(ped_dir>0) + (line_end-ped_pos)*(ped_dir<0)\n",
    "    return (ped_pos>line_start and ped_pos<line_end),dist_to_start\n",
    "\n",
    "def leave_cross(car_line, ped_pos, ped_dir, cross_lines, lines):\n",
    "    cross= (cross_lines*2) /lines\n",
    "    line_start, line_end = (-cross_lines)+cross*(car_line), (-cross_lines)+cross*(car_line+1)\n",
    "    #dist_to_end=(ped_pos-line_end)*(ped_dir>0) + (line_start-ped_pos)*(ped_dir<0)\n",
    "    if(ped_dir==-1):\n",
    "        return (ped_pos<line_start) , (line_start-ped_pos)\n",
    "    else:\n",
    "        return (ped_pos>line_end) , (ped_pos-line_end)\n",
    "#transition from distrib to state\n",
    "#def modify(state_distrib, nb_ped, nb_car, nb_lane):\n",
    "#    ped_speed = [state_distrib[2*i:2*(i+1)] for i in range(nb_ped)] # 2 inputs\n",
    "#    ped_pos = [state_distrib[2*(i+nb_ped):2*(i+nb_ped+1)] for i in range(nb_ped)]# 2 inputs\n",
    "#    ped_direction = [state_distrib[4*nb_ped+i:4*nb_ped+i+1] for i in range(nb_ped)]# 1 inputs\n",
    "#    car_pos = [state_distrib[5*nb_ped+i:5*nb_ped+(i+1)] for i in range(nb_car)]# 1 inputs\n",
    "#    env_size = state_distrib[5*nb_ped+2*nb_car]# 1 inputs\n",
    "#    cars=[[0., 10., 0., car_pos[i], 0., i] for i in range(nb_car)]\n",
    "#    peds=[[ped_speed[i][0], ped_speed[i][1], ped_pos[i][0], ped_pos[i][1], delta_l_all(cars[:,1],cars[:,3],ped_pos[i]),\n",
    "#           False, False, True, ped_direction[i]]  for i in range(nb_ped)]\n",
    "#    env=[env_size,nb_ped,nb_lane]\n",
    "#    state={\"car\":cars, \"ped\":peds, \"env\":env}\n",
    "#    return state\n",
    "#transition from distrib to state\n",
    "\n",
    "def modify2(state_distrib, nb_ped, nb_car, nb_lane):\n",
    "    input_p, input_c, input_e = 5, 1, 1\n",
    "    ped_speed = [state_distrib[0+input_p*i:2+input_p*i] for i in range(nb_ped)] # 2 inputs\n",
    "    ped_pos = [state_distrib[2+input_p*i:4+input_p*i] for i in range(nb_ped)]# 2 inputs\n",
    "    ped_direction = [state_distrib[4+input_p*i] for i in range(nb_ped)]# 1 inputs\n",
    "    car_pos = [state_distrib[i+input_p*nb_ped] for i in range(nb_car)]# 1 inputs\n",
    "    env_size = state_distrib[nb_car*input_c+input_p*nb_ped]# 1 inputs\n",
    "    cars=[[0., 10., 0., car_pos[i], 0., i] for i in range(nb_car)]\n",
    "    peds=[[ped_speed[i][0], ped_speed[i][1], ped_pos[i][0], ped_pos[i][1],\n",
    "           delta_l_all([10.0 for i in range(nb_car)],[car_pos[i] for i in range(nb_car)],ped_pos[i][0]),#[10.0 for i in range(nb_car)]\n",
    "           False, False, True, ped_direction[i]]  for i in range(nb_ped)]\n",
    "    env=[env_size,nb_ped,nb_lane]\n",
    "    state={\"car\":cars, \"ped\":peds, \"env\":env}\n",
    "    state_full=[]\n",
    "    for i in list(cars):\n",
    "        state_full+=i\n",
    "    for i in list(peds):\n",
    "        state_full+=i\n",
    "    state_full+=env\n",
    "    #print(torch.cat([torch.tensor(i) for i in list(state.values())]))\n",
    "    return torch.tensor(state_full)#torch.cat([i for i in list(state.values())])\n",
    "#np.concatenate([i.flatten() for i in list(state.values())])\n",
    "\n",
    "def modify_statefull(state_distrib, nb_ped, nb_car, nb_lane):\n",
    "    input_p, input_c, input_e = 5, 1, 1\n",
    "    ped_speed = [state_distrib[0+input_p*i:2+input_p*i] for i in range(nb_ped)] # 2 inputs\n",
    "    ped_pos = [state_distrib[2+input_p*i:4+input_p*i] for i in range(nb_ped)]# 2 inputs\n",
    "    ped_direction = [state_distrib[4+input_p*i] for i in range(nb_ped)]# 1 inputs\n",
    "    car_pos = [state_distrib[i+input_p*nb_ped] for i in range(nb_car)]# 1 inputs\n",
    "    env_size = state_distrib[nb_car*input_c+input_p*nb_ped]# 1 inputs\n",
    "    #print(\"First \",car_pos)\n",
    "    #cars=torch.cat([torch.cat([torch.tensor(0.), torch.tensor(10.), torch.tensor(0.), car_pos[i], torch.tensor(0.), torch.tensor(i)]) for i in range(nb_car)])\n",
    "    #car_i=torch.cat([10.,0.])\n",
    "    cars=torch.cat([torch.tensor([0., 10., 0., car_pos[i], 0., i]) for i in range(nb_car)])\n",
    "    for i in range(nb_car):\n",
    "        cars[i*6+3]=car_pos[i]\n",
    "    #print(\"Second \",cars)\n",
    "    peds=torch.cat([torch.tensor([ped_speed[i][0], ped_speed[i][1], ped_pos[i][0], ped_pos[i][1],\n",
    "           torch.tensor(delta_l_all([10.0 for i in range(nb_car)],[car_pos[i] for i in range(nb_car)],ped_pos[i][0])),#[10.0 for i in range(nb_car)]\n",
    "           False, False, True, ped_direction[i]])  for i in range(nb_ped)])\n",
    "    # speed, is in front,diff position, light, line (5 data) manque position relative % au vehicule?\n",
    "    #car_data2[1],ped_data[2]>car_data2[3],(ped_data[2]-car_data2[3]), car_data2[4], car_data2[5]-car_data[5]\n",
    "    for i in range(nb_ped):\n",
    "        peds[i*9+0]=ped_speed[i][0]\n",
    "        peds[i*9+1]=ped_speed[i][1]\n",
    "        peds[i*9+2]=ped_pos[i][0]\n",
    "        peds[i*9+3]=ped_pos[i][1]\n",
    "        peds[i*9+8]=ped_direction[i]\n",
    "    env=torch.tensor([env_size,nb_ped,nb_lane])\n",
    "    env[0]=env_size\n",
    "    #state={\"car\":cars, \"ped\":peds, \"env\":env}\n",
    "    #state_full=[]\n",
    "    #for i in list(cars):\n",
    "    #    state_full+=i\n",
    "    #for i in list(peds):\n",
    "    #    state_full+=i\n",
    "    #state_full+=env\n",
    "    #print(torch.cat([torch.tensor(i) for i in list(state.values())]))\n",
    "    return torch.cat([cars,env,peds])#torch.tensor(, requires_grad=True)\n",
    "\n",
    "def modify_2(state_distrib, nb_ped, nb_car, nb_lane, id_car, id_ped):\n",
    "    input_p, input_c, input_e = 5, 1, 1\n",
    "    ped_speed = [state_distrib[0+input_p*i:2+input_p*i] for i in range(nb_ped)] # 2*nb_ped inputs\n",
    "    ped_pos = [state_distrib[2+input_p*i:4+input_p*i] for i in range(nb_ped)]# 2*nb_ped inputs\n",
    "    ped_direction = [1.*(state_distrib[4+input_p*i]>=0)-1.*(state_distrib[4+input_p*i]<0) for i in range(nb_ped)]# 2*nb_ped inputs\n",
    "    car_pos = [state_distrib[i+input_p*nb_ped] for i in range(nb_car)]# nb_car inputs\n",
    "    env_size = state_distrib[nb_car*input_c+input_p*nb_ped]# 1 inputs\n",
    "    for i in range(nb_ped):\n",
    "        ped_pos[i][1] = ped_direction[i]*(ped_pos[i][1] - torch.tensor(nb_lane*env_size/2.0))\n",
    "        #output[4]=1.*(output[4]>=0)-1.*(output[4]<0)\n",
    "        #output[3]=output[3]+output[4]*output[6]\n",
    "    #print(\"First \",car_pos)\n",
    "    #cars=torch.cat([torch.cat([torch.tensor(0.), torch.tensor(10.), torch.tensor(0.), car_pos[i], torch.tensor(0.), torch.tensor(i)]) for i in range(nb_car)])\n",
    "    cars_i=torch.tensor([10.,0.])\n",
    "    #[car_data2[1],ped_data[2]>car_data2[3],(ped_data[2]-car_data2[3]),car_data2[4], car_data2[5]-car_data[5]]\n",
    "    if(nb_car>1):\n",
    "        cars=torch.cat([torch.tensor([10., 0.,0.,0., i-id_car]) for i in range(nb_car) if i!=id_car])\n",
    "        for i in range(nb_car):\n",
    "            if i!=id_car:\n",
    "                cars[i*6+1]=ped_pos[id_ped][0]>car_pos[i]\n",
    "                cars[i*6+2]=ped_pos[id_ped][0]-car_pos[i]\n",
    "                cars[i*6+3]=delta_l(10.0 ,car_pos[i],ped_pos[i][0])\n",
    "    #print(\"Second \",cars)\n",
    "    crossing, dist_start=is_in_cross(id_car,ped_pos[id_ped][1],ped_direction[id_ped],env_size,nb_lane)\n",
    "    end_cross, dist_end=leave_cross(id_car,ped_pos[id_ped][1],ped_direction[id_ped],env_size,nb_lane) \n",
    "    peds=torch.tensor([0.]*8)\n",
    "    peds[0]=ped_speed[id_ped][1]\n",
    "    peds[1]=ped_pos[id_ped][0]>car_pos[id_car]\n",
    "    peds[2]=(ped_pos[id_ped][0]-car_pos[id_car])\n",
    "    peds[3]=delta_l(10.0 ,car_pos[id_car],ped_pos[id_ped][0])\n",
    "    peds[4]=crossing\n",
    "    peds[5]=end_cross\n",
    "    peds[6]=dist_start\n",
    "    peds[7]=dist_end\n",
    "    #peds=torch.cat([torch.tensor([ped_speed[i][0], ped_speed[i][1], ped_pos[i][0], ped_pos[i][1],\n",
    "    #       torch.tensor(delta_l_all([10.0 for i in range(nb_car)],[car_pos[i] for i in range(nb_car)],ped_pos[i][0])),#[10.0 for i in range(nb_car)]\n",
    "    #       False, False, True, ped_direction[i]])  for i in range(nb_ped)])\n",
    "    # speed, is in front,diff position, light, line (5 data) manque position relative % au vehicule?\n",
    "    #car_data2[1],ped_data[2]>car_data2[3],(ped_data[2]-car_data2[3]), car_data2[4], car_data2[5]-car_data[5]\n",
    "    env=torch.tensor([env_size,nb_lane])\n",
    "    env[0]=env_size\n",
    "    #state={\"car\":cars, \"ped\":peds, \"env\":env}\n",
    "    #state_full=[]\n",
    "    #for i in list(cars):\n",
    "    #    state_full+=i\n",
    "    #for i in list(peds):\n",
    "    #    state_full+=i\n",
    "    #state_full+=env\n",
    "    #print(torch.cat([torch.tensor(i) for i in list(state.values())]))\n",
    "    if(nb_car>1):\n",
    "        return torch.cat([cars_i,cars,env,peds])\n",
    "    return torch.cat([cars_i,env,peds])#torch.tensor(, requires_grad=True)\n",
    "\n",
    "def modify(state_distrib, nb_ped, nb_car, nb_lane, id_car, id_ped):\n",
    "    input_p, input_c, input_e = 5, 1, 1\n",
    "    ped_speed = [state_distrib[0+input_p*i:2+input_p*i] for i in range(nb_ped)] # 2*nb_ped inputs\n",
    "    ped_pos = [state_distrib[2+input_p*i:4+input_p*i] for i in range(nb_ped)]# 2*nb_ped inputs\n",
    "    ped_direction = [1.*int(state_distrib[4+input_p*i]>=0)-1.*int(state_distrib[4+input_p*i]<0) for i in range(nb_ped)]# 2*nb_ped inputs\n",
    "    car_pos = [state_distrib[i+input_p*nb_ped] for i in range(nb_car)]# nb_car inputs\n",
    "    env_size = state_distrib[nb_car*input_c+input_p*nb_ped]# 1 inputs\n",
    "    for i in range(nb_ped):\n",
    "        ped_pos[i][1] = ped_direction[i]*(ped_pos[i][1] - torch.tensor(nb_lane*env_size/2.0))\n",
    "        #output[4]=1.*(output[4]>=0)-1.*(output[4]<0)\n",
    "        #output[3]=output[3]+output[4]*output[6]\n",
    "    #print(\"First \",car_pos)\n",
    "    #cars=torch.cat([torch.cat([torch.tensor(0.), torch.tensor(10.), torch.tensor(0.), car_pos[i], torch.tensor(0.), torch.tensor(i)]) for i in range(nb_car)])\n",
    "    cars_i=torch.tensor([10.,0.])\n",
    "    #[car_data2[1],ped_data[2]>car_data2[3],(ped_data[2]-car_data2[3]),car_data2[4], car_data2[5]-car_data[5]]\n",
    "    if(nb_car>1):\n",
    "        cars=torch.cat([torch.tensor([10., 0.,0.,0., i-id_car]) for i in range(nb_car) if i!=id_car])\n",
    "        t=0\n",
    "        for i in range(nb_car):\n",
    "            if i!=id_car:\n",
    "                cars[(i-1*(id_car<i))*6+1]=(ped_pos[id_ped][0]>car_pos[i]).detach()\n",
    "                cars[(i-1*(id_car<i))*6+2]=(ped_pos[id_ped][0]-car_pos[i]).detach()\n",
    "                #cars[(i+1*(id_car<i))*6+3]=delta_l(10.0 ,car_pos[i],ped_pos[i][0]) not dl but light\n",
    "    #print(\"Second \",cars)\n",
    "    crossing, dist_start=is_in_cross(id_car,ped_pos[id_ped][1],ped_direction[id_ped],env_size,nb_lane)\n",
    "    end_cross, dist_end=leave_cross(id_car,ped_pos[id_ped][1],ped_direction[id_ped],env_size,nb_lane) \n",
    "    peds=torch.tensor([0.]*8)\n",
    "    peds[0]=ped_speed[id_ped][1].detach()\n",
    "    peds[1]=(ped_pos[id_ped][0]>car_pos[id_car]).detach()\n",
    "    peds[2]=(ped_pos[id_ped][0]-car_pos[id_car]).detach()\n",
    "    peds[3]=delta_l(10.0 ,car_pos[id_car],ped_pos[id_ped][0]).detach()\n",
    "    peds[4]=crossing\n",
    "    peds[5]=end_cross\n",
    "    peds[6]=dist_start\n",
    "    peds[7]=dist_end\n",
    "    #peds=torch.cat([torch.tensor([ped_speed[i][0], ped_speed[i][1], ped_pos[i][0], ped_pos[i][1],\n",
    "    #       torch.tensor(delta_l_all([10.0 for i in range(nb_car)],[car_pos[i] for i in range(nb_car)],ped_pos[i][0])),#[10.0 for i in range(nb_car)]\n",
    "    #       False, False, True, ped_direction[i]])  for i in range(nb_ped)])\n",
    "    # speed, is in front,diff position, light, line (5 data) manque position relative % au vehicule?\n",
    "    #car_data2[1],ped_data[2]>car_data2[3],(ped_data[2]-car_data2[3]), car_data2[4], car_data2[5]-car_data[5]\n",
    "    env=torch.tensor([env_size,nb_lane])\n",
    "    env[0]=env_size\n",
    "    #state={\"car\":cars, \"ped\":peds, \"env\":env}\n",
    "    #state_full=[]\n",
    "    #for i in list(cars):\n",
    "    #    state_full+=i\n",
    "    #for i in list(peds):\n",
    "    #    state_full+=i\n",
    "    #state_full+=env\n",
    "    #print(torch.cat([torch.tensor(i) for i in list(state.values())]))\n",
    "    if(nb_car>1):\n",
    "        return torch.cat([cars_i,cars,env,peds])\n",
    "    return torch.cat([cars_i,env,peds])#torch.tensor(, requires_grad=True)\n",
    "\n",
    "class Algo_PPO():\n",
    "    \"\"\" \n",
    "    PPO algorithm : training and testing\n",
    "    :param policy_class: policy (actor model)\n",
    "    :param env: environment\n",
    "    :param hyperparameters: other hyperparameters\n",
    "    \"\"\"\n",
    "    def __init__(self, policy_class, distrib_class, env, **hyperparameters):\n",
    "        \n",
    "        self._init_hyperparameters(hyperparameters)\n",
    "        self.max_steps=env.max_episode\n",
    "        #print(self.mean)\n",
    "        #print(self.std)\n",
    "        self.actor_net_cross = policy_class(self.num_states_c, self.num_actions, 1,\n",
    "                                            nb_car=self.nb_cars,mean=self.mean,std=self.std)\n",
    "        self.actor_net_wait = policy_class(self.num_states_c, self.num_actions, 1,\n",
    "                                           nb_car=self.nb_cars,mean=self.mean,std=self.std)\n",
    "        self.actor_net_choice = policy_class(self.num_states_d, 2, 2) # only one we need two nb_car\n",
    "        self.critic_net_cross = policy_class(self.num_states_c, 1, 0)\n",
    "        self.critic_net_wait = policy_class(self.num_states_c, 1, 0)\n",
    "        self.critic_net_choice = policy_class(self.num_states_d, 1, 0)\n",
    "        self.distribution = distrib_class(1,env.nb_ped*5+env.nb_car*1+1, env.nb_car, env.nb_ped)\n",
    "        self.optimizer_critic_cross = optim.Adam(self.critic_net_cross.parameters(), self.critic_lr)\n",
    "        self.optimizer_critic_wait = optim.Adam(self.critic_net_wait.parameters(), self.critic_lr)\n",
    "        self.optimizer_critic_choice = optim.Adam(self.critic_net_choice.parameters(), self.critic_d_lr)\n",
    "        self.optimizer_actor_cross = optim.Adam(self.actor_net_cross.parameters(), self.actor_lr)\n",
    "        self.optimizer_actor_wait = optim.Adam(self.actor_net_wait.parameters(), self.actor_lr)\n",
    "        self.optimizer_actor_choice = optim.Adam(self.actor_net_choice.parameters(), self.actor_d_lr)\n",
    "        self.optimizer_distribution = optim.Adam(self.distribution.parameters(), self.distribution_lr)\n",
    "        #self.change_std = 0.0\n",
    "        self.value_std = 0.5\n",
    "        self.value_std_d = 0.1\n",
    "        self.cov_var = torch.full(size=(self.num_actions,), fill_value=self.value_std)\n",
    "        self.cov_mat = torch.diag(self.cov_var)\n",
    "        self.cov_var_d = torch.full(size=(2*self.nb_cars,), fill_value=self.value_std_d)\n",
    "        self.cov_mat_d = torch.diag(self.cov_var_d)\n",
    "        self.rollout = Env_rollout(env, self.nb_cars, self.max_steps, self.dt)\n",
    "        self.ep_reward_cross=[]\n",
    "        self.ep_reward_wait=[]\n",
    "        self.ep_reward_choice=[]\n",
    "        self.ep_scenario_balance=[]\n",
    "    \n",
    "    def evaluate(self, nbr_episodes, random_distrib=False):\n",
    "        \"\"\"\n",
    "        Testing\n",
    "        :param nbr_episodes: episode number \n",
    "        :return: state batch, action batch, and reward batch\n",
    "        \"\"\"\n",
    "        self.rollout.reset()\n",
    "        state_batch, action_batch, rew_c_batch, rew_d_batch, time_stop_batch = self.rollout.iterations(self.actor_net_cross, self.actor_net_wait, self.actor_net_choice, self.distribution, nbr_episodes, random_distrib)\n",
    "        return state_batch, action_batch, rew_c_batch, rew_d_batch, time_stop_batch\n",
    "    \n",
    "    def evaluate_dataset(self, nbr_episodes):\n",
    "        \"\"\"\n",
    "        Testing\n",
    "        :param nbr_episodes: episode number \n",
    "        :return: state batch, action batch, and reward batch\n",
    "        \"\"\"\n",
    "        self.rollout.reset()\n",
    "        state_batch, action_batch, rew_c_batch, rew_d_batch, time_stop_batch = self.rollout.iterations_dataset(self.actor_net_cross, self.actor_net_wait, self.actor_net_choice, nbr_episodes)\n",
    "        #rew_cross_batch, rew_wait_batch, rew_choice_batch = self.rollounb_linesnb_linesnb_linesnb_linesnb_linesnb_linesnb_linesnb_linesnb_linest.immediate_rewards()\n",
    "        return state_batch, action_batch, rew_c_batch, rew_d_batch, time_stop_batch\n",
    "    \n",
    "    def tests_cross_wait(self):\n",
    "        \"\"\"\n",
    "        Testing\n",
    "        :return: state batch, action batch, and reward batch\n",
    "        \"\"\"\n",
    "        self.rollout.reset()\n",
    "        state_batch, action_batch, rew_c_batch, rew_d_batch = self.rollout.tests_cross_wait(self.actor_net_cross, self.actor_net_wait)\n",
    "        return state_batch, action_batch, rew_c_batch, rew_d_batch\n",
    "    \n",
    "    def tests_choice(self):\n",
    "        \"\"\"\n",
    "        Testing\n",
    "        :return: state batch, action batch, and reward batch\n",
    "        \"\"\"\n",
    "        self.rollout.reset()\n",
    "        state_batch, action_batch, rew_c_batch, rew_d_batch = self.rollout.tests_choice(self.actor_net_cross, self.actor_net_wait)\n",
    "        return state_batch, action_batch, rew_c_batch, rew_d_batch\n",
    "    \n",
    "    def train_distrib(self, model_d, critic, opti_model_d, state_batch, rtgs_batch):\n",
    "        #action_batch is the result of action train_distrib, probleme the critic is linked to each vehicle\\\n",
    "        # and we wand a common distribution model\n",
    "        print(\"State distrib \"+str(torch.tensor(state_batch).shape))\n",
    "        V_batch = torch.squeeze(critic(state_batch.float()))\n",
    "        V_batch=torch.sum(V_batch.reshape(-1,self.nb_cars),1)\n",
    "        rtgs_batch=torch.sum(rtgs_batch.reshape(-1,self.nb_cars),1)\n",
    "        print(V_batch.shape)\n",
    "        print(rtgs_batch.shape)\n",
    "        criterion=nn.MSELoss(reduction='mean')\n",
    "        model_d_loss = -criterion(V_batch.float(), rtgs_batch.float())\n",
    "        opti_model_d.zero_grad()\n",
    "        model_d_loss.backward()\n",
    "        opti_model_d.step()\n",
    "        \n",
    "    def train_model_c(self, actor, critic, opti_actor, opti_critic, state_batch, action_batch, log_prob_batch, rtgs_batch, cov_mat):\n",
    "        V_batch = torch.squeeze(critic(torch.tensor(state_batch).float()))\n",
    "        rtgs_batch=rtgs_batch.flatten()\n",
    "        advantage_batch = rtgs_batch - V_batch\n",
    "        advantage_batch = (advantage_batch - advantage_batch.mean()) / (advantage_batch.std() + 1e-10)\n",
    "\n",
    "        parameters_batch = torch.squeeze(actor(torch.tensor(state_batch).float()))\n",
    "        if(parameters_batch.dim()==1):\n",
    "            parameters_batch=torch.unsqueeze(parameters_batch, dim=1)\n",
    "        if(len(cov_mat)>1):\n",
    "            parameters_batch=parameters_batch.reshape(-1,len(cov_mat))\n",
    "            action_batch=torch.tensor(action_batch).reshape(-1,len(cov_mat))\n",
    "            \n",
    "        distribution_p = MultivariateNormal(parameters_batch, cov_mat)\n",
    "        log_prob_current_batch = distribution_p.log_prob(torch.tensor(action_batch))\n",
    "        ratio_batch = torch.exp(log_prob_current_batch - torch.tensor(log_prob_batch))\n",
    "        ratio_loss = torch.mul(ratio_batch, advantage_batch)\n",
    "        clip_loss = torch.mul(torch.clamp(ratio_batch, 0.8, 1.2), advantage_batch)\n",
    "        actor_loss = (-torch.min(ratio_loss, clip_loss)).mean()\n",
    "\n",
    "        criterion=nn.MSELoss(reduction='mean')\n",
    "        critic_loss = criterion(V_batch.float(), rtgs_batch.float())\n",
    "        opti_actor.zero_grad()\n",
    "        actor_loss.backward(retain_graph=True)\n",
    "        opti_actor.step()\n",
    "        opti_critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        opti_critic.step()\n",
    "        \n",
    "        \n",
    "    def train_model_d(self, actor, critic, opti_actor, opti_critic, state_batch, action_batch, log_prob_batch, rtgs_batch, cov_mat):\n",
    "        print(\"State \"+str(torch.tensor(state_batch).shape))#8000\n",
    "        #print(\"Action \"+str(torch.tensor(action_batch).shape))#16744\n",
    "        #print(\"Log \"+str(torch.tensor(log_prob_batch).shape))#8000\n",
    "        #print(\"Rtgs \"+str(torch.tensor(rtgs_batch).shape)) #8000\n",
    "        V_batch = torch.squeeze(critic(torch.tensor(state_batch).float()))\n",
    "        rtgs_batch=rtgs_batch.flatten()\n",
    "        advantage_batch = rtgs_batch - V_batch\n",
    "        advantage_batch = (advantage_batch - advantage_batch.mean()) / (advantage_batch.std() + 1e-10)\n",
    "\n",
    "        parameters_batch = torch.squeeze(actor(torch.tensor(state_batch).float()))\n",
    "        action_batch=torch.tensor(action_batch)#.reshape(-1,2)\n",
    "        if(parameters_batch.dim()==1):\n",
    "            parameters_batch=torch.unsqueeze(parameters_batch, dim=1)\n",
    "        parameters_batch=parameters_batch.reshape(-1,2)\n",
    "        \n",
    "        distribution_p=Categorical(parameters_batch)\n",
    "        #print(\"Parameters is \",parameters_batch.shape)\n",
    "        #print(\"Actions is \",action_batch.shape)\n",
    "        log_prob_current_batch = distribution_p.log_prob(torch.tensor(action_batch))\n",
    "        #print(\"Logs is \",log_prob_current_batch)\n",
    "        ratio_batch = torch.exp(log_prob_current_batch - torch.tensor(log_prob_batch))\n",
    "        ratio_loss = torch.mul(ratio_batch, advantage_batch)\n",
    "        clip_loss = torch.mul(torch.clamp(ratio_batch, 0.8, 1.2), advantage_batch)\n",
    "        actor_loss = (-torch.min(ratio_loss, clip_loss)).mean()\n",
    "\n",
    "        criterion=nn.MSELoss(reduction='mean')\n",
    "        critic_loss = criterion(V_batch.float(), rtgs_batch.float())\n",
    "        opti_actor.zero_grad()\n",
    "        actor_loss.backward(retain_graph=True)\n",
    "        opti_actor.step()\n",
    "        opti_critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        opti_critic.step()\n",
    "        \n",
    "        \n",
    "    def train(self, nb_loop):\n",
    "        \"\"\" \n",
    "        Training\n",
    "        :param nb_loop: number of batch iterations\n",
    "        \"\"\"\n",
    "        #self.change_std=self.value_std/float(nb_loop)\n",
    "        for ep in range(nb_loop):\n",
    "            self.rollout.reset()\n",
    "            random_rate=0.0\n",
    "            self.rollout.iterations_rand(self.actor_net_cross, self.actor_net_wait, self.actor_net_choice, self.distribution,\n",
    "                                         self.cov_mat, self.cov_mat_d, self.batch_size, random_rate)\n",
    "            rtgs_batch_cross, rtgs_batch_wait, rtgs_batch_choice = self.rollout.futur_rewards()\n",
    "            #print(rtgs_batch_cross.shape)\n",
    "            #print(rtgs_batch_wait.shape)\n",
    "            #print(rtgs_batch_choice.shape)\n",
    "            for i in range(10): # we could limit the learning if rew<constante\n",
    "                if(len(rtgs_batch_cross)>0):\n",
    "                    self.train_model_c(self.actor_net_cross, self.critic_net_cross, self.optimizer_actor_cross,\n",
    "                                       self.optimizer_critic_cross, np.array(self.rollout.batch_obs_cross),\n",
    "                                       np.array(self.rollout.batch_acts_cross), np.array(self.rollout.batch_log_probs_cross),\n",
    "                                       rtgs_batch_cross, self.cov_mat)\n",
    "                if(len(rtgs_batch_wait)>0):\n",
    "                    self.train_model_c(self.actor_net_wait, self.critic_net_wait, self.optimizer_actor_wait, self.optimizer_critic_wait,\n",
    "                                     np.array(self.rollout.batch_obs_wait), np.array(self.rollout.batch_acts_wait),\n",
    "                                     np.array(self.rollout.batch_log_probs_wait), rtgs_batch_wait, self.cov_mat)\n",
    "            #if(len(rtgs_batch_choice)>0): a voir pour apprendre qu'une seule fois\n",
    "            for i in range(10):\n",
    "                self.train_model_d(self.actor_net_choice, self.critic_net_choice, self.optimizer_actor_choice, self.optimizer_critic_choice,\n",
    "                                 np.array(self.rollout.batch_obs_choice), np.array(self.rollout.batch_acts_choice),\n",
    "                                 np.array(self.rollout.batch_log_probs_choice), rtgs_batch_choice, self.cov_mat_d)\n",
    "            #print(self.rollout.batch_obs_distrib)\n",
    "            #print(torch.cat(self.rollout.batch_obs_distrib).shape)\n",
    "            #print(torch.cat(self.rollout.batch_obs_distrib).reshape(-1,self.num_states_d).shape)\n",
    "            #print(np.array(self.rollout.batch_obs_choice))\n",
    "            self.train_distrib(self.distribution, self.critic_net_choice, self.optimizer_distribution,\n",
    "                               torch.cat(self.rollout.batch_obs_distrib).reshape(-1,self.num_states_d),\n",
    "                               rtgs_batch_choice)#batch_acts_distrib\n",
    "            #state_batch, action_c_batch, action_d_batch = self.rollout.iterations_step(self.actor_net_cross, self.actor_net_wait, self.actor_net_choice, 20)\n",
    "            rew_cross_batch, rew_wait_batch, rew_choice_batch = self.rollout.immediate_rewards()\n",
    "            #print(rew_cross_batch.shape)\n",
    "            #print(rew_wait_batch.shape)\n",
    "            #print(rew_choice_batch.shape)\n",
    "            if(len(rew_cross_batch)>0):\n",
    "                self.ep_reward_cross.append(rew_cross_batch.mean().numpy())\n",
    "                print(\"Cross not empty\")\n",
    "            if(len(rew_wait_batch)>0):\n",
    "                print(\"Wait not empty\")\n",
    "                self.ep_reward_wait.append(rew_wait_batch.mean().numpy())\n",
    "            self.ep_reward_choice.append(rew_choice_batch.mean().numpy())\n",
    "            print(\"Mean of choices\",rew_choice_batch.mean())\n",
    "            avg_reward_cross = np.mean(self.ep_reward_cross[-10:])\n",
    "            avg_reward_wait = np.mean(self.ep_reward_wait[-10:])\n",
    "            avg_reward_choice = np.mean(self.ep_reward_choice[-10:])\n",
    "            self.rollout.reset()\n",
    "            \n",
    "            print(\"Episode * {} * And Number of steps is ==> {}\".format(ep, ep*self.batch_size))\n",
    "            print(\"Average Cross reward is ==> {}, Average Wait reward is ==> {}\".format(avg_reward_cross, avg_reward_wait))\n",
    "            print(\"Average Choice reward is ==> {}\".format( avg_reward_choice))\n",
    "            print(\"Number Cross is ==> {} and Number Wait is ==> {} \".format(len(rew_cross_batch), len(rew_wait_batch)))\n",
    "            self.ep_scenario_balance.append([len(rew_cross_batch), len(rew_wait_batch)])\n",
    "            self.total_loop = self.total_loop +1\n",
    "        path='load_model/parameters/pappo-acc6-{num_algo:02d}-{name}-step-{epoch:03d}000.npy'\n",
    "        with open(path.format(num_algo=self.num_algo, epoch=int(self.total_loop/1000), name=\"reward_cross\"), 'wb') as f:\n",
    "            np.save(f, np.array(self.ep_reward_cross))\n",
    "        with open(path.format(num_algo=self.num_algo, epoch=int(self.total_loop/1000), name=\"reward_wait\"), 'wb') as f:\n",
    "            np.save(f, np.array(self.ep_reward_wait))\n",
    "        with open(path.format(num_algo=self.num_algo, epoch=int(self.total_loop/1000), name=\"reward_choice\"), 'wb') as f:\n",
    "            np.save(f, np.array(self.ep_reward_choice))\n",
    "        with open(path.format(num_algo=self.num_algo, epoch=int(self.total_loop/1000), name=\"scenario_balance\"), 'wb') as f:\n",
    "            np.save(f, np.array(self.ep_scenario_balance).reshape((-1,2)))\n",
    "        print(\"Complete\")\n",
    "        \n",
    "    def _init_hyperparameters(self, hyperparameters):\n",
    "        \"\"\"\n",
    "        Initialize hyperparameters. \n",
    "        :param hyperparameters: hyperparameter list\n",
    "        \"\"\"\n",
    "        self.num_algo = 1\n",
    "        self.total_loop = 0\n",
    "        self.batch_size = 2048\n",
    "        self.gamma = 0.99\n",
    "        self.critic_lr = 1e-3\n",
    "        self.actor_lr = 3e-4\n",
    "        self.critic_d_lr = 1e-3\n",
    "        self.actor_d_lr = 3e-4\n",
    "        self.distribution_lr = 1e-3\n",
    "        for param, val in hyperparameters.items():\n",
    "            exec('self.' + param + ' = ' + str(val)) #juste trop fort\n",
    "            \n",
    "    def loading(self, num_algo, total_loop):\n",
    "        \"\"\"\n",
    "        Loading NN weights \n",
    "        :param num_algo: algorithm number\n",
    "        :param total_loop: number of total batch iterations\n",
    "        \"\"\"\n",
    "        self.num_algo = num_algo\n",
    "        self.total_loop = total_loop\n",
    "        actor_cross_path = \"load_model/weights/pappo-SD-cross-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        actor_wait_path = \"load_model/weights/pappo-SD-wait-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        actor_choice_path = \"load_model/weights/pappo-SD-choice-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        critic_cross_path = \"load_model/weights/pappo-SD-cross-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        critic_wait_path = \"load_model/weights/pappo-SD-wait-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        critic_choice_path = \"load_model/weights/pappo-SD-choice-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        distrib_path = \"load_model/weights/pappo-SD-distrib-{num_algo:02d}-step-{epoch:03d}0.pth\"\n",
    "        #pappo-SD-cross-111-actor-step-1000.pth\n",
    "        self.actor_net_cross.load_state_dict(torch.load(actor_cross_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)))\n",
    "        self.actor_net_wait.load_state_dict(torch.load(actor_wait_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)))\n",
    "        self.actor_net_choice.load_state_dict(torch.load(actor_choice_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)))\n",
    "        self.critic_net_cross.load_state_dict(torch.load(critic_cross_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)))\n",
    "        self.critic_net_wait.load_state_dict(torch.load(critic_wait_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)))\n",
    "        self.critic_net_choice.load_state_dict(torch.load(critic_choice_path.format(epoch=int(self.total_loop/10),num_algo=self.num_algo)))\n",
    "        self.distribution.load_state_dict(torch.load(distrib_path.format(epoch=int(total_loop/10), num_algo=num_algo)))\n",
    "\n",
    "    def loading_curriculum(self, num_actor, num_algo, total_loop):\n",
    "        \"\"\"\n",
    "        Loading NN weights \n",
    "        :param num_algo: number of the algo\n",
    "        :param total_loop: number of total batch iterations\n",
    "        \"\"\"\n",
    "        self.total_loop = total_loop\n",
    "        if(num_actor==0):\n",
    "            actor_cross_path = \"load_model/weights/pappo-SD-cross-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "            critic_cross_path = \"load_model/weights/pappo-SD-cross-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "            self.actor_net_cross.load_state_dict(torch.load(actor_cross_path.format(epoch=int(total_loop/10),\n",
    "                                                                                    num_algo=num_algo)))\n",
    "            self.critic_net_cross.load_state_dict(torch.load(critic_cross_path.format(epoch=int(total_loop/10),\n",
    "                                                                                      num_algo=num_algo)))\n",
    "        if(num_actor==1):\n",
    "            actor_wait_path = \"load_model/weights/pappo-SD-wait-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "            critic_wait_path = \"load_model/weights/pappo-SD-wait-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "            self.actor_net_wait.load_state_dict(torch.load(actor_wait_path.format(epoch=int(total_loop/10),\n",
    "                                                                                  num_algo=num_algo)))\n",
    "            self.critic_net_wait.load_state_dict(torch.load(critic_wait_path.format(epoch=int(total_loop/10),\n",
    "                                                                                    num_algo=num_algo)))\n",
    "        if(num_actor==2):\n",
    "            actor_choice_path = \"load_model/weights/pappo-SD-choice-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "            critic_choice_path = \"load_model/weights/pappo-SD-choice-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "            distrib_path = \"load_model/weights/pappo-SD-distrib-{num_algo:02d}-step-{epoch:03d}0.pth\"\n",
    "            self.actor_net_choice.load_state_dict(torch.load(actor_choice_path.format(epoch=int(total_loop/10),\n",
    "                                                                                       num_algo=num_algo)))\n",
    "            self.critic_net_choice.load_state_dict(torch.load(critic_choice_path.format(epoch=int(total_loop/10),\n",
    "                                                                                          num_algo=num_algo)))\n",
    "            self.distribution.load_state_dict(torch.load(distrib_path.format(epoch=int(total_loop/10), num_algo=num_algo)))\n",
    "            \n",
    "    def saving(self):\n",
    "        \"\"\"\n",
    "        Saving NN weights \n",
    "        \"\"\"\n",
    "        actor_cross_path = \"load_model/weights/pappo-SD-cross-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        actor_wait_path = \"load_model/weights/pappo-SD-wait-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        actor_choice_path = \"load_model/weights/pappo-SD-choice-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        critic_cross_path = \"load_model/weights/pappo-SD-cross-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        critic_wait_path = \"load_model/weights/pappo-SD-wait-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        critic_choice_path = \"load_model/weights/pappo-SD-choice-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        distrib_path = \"load_model/weights/pappo-SD-distrib-{num_algo:02d}-step-{epoch:03d}0.pth\"\n",
    "        \n",
    "        torch.save(self.actor_net_cross.state_dict(), actor_cross_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo))\n",
    "        torch.save(self.actor_net_wait.state_dict(), actor_wait_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)) \n",
    "        torch.save(self.actor_net_choice.state_dict(), actor_choice_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo))\n",
    "        torch.save(self.critic_net_cross.state_dict(), critic_cross_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)) \n",
    "        torch.save(self.critic_net_wait.state_dict(), critic_wait_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo))\n",
    "        torch.save(self.critic_net_choice.state_dict(), critic_choice_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)) \n",
    "        torch.save(self.distribution.state_dict(), distrib_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)) \n",
    "\n",
    "#5) Computing part:\n",
    "# Import environment\n",
    "#problem = \"Crosswalk_hybrid_multi_opti7_3-v0\"\n",
    "#problem = \"Crosswalk_hybrid_multi_naif-v0\"\n",
    "problem = \"Crosswalk_hybrid_multi_naif-v0\"\n",
    "car_b = np.array([[ -4.0,  10.], [ 2.0, 10.]]) # acceleration and speed of the car\n",
    "ped_b = np.array([[ -0.05, 0.75, 0.0, -3.0], [ 0.05, 1.75, 4., -0.5]]) # speed x, y , position x, y of the pedestrian  [ajout 4 en 3]\n",
    "cross_b = np.array([2.5, 3.0]) # cross min/max, car nbr,  ped nbr\n",
    "print(\"Number of ped\")\n",
    "nb_ped=int(input())\n",
    "#nb_ped=1\n",
    "print(\"Number of car\")\n",
    "nb_car=int(input())\n",
    "#nb_car=1\n",
    "print(\"Number of lines\")\n",
    "nb_lines=int(input())\n",
    "#nb_lines=1\n",
    "print(\"Load model for continuous part?(input number)\")\n",
    "is_loading_c=int(input())\n",
    "print(\"Load model for discrete part?(input number)\")\n",
    "is_loading_d=int(input())\n",
    "print(\"Number steps\")\n",
    "data_size=int(input())\n",
    "\n",
    "max_episode=80\n",
    "env = gym.make(problem, car_b=car_b, ped_b= ped_b, cross_b=cross_b, nb_car=nb_car, nb_ped=nb_ped, nb_lines=nb_lines, dt=0.3,\n",
    "               max_episode=max_episode, simulation=\"sin\")\n",
    "#car_b, ped_b, cross_b, nb_car, nb_ped, nb_lines, dt, max_episode, simulation=\"unif\"\n",
    "#simulation=\"sin\")\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the algorithm\n",
    "num_states_c = 2+9+2#sum([int(env.observation_space[\"car\"].shape[0]/env.nb_car),\n",
    "                 #   int(env.observation_space[\"ped\"].shape[0]/env.nb_ped),\n",
    "                 #   int(env.observation_space[\"env\"].shape[0])])\n",
    "num_states_d = 2+(5*(nb_car-1))+8+2#+5*nb_ped#sum([int(env.observation_space[\"car\"].shape[0]/env.nb_car),\n",
    "                         #int(env.observation_space[\"ped\"].shape[0]),\n",
    "                         #int(env.observation_space[\"env\"].shape[0])])\n",
    "#= sum([math.prod(i.shape) for i in list(env.observation_space.values())])\n",
    "num_actions = 1 # env.action_space.shape[0]\n",
    "num_algo=100*nb_ped+10*nb_car+nb_lines\n",
    "\n",
    "mean =(car_b[1,0]+car_b[0,0])/2.0\n",
    "std =(car_b[1,0]-car_b[0,0])/2.0\n",
    "\n",
    "algo=Algo_PPO(Model_PPO, Model_SD, env, num_algo= num_algo, num_states_c=num_states_c, num_states_d=num_states_d, num_actions=num_actions,\n",
    "              mean=mean, std=std, nb_cars=nb_car, dt=0.3)\n",
    "#algo.loading(1,1000)\n",
    "if(is_loading_c):\n",
    "    algo.loading_curriculum(0,is_loading_c,data_size)\n",
    "    algo.loading_curriculum(1,is_loading_c,data_size)\n",
    "    \n",
    "if(is_loading_d):\n",
    "    algo.loading_curriculum(2,is_loading_d,data_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "885fc85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1)[0]<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360fbbab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-43.5143)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * And Number of steps is ==> 0\n",
      "Average Cross reward is ==> -7.710545063018799, Average Wait reward is ==> -37.26577377319336\n",
      "Average Choice reward is ==> -43.51432800292969\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-29.1464)\n",
      "Episode * 1 * And Number of steps is ==> 2048\n",
      "Average Cross reward is ==> -7.725187301635742, Average Wait reward is ==> -36.029842376708984\n",
      "Average Choice reward is ==> -36.330387115478516\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-20.7812)\n",
      "Episode * 2 * And Number of steps is ==> 4096\n",
      "Average Cross reward is ==> -7.627871036529541, Average Wait reward is ==> -34.889163970947266\n",
      "Average Choice reward is ==> -31.147323608398438\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-16.3722)\n",
      "Episode * 3 * And Number of steps is ==> 6144\n",
      "Average Cross reward is ==> -7.5575690269470215, Average Wait reward is ==> -33.819908142089844\n",
      "Average Choice reward is ==> -27.453533172607422\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-13.5929)\n",
      "Episode * 4 * And Number of steps is ==> 8192\n",
      "Average Cross reward is ==> -7.499310493469238, Average Wait reward is ==> -33.28263473510742\n",
      "Average Choice reward is ==> -24.68140411376953\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-8.7783)\n",
      "Episode * 5 * And Number of steps is ==> 10240\n",
      "Average Cross reward is ==> -7.367391109466553, Average Wait reward is ==> -32.474124908447266\n",
      "Average Choice reward is ==> -22.030885696411133\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-7.2169)\n",
      "Episode * 6 * And Number of steps is ==> 12288\n",
      "Average Cross reward is ==> -7.283505916595459, Average Wait reward is ==> -31.44611167907715\n",
      "Average Choice reward is ==> -19.914596557617188\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-7.9900)\n",
      "Episode * 7 * And Number of steps is ==> 14336\n",
      "Average Cross reward is ==> -7.191326141357422, Average Wait reward is ==> -30.534759521484375\n",
      "Average Choice reward is ==> -18.42402458190918\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-3.9501)\n",
      "Episode * 8 * And Number of steps is ==> 16384\n",
      "Average Cross reward is ==> -7.104005336761475, Average Wait reward is ==> -29.2978515625\n",
      "Average Choice reward is ==> -16.815814971923828\n",
      "Number Cross is ==> 1440 and Number Wait is ==> 2720 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-2.2554)\n",
      "Episode * 9 * And Number of steps is ==> 18432\n",
      "Average Cross reward is ==> -6.964673042297363, Average Wait reward is ==> -27.8200626373291\n",
      "Average Choice reward is ==> -15.359773635864258\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.7973)\n",
      "Episode * 10 * And Number of steps is ==> 20480\n",
      "Average Cross reward is ==> -6.752504825592041, Average Wait reward is ==> -25.183443069458008\n",
      "Average Choice reward is ==> -11.188069343566895\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6823)\n",
      "Episode * 11 * And Number of steps is ==> 22528\n",
      "Average Cross reward is ==> -6.519797325134277, Average Wait reward is ==> -22.673606872558594\n",
      "Average Choice reward is ==> -8.441649436950684\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5263)\n",
      "Episode * 12 * And Number of steps is ==> 24576\n",
      "Average Cross reward is ==> -6.301977157592773, Average Wait reward is ==> -20.185466766357422\n",
      "Average Choice reward is ==> -6.5161590576171875\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5749)\n",
      "Episode * 13 * And Number of steps is ==> 26624\n",
      "Average Cross reward is ==> -6.1157121658325195, Average Wait reward is ==> -18.004356384277344\n",
      "Average Choice reward is ==> -5.036433219909668\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6994)\n",
      "Episode * 14 * And Number of steps is ==> 28672\n",
      "Average Cross reward is ==> -5.883879661560059, Average Wait reward is ==> -15.718953132629395\n",
      "Average Choice reward is ==> -3.8470821380615234\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.9468)\n",
      "Episode * 15 * And Number of steps is ==> 30720\n",
      "Average Cross reward is ==> -5.686044692993164, Average Wait reward is ==> -13.801709175109863\n",
      "Average Choice reward is ==> -3.1639339923858643\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4975)\n",
      "Episode * 16 * And Number of steps is ==> 32768\n",
      "Average Cross reward is ==> -5.4528093338012695, Average Wait reward is ==> -12.036779403686523\n",
      "Average Choice reward is ==> -2.591996908187866\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3387)\n",
      "Episode * 17 * And Number of steps is ==> 34816\n",
      "Average Cross reward is ==> -5.210293292999268, Average Wait reward is ==> -10.507085800170898\n",
      "Average Choice reward is ==> -1.9268604516983032\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5265)\n",
      "Episode * 18 * And Number of steps is ==> 36864\n",
      "Average Cross reward is ==> -4.970961570739746, Average Wait reward is ==> -9.338132858276367\n",
      "Average Choice reward is ==> -1.6844961643218994\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.7402)\n",
      "Episode * 19 * And Number of steps is ==> 38912\n",
      "Average Cross reward is ==> -4.782287120819092, Average Wait reward is ==> -8.599359512329102\n",
      "Average Choice reward is ==> -1.6329787969589233\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4023)\n",
      "Episode * 20 * And Number of steps is ==> 40960\n",
      "Average Cross reward is ==> -4.608680248260498, Average Wait reward is ==> -8.17839241027832\n",
      "Average Choice reward is ==> -1.5934805870056152\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6058)\n",
      "Episode * 21 * And Number of steps is ==> 43008\n",
      "Average Cross reward is ==> -4.443041801452637, Average Wait reward is ==> -7.912269592285156\n",
      "Average Choice reward is ==> -1.5858350992202759\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4836)\n",
      "Episode * 22 * And Number of steps is ==> 45056\n",
      "Average Cross reward is ==> -4.29113245010376, Average Wait reward is ==> -7.852532386779785\n",
      "Average Choice reward is ==> -1.5815616846084595\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5607)\n",
      "Episode * 23 * And Number of steps is ==> 47104\n",
      "Average Cross reward is ==> -4.09827184677124, Average Wait reward is ==> -7.6152472496032715\n",
      "Average Choice reward is ==> -1.5801420211791992\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4514)\n",
      "Episode * 24 * And Number of steps is ==> 49152\n",
      "Average Cross reward is ==> -3.959160566329956, Average Wait reward is ==> -7.37795877456665\n",
      "Average Choice reward is ==> -1.5553439855575562\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2560)\n",
      "Episode * 25 * And Number of steps is ==> 51200\n",
      "Average Cross reward is ==> -3.831805467605591, Average Wait reward is ==> -7.006868839263916\n",
      "Average Choice reward is ==> -1.4862635135650635\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6188)\n",
      "Episode * 26 * And Number of steps is ==> 53248\n",
      "Average Cross reward is ==> -3.732635974884033, Average Wait reward is ==> -6.81366491317749\n",
      "Average Choice reward is ==> -1.4984002113342285\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3820)\n",
      "Episode * 27 * And Number of steps is ==> 55296\n",
      "Average Cross reward is ==> -3.6599411964416504, Average Wait reward is ==> -6.455521583557129\n",
      "Average Choice reward is ==> -1.502730131149292\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4906)\n",
      "Episode * 28 * And Number of steps is ==> 57344\n",
      "Average Cross reward is ==> -3.584054946899414, Average Wait reward is ==> -6.346839904785156\n",
      "Average Choice reward is ==> -1.499138593673706\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0436)\n",
      "Episode * 29 * And Number of steps is ==> 59392\n",
      "Average Cross reward is ==> -3.5272223949432373, Average Wait reward is ==> -6.149243354797363\n",
      "Average Choice reward is ==> -1.4294774532318115\n",
      "Number Cross is ==> 1200 and Number Wait is ==> 2960 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.9065)\n",
      "Episode * 30 * And Number of steps is ==> 61440\n",
      "Average Cross reward is ==> -3.4438910484313965, Average Wait reward is ==> -5.980992794036865\n",
      "Average Choice reward is ==> -1.4798965454101562\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4431)\n",
      "Episode * 31 * And Number of steps is ==> 63488\n",
      "Average Cross reward is ==> -3.3846347332000732, Average Wait reward is ==> -5.742362022399902\n",
      "Average Choice reward is ==> -1.4636250734329224\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2515)\n",
      "Episode * 32 * And Number of steps is ==> 65536\n",
      "Average Cross reward is ==> -3.3101565837860107, Average Wait reward is ==> -5.518627643585205\n",
      "Average Choice reward is ==> -1.4404176473617554\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3257)\n",
      "Episode * 33 * And Number of steps is ==> 67584\n",
      "Average Cross reward is ==> -3.23087739944458, Average Wait reward is ==> -5.472479820251465\n",
      "Average Choice reward is ==> -1.4169152975082397\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4577)\n",
      "Episode * 34 * And Number of steps is ==> 69632\n",
      "Average Cross reward is ==> -3.1419224739074707, Average Wait reward is ==> -5.387343406677246\n",
      "Average Choice reward is ==> -1.417547345161438\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.8663)\n",
      "Episode * 35 * And Number of steps is ==> 71680\n",
      "Average Cross reward is ==> -3.0597643852233887, Average Wait reward is ==> -5.3015031814575195\n",
      "Average Choice reward is ==> -1.4785810708999634\n",
      "Number Cross is ==> 2640 and Number Wait is ==> 1520 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6138)\n",
      "Episode * 36 * And Number of steps is ==> 73728\n",
      "Average Cross reward is ==> -2.962116241455078, Average Wait reward is ==> -5.252856254577637\n",
      "Average Choice reward is ==> -1.4780741930007935\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0173)\n",
      "Episode * 37 * And Number of steps is ==> 75776\n",
      "Average Cross reward is ==> -2.8635144233703613, Average Wait reward is ==> -5.162235260009766\n",
      "Average Choice reward is ==> -1.4416093826293945\n",
      "Number Cross is ==> 1280 and Number Wait is ==> 2880 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2221)\n",
      "Episode * 38 * And Number of steps is ==> 77824\n",
      "Average Cross reward is ==> -2.730935573577881, Average Wait reward is ==> -4.920405387878418\n",
      "Average Choice reward is ==> -1.414764642715454\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3663)\n",
      "Episode * 39 * And Number of steps is ==> 79872\n",
      "Average Cross reward is ==> -2.5757274627685547, Average Wait reward is ==> -4.821117401123047\n",
      "Average Choice reward is ==> -1.4470384120941162\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3195)\n",
      "Episode * 40 * And Number of steps is ==> 81920\n",
      "Average Cross reward is ==> -2.4022607803344727, Average Wait reward is ==> -4.722990989685059\n",
      "Average Choice reward is ==> -1.388339877128601\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3414)\n",
      "Episode * 41 * And Number of steps is ==> 83968\n",
      "Average Cross reward is ==> -2.2005035877227783, Average Wait reward is ==> -4.665614128112793\n",
      "Average Choice reward is ==> -1.3781684637069702\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5068)\n",
      "Episode * 42 * And Number of steps is ==> 86016\n",
      "Average Cross reward is ==> -2.0214931964874268, Average Wait reward is ==> -4.547841548919678\n",
      "Average Choice reward is ==> -1.403700828552246\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5261)\n",
      "Episode * 43 * And Number of steps is ==> 88064\n",
      "Average Cross reward is ==> -1.8475421667099, Average Wait reward is ==> -4.329944610595703\n",
      "Average Choice reward is ==> -1.423747181892395\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3347)\n",
      "Episode * 44 * And Number of steps is ==> 90112\n",
      "Average Cross reward is ==> -1.6592435836791992, Average Wait reward is ==> -4.1721906661987305\n",
      "Average Choice reward is ==> -1.4114490747451782\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6675)\n",
      "Episode * 45 * And Number of steps is ==> 92160\n",
      "Average Cross reward is ==> -1.5119788646697998, Average Wait reward is ==> -4.038753032684326\n",
      "Average Choice reward is ==> -1.3915672302246094\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.8342)\n",
      "Episode * 46 * And Number of steps is ==> 94208\n",
      "Average Cross reward is ==> -1.3593682050704956, Average Wait reward is ==> -4.020356178283691\n",
      "Average Choice reward is ==> -1.4136093854904175\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6760)\n",
      "Episode * 47 * And Number of steps is ==> 96256\n",
      "Average Cross reward is ==> -1.2007290124893188, Average Wait reward is ==> -3.909839153289795\n",
      "Average Choice reward is ==> -1.4794751405715942\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4973)\n",
      "Episode * 48 * And Number of steps is ==> 98304\n",
      "Average Cross reward is ==> -1.092894196510315, Average Wait reward is ==> -3.8211727142333984\n",
      "Average Choice reward is ==> -1.5069940090179443\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4044)\n",
      "Episode * 49 * And Number of steps is ==> 100352\n",
      "Average Cross reward is ==> -1.0016671419143677, Average Wait reward is ==> -3.7022266387939453\n",
      "Average Choice reward is ==> -1.510802149772644\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4632)\n",
      "Episode * 50 * And Number of steps is ==> 102400\n",
      "Average Cross reward is ==> -0.9522435069084167, Average Wait reward is ==> -3.6035048961639404\n",
      "Average Choice reward is ==> -1.5251684188842773\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3148)\n",
      "Episode * 51 * And Number of steps is ==> 104448\n",
      "Average Cross reward is ==> -0.9026614427566528, Average Wait reward is ==> -3.4518871307373047\n",
      "Average Choice reward is ==> -1.5225152969360352\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3033)\n",
      "Episode * 52 * And Number of steps is ==> 106496\n",
      "Average Cross reward is ==> -0.8375642895698547, Average Wait reward is ==> -3.495856523513794\n",
      "Average Choice reward is ==> -1.5021617412567139\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3367)\n",
      "Episode * 53 * And Number of steps is ==> 108544\n",
      "Average Cross reward is ==> -0.8005754351615906, Average Wait reward is ==> -3.3819801807403564\n",
      "Average Choice reward is ==> -1.4832160472869873\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1692)\n",
      "Episode * 54 * And Number of steps is ==> 110592\n",
      "Average Cross reward is ==> -0.7952655553817749, Average Wait reward is ==> -3.272784471511841\n",
      "Average Choice reward is ==> -1.4666669368743896\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6966)\n",
      "Episode * 55 * And Number of steps is ==> 112640\n",
      "Average Cross reward is ==> -0.7461730241775513, Average Wait reward is ==> -3.2497754096984863\n",
      "Average Choice reward is ==> -1.4695723056793213\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2188)\n",
      "Episode * 56 * And Number of steps is ==> 114688\n",
      "Average Cross reward is ==> -0.7183186411857605, Average Wait reward is ==> -3.0381553173065186\n",
      "Average Choice reward is ==> -1.4080301523208618\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4048)\n",
      "Episode * 57 * And Number of steps is ==> 116736\n",
      "Average Cross reward is ==> -0.6956325769424438, Average Wait reward is ==> -2.971369981765747\n",
      "Average Choice reward is ==> -1.3809144496917725\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9731)\n",
      "Episode * 58 * And Number of steps is ==> 118784\n",
      "Average Cross reward is ==> -0.6732767820358276, Average Wait reward is ==> -2.9222116470336914\n",
      "Average Choice reward is ==> -1.3284881114959717\n",
      "Number Cross is ==> 1360 and Number Wait is ==> 2800 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6412)\n",
      "Episode * 59 * And Number of steps is ==> 120832\n",
      "Average Cross reward is ==> -0.6551135778427124, Average Wait reward is ==> -2.968676805496216\n",
      "Average Choice reward is ==> -1.3521640300750732\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5606)\n",
      "Episode * 60 * And Number of steps is ==> 122880\n",
      "Average Cross reward is ==> -0.6374230980873108, Average Wait reward is ==> -2.9449474811553955\n",
      "Average Choice reward is ==> -1.3619048595428467\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4222)\n",
      "Episode * 61 * And Number of steps is ==> 124928\n",
      "Average Cross reward is ==> -0.639025092124939, Average Wait reward is ==> -2.9352622032165527\n",
      "Average Choice reward is ==> -1.3726446628570557\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.9000)\n",
      "Episode * 62 * And Number of steps is ==> 126976\n",
      "Average Cross reward is ==> -0.6424387693405151, Average Wait reward is ==> -2.773468494415283\n",
      "Average Choice reward is ==> -1.432318925857544\n",
      "Number Cross is ==> 2720 and Number Wait is ==> 1440 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6971)\n",
      "Episode * 63 * And Number of steps is ==> 129024\n",
      "Average Cross reward is ==> -0.6318935751914978, Average Wait reward is ==> -2.7404088973999023\n",
      "Average Choice reward is ==> -1.4683613777160645\n",
      "Number Cross is ==> 2640 and Number Wait is ==> 1520 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5025)\n",
      "Episode * 64 * And Number of steps is ==> 131072\n",
      "Average Cross reward is ==> -0.6100515723228455, Average Wait reward is ==> -2.7430453300476074\n",
      "Average Choice reward is ==> -1.501690149307251\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3808)\n",
      "Episode * 65 * And Number of steps is ==> 133120\n",
      "Average Cross reward is ==> -0.5956180691719055, Average Wait reward is ==> -2.641770124435425\n",
      "Average Choice reward is ==> -1.470109462738037\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6270)\n",
      "Episode * 66 * And Number of steps is ==> 135168\n",
      "Average Cross reward is ==> -0.5780907273292542, Average Wait reward is ==> -2.583531618118286\n",
      "Average Choice reward is ==> -1.5109283924102783\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6587)\n",
      "Episode * 67 * And Number of steps is ==> 137216\n",
      "Average Cross reward is ==> -0.5648797750473022, Average Wait reward is ==> -2.575923204421997\n",
      "Average Choice reward is ==> -1.5363129377365112\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3280)\n",
      "Episode * 68 * And Number of steps is ==> 139264\n",
      "Average Cross reward is ==> -0.5693784952163696, Average Wait reward is ==> -2.573699474334717\n",
      "Average Choice reward is ==> -1.5718098878860474\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3353)\n",
      "Episode * 69 * And Number of steps is ==> 141312\n",
      "Average Cross reward is ==> -0.5487484931945801, Average Wait reward is ==> -2.458055257797241\n",
      "Average Choice reward is ==> -1.541223406791687\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.7188)\n",
      "Episode * 70 * And Number of steps is ==> 143360\n",
      "Average Cross reward is ==> -0.5373505353927612, Average Wait reward is ==> -2.40116810798645\n",
      "Average Choice reward is ==> -1.5570495128631592\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1971)\n",
      "Episode * 71 * And Number of steps is ==> 145408\n",
      "Average Cross reward is ==> -0.5072892904281616, Average Wait reward is ==> -2.3732497692108154\n",
      "Average Choice reward is ==> -1.5345369577407837\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4794)\n",
      "Episode * 72 * And Number of steps is ==> 147456\n",
      "Average Cross reward is ==> -0.4995940625667572, Average Wait reward is ==> -2.3226726055145264\n",
      "Average Choice reward is ==> -1.4924721717834473\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2183)\n",
      "Episode * 73 * And Number of steps is ==> 149504\n",
      "Average Cross reward is ==> -0.47420182824134827, Average Wait reward is ==> -2.2963736057281494\n",
      "Average Choice reward is ==> -1.4445875883102417\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3635)\n",
      "Episode * 74 * And Number of steps is ==> 151552\n",
      "Average Cross reward is ==> -0.4505015015602112, Average Wait reward is ==> -2.2699129581451416\n",
      "Average Choice reward is ==> -1.430680513381958\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5472)\n",
      "Episode * 75 * And Number of steps is ==> 153600\n",
      "Average Cross reward is ==> -0.43244868516921997, Average Wait reward is ==> -2.278627872467041\n",
      "Average Choice reward is ==> -1.4473247528076172\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4356)\n",
      "Episode * 76 * And Number of steps is ==> 155648\n",
      "Average Cross reward is ==> -0.4143557548522949, Average Wait reward is ==> -2.244525194168091\n",
      "Average Choice reward is ==> -1.4281857013702393\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3654)\n",
      "Episode * 77 * And Number of steps is ==> 157696\n",
      "Average Cross reward is ==> -0.3974906802177429, Average Wait reward is ==> -2.1978182792663574\n",
      "Average Choice reward is ==> -1.398858904838562\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2537)\n",
      "Episode * 78 * And Number of steps is ==> 159744\n",
      "Average Cross reward is ==> -0.3560830354690552, Average Wait reward is ==> -2.095353603363037\n",
      "Average Choice reward is ==> -1.3914268016815186\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1913)\n",
      "Episode * 79 * And Number of steps is ==> 161792\n",
      "Average Cross reward is ==> -0.33763882517814636, Average Wait reward is ==> -2.0949230194091797\n",
      "Average Choice reward is ==> -1.3770242929458618\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9042)\n",
      "Episode * 80 * And Number of steps is ==> 163840\n",
      "Average Cross reward is ==> -0.3079482913017273, Average Wait reward is ==> -2.050262212753296\n",
      "Average Choice reward is ==> -1.295562505722046\n",
      "Number Cross is ==> 1360 and Number Wait is ==> 2800 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5742)\n",
      "Episode * 81 * And Number of steps is ==> 165888\n",
      "Average Cross reward is ==> -0.28606849908828735, Average Wait reward is ==> -2.0543594360351562\n",
      "Average Choice reward is ==> -1.3332667350769043\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2991)\n",
      "Episode * 82 * And Number of steps is ==> 167936\n",
      "Average Cross reward is ==> -0.2557641565799713, Average Wait reward is ==> -2.0578815937042236\n",
      "Average Choice reward is ==> -1.3152374029159546\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4347)\n",
      "Episode * 83 * And Number of steps is ==> 169984\n",
      "Average Cross reward is ==> -0.2411688268184662, Average Wait reward is ==> -2.0123493671417236\n",
      "Average Choice reward is ==> -1.3368850946426392\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2835)\n",
      "Episode * 84 * And Number of steps is ==> 172032\n",
      "Average Cross reward is ==> -0.2234380543231964, Average Wait reward is ==> -1.983263373374939\n",
      "Average Choice reward is ==> -1.3288919925689697\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1488)\n",
      "Episode * 85 * And Number of steps is ==> 174080\n",
      "Average Cross reward is ==> -0.19995960593223572, Average Wait reward is ==> -1.9372053146362305\n",
      "Average Choice reward is ==> -1.289050817489624\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.5302)\n",
      "Episode * 86 * And Number of steps is ==> 176128\n",
      "Average Cross reward is ==> -0.17670464515686035, Average Wait reward is ==> -1.919885277748108\n",
      "Average Choice reward is ==> -1.2985100746154785\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3075)\n",
      "Episode * 87 * And Number of steps is ==> 178176\n",
      "Average Cross reward is ==> -0.15666727721691132, Average Wait reward is ==> -1.8902782201766968\n",
      "Average Choice reward is ==> -1.2927166223526\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2388)\n",
      "Episode * 88 * And Number of steps is ==> 180224\n",
      "Average Cross reward is ==> -0.13911333680152893, Average Wait reward is ==> -2.1188082695007324\n",
      "Average Choice reward is ==> -1.2912280559539795\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2659)\n",
      "Episode * 89 * And Number of steps is ==> 182272\n",
      "Average Cross reward is ==> -0.12396500259637833, Average Wait reward is ==> -2.170827627182007\n",
      "Average Choice reward is ==> -1.298685073852539\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3631)\n",
      "Episode * 90 * And Number of steps is ==> 184320\n",
      "Average Cross reward is ==> -0.10756585747003555, Average Wait reward is ==> -2.1871209144592285\n",
      "Average Choice reward is ==> -1.3445707559585571\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9783)\n",
      "Episode * 91 * And Number of steps is ==> 186368\n",
      "Average Cross reward is ==> -0.09752774238586426, Average Wait reward is ==> -2.151829719543457\n",
      "Average Choice reward is ==> -1.2849886417388916\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3080)\n",
      "Episode * 92 * And Number of steps is ==> 188416\n",
      "Average Cross reward is ==> -0.08211979269981384, Average Wait reward is ==> -2.211045026779175\n",
      "Average Choice reward is ==> -1.285876750946045\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1957)\n",
      "Episode * 93 * And Number of steps is ==> 190464\n",
      "Average Cross reward is ==> -0.07042548805475235, Average Wait reward is ==> -2.2290873527526855\n",
      "Average Choice reward is ==> -1.2619695663452148\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1794)\n",
      "Episode * 94 * And Number of steps is ==> 192512\n",
      "Average Cross reward is ==> -0.06376171112060547, Average Wait reward is ==> -2.2434258460998535\n",
      "Average Choice reward is ==> -1.2515513896942139\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2271)\n",
      "Episode * 95 * And Number of steps is ==> 194560\n",
      "Average Cross reward is ==> -0.05581345036625862, Average Wait reward is ==> -2.2601511478424072\n",
      "Average Choice reward is ==> -1.2593809366226196\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2480)\n",
      "Episode * 96 * And Number of steps is ==> 196608\n",
      "Average Cross reward is ==> -0.050251554697752, Average Wait reward is ==> -2.247781753540039\n",
      "Average Choice reward is ==> -1.231166958808899\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3665)\n",
      "Episode * 97 * And Number of steps is ==> 198656\n",
      "Average Cross reward is ==> -0.04348856955766678, Average Wait reward is ==> -2.2478389739990234\n",
      "Average Choice reward is ==> -1.2370697259902954\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2477)\n",
      "Episode * 98 * And Number of steps is ==> 200704\n",
      "Average Cross reward is ==> -0.03756288066506386, Average Wait reward is ==> -1.997603416442871\n",
      "Average Choice reward is ==> -1.2379543781280518\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9363)\n",
      "Episode * 99 * And Number of steps is ==> 202752\n",
      "Average Cross reward is ==> -0.033664949238300323, Average Wait reward is ==> -1.933504343032837\n",
      "Average Choice reward is ==> -1.2049956321716309\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1353)\n",
      "Episode * 100 * And Number of steps is ==> 204800\n",
      "Average Cross reward is ==> -0.03259962052106857, Average Wait reward is ==> -1.9675190448760986\n",
      "Average Choice reward is ==> -1.1822197437286377\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1666)\n",
      "Episode * 101 * And Number of steps is ==> 206848\n",
      "Average Cross reward is ==> -0.031619247049093246, Average Wait reward is ==> -2.011643648147583\n",
      "Average Choice reward is ==> -1.2010465860366821\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1583)\n",
      "Episode * 102 * And Number of steps is ==> 208896\n",
      "Average Cross reward is ==> -0.029201453551650047, Average Wait reward is ==> -1.9075708389282227\n",
      "Average Choice reward is ==> -1.1860861778259277\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4630)\n",
      "Episode * 103 * And Number of steps is ==> 210944\n",
      "Average Cross reward is ==> -0.028559986501932144, Average Wait reward is ==> -1.9230035543441772\n",
      "Average Choice reward is ==> -1.212821125984192\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0923)\n",
      "Episode * 104 * And Number of steps is ==> 212992\n",
      "Average Cross reward is ==> -0.028077367693185806, Average Wait reward is ==> -2.0235371589660645\n",
      "Average Choice reward is ==> -1.2041139602661133\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4329)\n",
      "Episode * 105 * And Number of steps is ==> 215040\n",
      "Average Cross reward is ==> -0.02728310599923134, Average Wait reward is ==> -2.147645950317383\n",
      "Average Choice reward is ==> -1.2246956825256348\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4408)\n",
      "Episode * 106 * And Number of steps is ==> 217088\n",
      "Average Cross reward is ==> -0.02648591436445713, Average Wait reward is ==> -2.2022218704223633\n",
      "Average Choice reward is ==> -1.2439709901809692\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1521)\n",
      "Episode * 107 * And Number of steps is ==> 219136\n",
      "Average Cross reward is ==> -0.02609694004058838, Average Wait reward is ==> -2.221229076385498\n",
      "Average Choice reward is ==> -1.2225347757339478\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1373)\n",
      "Episode * 108 * And Number of steps is ==> 221184\n",
      "Average Cross reward is ==> -0.026194855570793152, Average Wait reward is ==> -2.2563047409057617\n",
      "Average Choice reward is ==> -1.2115023136138916\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.6184)\n",
      "Episode * 109 * And Number of steps is ==> 223232\n",
      "Average Cross reward is ==> -0.025332752615213394, Average Wait reward is ==> -2.201260805130005\n",
      "Average Choice reward is ==> -1.1797187328338623\n",
      "Number Cross is ==> 1120 and Number Wait is ==> 3040 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2687)\n",
      "Episode * 110 * And Number of steps is ==> 225280\n",
      "Average Cross reward is ==> -0.024444006383419037, Average Wait reward is ==> -2.169978618621826\n",
      "Average Choice reward is ==> -1.1930516958236694\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8686)\n",
      "Episode * 111 * And Number of steps is ==> 227328\n",
      "Average Cross reward is ==> -0.02300085686147213, Average Wait reward is ==> -2.263953685760498\n",
      "Average Choice reward is ==> -1.163251280784607\n",
      "Number Cross is ==> 1440 and Number Wait is ==> 2720 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1058)\n",
      "Episode * 112 * And Number of steps is ==> 229376\n",
      "Average Cross reward is ==> -0.02232307568192482, Average Wait reward is ==> -2.321535348892212\n",
      "Average Choice reward is ==> -1.158001184463501\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3804)\n",
      "Episode * 113 * And Number of steps is ==> 231424\n",
      "Average Cross reward is ==> -0.02215496078133583, Average Wait reward is ==> -2.305318593978882\n",
      "Average Choice reward is ==> -1.1497350931167603\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0187)\n",
      "Episode * 114 * And Number of steps is ==> 233472\n",
      "Average Cross reward is ==> -0.021274704486131668, Average Wait reward is ==> -2.1633925437927246\n",
      "Average Choice reward is ==> -1.1423752307891846\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.6188)\n",
      "Episode * 115 * And Number of steps is ==> 235520\n",
      "Average Cross reward is ==> -0.02058699168264866, Average Wait reward is ==> -2.048210859298706\n",
      "Average Choice reward is ==> -1.1609618663787842\n",
      "Number Cross is ==> 2720 and Number Wait is ==> 1440 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2139)\n",
      "Episode * 116 * And Number of steps is ==> 237568\n",
      "Average Cross reward is ==> -0.020250024273991585, Average Wait reward is ==> -2.0184457302093506\n",
      "Average Choice reward is ==> -1.1382720470428467\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1209)\n",
      "Episode * 117 * And Number of steps is ==> 239616\n",
      "Average Cross reward is ==> -0.01969030871987343, Average Wait reward is ==> -2.037360668182373\n",
      "Average Choice reward is ==> -1.135149598121643\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8923)\n",
      "Episode * 118 * And Number of steps is ==> 241664\n",
      "Average Cross reward is ==> -0.018818343058228493, Average Wait reward is ==> -2.0009560585021973\n",
      "Average Choice reward is ==> -1.1106441020965576\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1660)\n",
      "Episode * 119 * And Number of steps is ==> 243712\n",
      "Average Cross reward is ==> -0.01856059767305851, Average Wait reward is ==> -2.0320680141448975\n",
      "Average Choice reward is ==> -1.1653980016708374\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1829)\n",
      "Episode * 120 * And Number of steps is ==> 245760\n",
      "Average Cross reward is ==> -0.018095191568136215, Average Wait reward is ==> -2.169290065765381\n",
      "Average Choice reward is ==> -1.156827688217163\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4122)\n",
      "Episode * 121 * And Number of steps is ==> 247808\n",
      "Average Cross reward is ==> -0.017205581068992615, Average Wait reward is ==> -2.0185818672180176\n",
      "Average Choice reward is ==> -1.2111835479736328\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9434)\n",
      "Episode * 122 * And Number of steps is ==> 249856\n",
      "Average Cross reward is ==> -0.01671275496482849, Average Wait reward is ==> -1.9629552364349365\n",
      "Average Choice reward is ==> -1.1949383020401\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1409)\n",
      "Episode * 123 * And Number of steps is ==> 251904\n",
      "Average Cross reward is ==> -0.01590009592473507, Average Wait reward is ==> -1.961948037147522\n",
      "Average Choice reward is ==> -1.1709892749786377\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0063)\n",
      "Episode * 124 * And Number of steps is ==> 253952\n",
      "Average Cross reward is ==> -0.01544674951583147, Average Wait reward is ==> -1.9641573429107666\n",
      "Average Choice reward is ==> -1.169746994972229\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1689)\n",
      "Episode * 125 * And Number of steps is ==> 256000\n",
      "Average Cross reward is ==> -0.01493112463504076, Average Wait reward is ==> -1.9331268072128296\n",
      "Average Choice reward is ==> -1.1247551441192627\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0289)\n",
      "Episode * 126 * And Number of steps is ==> 258048\n",
      "Average Cross reward is ==> -0.014754829928278923, Average Wait reward is ==> -1.8970367908477783\n",
      "Average Choice reward is ==> -1.1062543392181396\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0349)\n",
      "Episode * 127 * And Number of steps is ==> 260096\n",
      "Average Cross reward is ==> -0.014411404728889465, Average Wait reward is ==> -1.8701626062393188\n",
      "Average Choice reward is ==> -1.0976531505584717\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9764)\n",
      "Episode * 128 * And Number of steps is ==> 262144\n",
      "Average Cross reward is ==> -0.014097074046730995, Average Wait reward is ==> -1.9031174182891846\n",
      "Average Choice reward is ==> -1.1060645580291748\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2333)\n",
      "Episode * 129 * And Number of steps is ==> 264192\n",
      "Average Cross reward is ==> -0.013763410970568657, Average Wait reward is ==> -1.9672596454620361\n",
      "Average Choice reward is ==> -1.1127960681915283\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1950)\n",
      "Episode * 130 * And Number of steps is ==> 266240\n",
      "Average Cross reward is ==> -0.013931001536548138, Average Wait reward is ==> -1.8174479007720947\n",
      "Average Choice reward is ==> -1.1139976978302002\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0989)\n",
      "Episode * 131 * And Number of steps is ==> 268288\n",
      "Average Cross reward is ==> -0.01400080882012844, Average Wait reward is ==> -1.830061912536621\n",
      "Average Choice reward is ==> -1.082674264907837\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2426)\n",
      "Episode * 132 * And Number of steps is ==> 270336\n",
      "Average Cross reward is ==> -0.014334723353385925, Average Wait reward is ==> -1.835099220275879\n",
      "Average Choice reward is ==> -1.1125905513763428\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2228)\n",
      "Episode * 133 * And Number of steps is ==> 272384\n",
      "Average Cross reward is ==> -0.014035487547516823, Average Wait reward is ==> -1.8131719827651978\n",
      "Average Choice reward is ==> -1.1207802295684814\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2436)\n",
      "Episode * 134 * And Number of steps is ==> 274432\n",
      "Average Cross reward is ==> -0.01388492900878191, Average Wait reward is ==> -1.804363489151001\n",
      "Average Choice reward is ==> -1.144517421722412\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3850)\n",
      "Episode * 135 * And Number of steps is ==> 276480\n",
      "Average Cross reward is ==> -0.013843471184372902, Average Wait reward is ==> -1.7734571695327759\n",
      "Average Choice reward is ==> -1.1661293506622314\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4595)\n",
      "Episode * 136 * And Number of steps is ==> 278528\n",
      "Average Cross reward is ==> -0.013157986104488373, Average Wait reward is ==> -2.045836925506592\n",
      "Average Choice reward is ==> -1.2091952562332153\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0233)\n",
      "Episode * 137 * And Number of steps is ==> 280576\n",
      "Average Cross reward is ==> -0.013002576306462288, Average Wait reward is ==> -2.074561834335327\n",
      "Average Choice reward is ==> -1.2080374956130981\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0790)\n",
      "Episode * 138 * And Number of steps is ==> 282624\n",
      "Average Cross reward is ==> -0.013175450265407562, Average Wait reward is ==> -2.0478923320770264\n",
      "Average Choice reward is ==> -1.2182964086532593\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1520)\n",
      "Episode * 139 * And Number of steps is ==> 284672\n",
      "Average Cross reward is ==> -0.01295440923422575, Average Wait reward is ==> -1.9755666255950928\n",
      "Average Choice reward is ==> -1.2101645469665527\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2780)\n",
      "Episode * 140 * And Number of steps is ==> 286720\n",
      "Average Cross reward is ==> -0.012312382459640503, Average Wait reward is ==> -2.0747106075286865\n",
      "Average Choice reward is ==> -1.218464732170105\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9781)\n",
      "Episode * 141 * And Number of steps is ==> 288768\n",
      "Average Cross reward is ==> -0.011917969211935997, Average Wait reward is ==> -2.029726505279541\n",
      "Average Choice reward is ==> -1.206377387046814\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0520)\n",
      "Episode * 142 * And Number of steps is ==> 290816\n",
      "Average Cross reward is ==> -0.011185362003743649, Average Wait reward is ==> -2.3691744804382324\n",
      "Average Choice reward is ==> -1.1873184442520142\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9441)\n",
      "Episode * 143 * And Number of steps is ==> 292864\n",
      "Average Cross reward is ==> -0.011014385148882866, Average Wait reward is ==> -2.426994800567627\n",
      "Average Choice reward is ==> -1.1594539880752563\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0683)\n",
      "Episode * 144 * And Number of steps is ==> 294912\n",
      "Average Cross reward is ==> -0.010868479497730732, Average Wait reward is ==> -2.440002679824829\n",
      "Average Choice reward is ==> -1.1419216394424438\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0542)\n",
      "Episode * 145 * And Number of steps is ==> 296960\n",
      "Average Cross reward is ==> -0.010830637067556381, Average Wait reward is ==> -2.5422537326812744\n",
      "Average Choice reward is ==> -1.1088430881500244\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2010)\n",
      "Episode * 146 * And Number of steps is ==> 299008\n",
      "Average Cross reward is ==> -0.010839427821338177, Average Wait reward is ==> -2.3024065494537354\n",
      "Average Choice reward is ==> -1.08298659324646\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3401)\n",
      "Episode * 147 * And Number of steps is ==> 301056\n",
      "Average Cross reward is ==> -0.01066700741648674, Average Wait reward is ==> -2.2304108142852783\n",
      "Average Choice reward is ==> -1.1146670579910278\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2528)\n",
      "Episode * 148 * And Number of steps is ==> 303104\n",
      "Average Cross reward is ==> -0.010423826053738594, Average Wait reward is ==> -2.222313404083252\n",
      "Average Choice reward is ==> -1.1320521831512451\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2168)\n",
      "Episode * 149 * And Number of steps is ==> 305152\n",
      "Average Cross reward is ==> -0.010277901776134968, Average Wait reward is ==> -2.2071566581726074\n",
      "Average Choice reward is ==> -1.1385324001312256\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9618)\n",
      "Episode * 150 * And Number of steps is ==> 307200\n",
      "Average Cross reward is ==> -0.01031523011624813, Average Wait reward is ==> -2.0836338996887207\n",
      "Average Choice reward is ==> -1.1069144010543823\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9111)\n",
      "Episode * 151 * And Number of steps is ==> 309248\n",
      "Average Cross reward is ==> -0.010326863266527653, Average Wait reward is ==> -2.118269443511963\n",
      "Average Choice reward is ==> -1.1002169847488403\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0712)\n",
      "Episode * 152 * And Number of steps is ==> 311296\n",
      "Average Cross reward is ==> -0.010279534384608269, Average Wait reward is ==> -1.9031873941421509\n",
      "Average Choice reward is ==> -1.1021431684494019\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0042)\n",
      "Episode * 153 * And Number of steps is ==> 313344\n",
      "Average Cross reward is ==> -0.010223817080259323, Average Wait reward is ==> -1.9065001010894775\n",
      "Average Choice reward is ==> -1.1081469058990479\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1179)\n",
      "Episode * 154 * And Number of steps is ==> 315392\n",
      "Average Cross reward is ==> -0.010296640917658806, Average Wait reward is ==> -1.9661363363265991\n",
      "Average Choice reward is ==> -1.1131088733673096\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0229)\n",
      "Episode * 155 * And Number of steps is ==> 317440\n",
      "Average Cross reward is ==> -0.010195483453571796, Average Wait reward is ==> -1.9821178913116455\n",
      "Average Choice reward is ==> -1.1099797487258911\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9674)\n",
      "Episode * 156 * And Number of steps is ==> 319488\n",
      "Average Cross reward is ==> -0.01020845863968134, Average Wait reward is ==> -2.0821566581726074\n",
      "Average Choice reward is ==> -1.0866202116012573\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2050)\n",
      "Episode * 157 * And Number of steps is ==> 321536\n",
      "Average Cross reward is ==> -0.010340489447116852, Average Wait reward is ==> -2.1239328384399414\n",
      "Average Choice reward is ==> -1.0731122493743896\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8216)\n",
      "Episode * 158 * And Number of steps is ==> 323584\n",
      "Average Cross reward is ==> -0.01038917526602745, Average Wait reward is ==> -2.136672019958496\n",
      "Average Choice reward is ==> -1.029982566833496\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1326)\n",
      "Episode * 159 * And Number of steps is ==> 325632\n",
      "Average Cross reward is ==> -0.01031408179551363, Average Wait reward is ==> -2.1351377964019775\n",
      "Average Choice reward is ==> -1.0215656757354736\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0099)\n",
      "Episode * 160 * And Number of steps is ==> 327680\n",
      "Average Cross reward is ==> -0.01023828610777855, Average Wait reward is ==> -2.141336441040039\n",
      "Average Choice reward is ==> -1.0263792276382446\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0366)\n",
      "Episode * 161 * And Number of steps is ==> 329728\n",
      "Average Cross reward is ==> -0.010136706754565239, Average Wait reward is ==> -2.179029703140259\n",
      "Average Choice reward is ==> -1.0389318466186523\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9981)\n",
      "Episode * 162 * And Number of steps is ==> 331776\n",
      "Average Cross reward is ==> -0.010189855471253395, Average Wait reward is ==> -2.059617757797241\n",
      "Average Choice reward is ==> -1.0316146612167358\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0321)\n",
      "Episode * 163 * And Number of steps is ==> 333824\n",
      "Average Cross reward is ==> -0.010081547312438488, Average Wait reward is ==> -2.024233818054199\n",
      "Average Choice reward is ==> -1.0344088077545166\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9015)\n",
      "Episode * 164 * And Number of steps is ==> 335872\n",
      "Average Cross reward is ==> -0.00991055928170681, Average Wait reward is ==> -1.9775314331054688\n",
      "Average Choice reward is ==> -1.0127644538879395\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9218)\n",
      "Episode * 165 * And Number of steps is ==> 337920\n",
      "Average Cross reward is ==> -0.009840545244514942, Average Wait reward is ==> -1.891202688217163\n",
      "Average Choice reward is ==> -1.0026490688323975\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8768)\n",
      "Episode * 166 * And Number of steps is ==> 339968\n",
      "Average Cross reward is ==> -0.009656058624386787, Average Wait reward is ==> -1.780906319618225\n",
      "Average Choice reward is ==> -0.993593692779541\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0310)\n",
      "Episode * 167 * And Number of steps is ==> 342016\n",
      "Average Cross reward is ==> -0.009392692707479, Average Wait reward is ==> -1.7699289321899414\n",
      "Average Choice reward is ==> -0.9761950373649597\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0198)\n",
      "Episode * 168 * And Number of steps is ==> 344064\n",
      "Average Cross reward is ==> -0.009163330309092999, Average Wait reward is ==> -1.7532726526260376\n",
      "Average Choice reward is ==> -0.9960218667984009\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7714)\n",
      "Episode * 169 * And Number of steps is ==> 346112\n",
      "Average Cross reward is ==> -0.00904469471424818, Average Wait reward is ==> -1.7370359897613525\n",
      "Average Choice reward is ==> -0.9598973989486694\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8972)\n",
      "Episode * 170 * And Number of steps is ==> 348160\n",
      "Average Cross reward is ==> -0.008995583280920982, Average Wait reward is ==> -1.7755047082901\n",
      "Average Choice reward is ==> -0.9486297369003296\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8265)\n",
      "Episode * 171 * And Number of steps is ==> 350208\n",
      "Average Cross reward is ==> -0.008938727900385857, Average Wait reward is ==> -1.9664510488510132\n",
      "Average Choice reward is ==> -0.9276188611984253\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8225)\n",
      "Episode * 172 * And Number of steps is ==> 352256\n",
      "Average Cross reward is ==> -0.008665712550282478, Average Wait reward is ==> -1.9686472415924072\n",
      "Average Choice reward is ==> -0.9100645780563354\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7202)\n",
      "Episode * 173 * And Number of steps is ==> 354304\n",
      "Average Cross reward is ==> -0.00861736573278904, Average Wait reward is ==> -1.9520785808563232\n",
      "Average Choice reward is ==> -0.8788738250732422\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9996)\n",
      "Episode * 174 * And Number of steps is ==> 356352\n",
      "Average Cross reward is ==> -0.008511144667863846, Average Wait reward is ==> -1.9508661031723022\n",
      "Average Choice reward is ==> -0.8886874914169312\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9838)\n",
      "Episode * 175 * And Number of steps is ==> 358400\n",
      "Average Cross reward is ==> -0.008445080369710922, Average Wait reward is ==> -1.9216772317886353\n",
      "Average Choice reward is ==> -0.8948891758918762\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8898)\n",
      "Episode * 176 * And Number of steps is ==> 360448\n",
      "Average Cross reward is ==> -0.008357437327504158, Average Wait reward is ==> -1.9232559204101562\n",
      "Average Choice reward is ==> -0.8961828947067261\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.5585)\n",
      "Episode * 177 * And Number of steps is ==> 362496\n",
      "Average Cross reward is ==> -0.008310893550515175, Average Wait reward is ==> -1.9083023071289062\n",
      "Average Choice reward is ==> -0.8489281535148621\n",
      "Number Cross is ==> 1280 and Number Wait is ==> 2880 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0940)\n",
      "Episode * 178 * And Number of steps is ==> 364544\n",
      "Average Cross reward is ==> -0.008259446360170841, Average Wait reward is ==> -2.066091537475586\n",
      "Average Choice reward is ==> -0.8563426733016968\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8202)\n",
      "Episode * 179 * And Number of steps is ==> 366592\n",
      "Average Cross reward is ==> -0.008247410878539085, Average Wait reward is ==> -2.0732007026672363\n",
      "Average Choice reward is ==> -0.8612291216850281\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7110)\n",
      "Episode * 180 * And Number of steps is ==> 368640\n",
      "Average Cross reward is ==> -0.008174690417945385, Average Wait reward is ==> -2.0342025756835938\n",
      "Average Choice reward is ==> -0.8426094055175781\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9342)\n",
      "Episode * 181 * And Number of steps is ==> 370688\n",
      "Average Cross reward is ==> -0.008164850063621998, Average Wait reward is ==> -1.828213095664978\n",
      "Average Choice reward is ==> -0.8533840179443359\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9286)\n",
      "Episode * 182 * And Number of steps is ==> 372736\n",
      "Average Cross reward is ==> -0.008194438181817532, Average Wait reward is ==> -1.8100236654281616\n",
      "Average Choice reward is ==> -0.8639901876449585\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8993)\n",
      "Episode * 183 * And Number of steps is ==> 374784\n",
      "Average Cross reward is ==> -0.00820712000131607, Average Wait reward is ==> -1.8062025308609009\n",
      "Average Choice reward is ==> -0.8818961977958679\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9803)\n",
      "Episode * 184 * And Number of steps is ==> 376832\n",
      "Average Cross reward is ==> -0.008179998025298119, Average Wait reward is ==> -1.803287148475647\n",
      "Average Choice reward is ==> -0.8799673914909363\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8944)\n",
      "Episode * 185 * And Number of steps is ==> 378880\n",
      "Average Cross reward is ==> -0.008250607177615166, Average Wait reward is ==> -1.825918436050415\n",
      "Average Choice reward is ==> -0.8710256814956665\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7836)\n",
      "Episode * 186 * And Number of steps is ==> 380928\n",
      "Average Cross reward is ==> -0.008196057751774788, Average Wait reward is ==> -1.8064886331558228\n",
      "Average Choice reward is ==> -0.8604116439819336\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7828)\n",
      "Episode * 187 * And Number of steps is ==> 382976\n",
      "Average Cross reward is ==> -0.008117149583995342, Average Wait reward is ==> -1.8784949779510498\n",
      "Average Choice reward is ==> -0.8828405141830444\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9410)\n",
      "Episode * 188 * And Number of steps is ==> 385024\n",
      "Average Cross reward is ==> -0.008077445439994335, Average Wait reward is ==> -1.7397016286849976\n",
      "Average Choice reward is ==> -0.8675487637519836\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7445)\n",
      "Episode * 189 * And Number of steps is ==> 387072\n",
      "Average Cross reward is ==> -0.007975166663527489, Average Wait reward is ==> -1.7227064371109009\n",
      "Average Choice reward is ==> -0.8599736094474792\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8147)\n",
      "Episode * 190 * And Number of steps is ==> 389120\n",
      "Average Cross reward is ==> -0.007965605705976486, Average Wait reward is ==> -1.8100788593292236\n",
      "Average Choice reward is ==> -0.8703390955924988\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8747)\n",
      "Episode * 191 * And Number of steps is ==> 391168\n",
      "Average Cross reward is ==> -0.007839864119887352, Average Wait reward is ==> -1.764923334121704\n",
      "Average Choice reward is ==> -0.8643842935562134\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.6627)\n",
      "Episode * 192 * And Number of steps is ==> 393216\n",
      "Average Cross reward is ==> -0.007821870036423206, Average Wait reward is ==> -1.831823706626892\n",
      "Average Choice reward is ==> -0.8378003239631653\n",
      "Number Cross is ==> 1440 and Number Wait is ==> 2720 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9012)\n",
      "Episode * 193 * And Number of steps is ==> 395264\n",
      "Average Cross reward is ==> -0.007815174758434296, Average Wait reward is ==> -1.8208967447280884\n",
      "Average Choice reward is ==> -0.8379924893379211\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0708)\n",
      "Episode * 194 * And Number of steps is ==> 397312\n",
      "Average Cross reward is ==> -0.007749664131551981, Average Wait reward is ==> -1.8701521158218384\n",
      "Average Choice reward is ==> -0.8470340967178345\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8523)\n",
      "Episode * 195 * And Number of steps is ==> 399360\n",
      "Average Cross reward is ==> -0.007573028560727835, Average Wait reward is ==> -1.8860721588134766\n",
      "Average Choice reward is ==> -0.8428243398666382\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7934)\n",
      "Episode * 196 * And Number of steps is ==> 401408\n",
      "Average Cross reward is ==> -0.007508282549679279, Average Wait reward is ==> -1.9172945022583008\n",
      "Average Choice reward is ==> -0.8438043594360352\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8506)\n",
      "Episode * 197 * And Number of steps is ==> 403456\n",
      "Average Cross reward is ==> -0.007512390613555908, Average Wait reward is ==> -1.8236109018325806\n",
      "Average Choice reward is ==> -0.8505867719650269\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0159)\n",
      "Episode * 198 * And Number of steps is ==> 405504\n",
      "Average Cross reward is ==> -0.007473143748939037, Average Wait reward is ==> -1.8265365362167358\n",
      "Average Choice reward is ==> -0.8580735325813293\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7429)\n",
      "Episode * 199 * And Number of steps is ==> 407552\n",
      "Average Cross reward is ==> -0.0074277035892009735, Average Wait reward is ==> -1.8619232177734375\n",
      "Average Choice reward is ==> -0.8579155802726746\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9656)\n",
      "Episode * 200 * And Number of steps is ==> 409600\n",
      "Average Cross reward is ==> -0.007270922418683767, Average Wait reward is ==> -1.9591407775878906\n",
      "Average Choice reward is ==> -0.8730033040046692\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9978)\n",
      "Episode * 201 * And Number of steps is ==> 411648\n",
      "Average Cross reward is ==> -0.007283077575266361, Average Wait reward is ==> -2.107104778289795\n",
      "Average Choice reward is ==> -0.885313868522644\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7164)\n",
      "Episode * 202 * And Number of steps is ==> 413696\n",
      "Average Cross reward is ==> -0.007251189090311527, Average Wait reward is ==> -2.188152551651001\n",
      "Average Choice reward is ==> -0.8906756639480591\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8378)\n",
      "Episode * 203 * And Number of steps is ==> 415744\n",
      "Average Cross reward is ==> -0.0072542899288237095, Average Wait reward is ==> -2.2575230598449707\n",
      "Average Choice reward is ==> -0.8843344449996948\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0214)\n",
      "Episode * 204 * And Number of steps is ==> 417792\n",
      "Average Cross reward is ==> -0.007222154643386602, Average Wait reward is ==> -2.3531458377838135\n",
      "Average Choice reward is ==> -0.8793994784355164\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9803)\n",
      "Episode * 205 * And Number of steps is ==> 419840\n",
      "Average Cross reward is ==> -0.007177718915045261, Average Wait reward is ==> -2.340618848800659\n",
      "Average Choice reward is ==> -0.8921995162963867\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8831)\n",
      "Episode * 206 * And Number of steps is ==> 421888\n",
      "Average Cross reward is ==> -0.007128468248993158, Average Wait reward is ==> -2.367868661880493\n",
      "Average Choice reward is ==> -0.9011634588241577\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7643)\n",
      "Episode * 207 * And Number of steps is ==> 423936\n",
      "Average Cross reward is ==> -0.00707227224484086, Average Wait reward is ==> -2.4860823154449463\n",
      "Average Choice reward is ==> -0.8925372958183289\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8238)\n",
      "Episode * 208 * And Number of steps is ==> 425984\n",
      "Average Cross reward is ==> -0.007193508092314005, Average Wait reward is ==> -2.483306646347046\n",
      "Average Choice reward is ==> -0.8733283281326294\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8040)\n",
      "Episode * 209 * And Number of steps is ==> 428032\n",
      "Average Cross reward is ==> -0.0072835832834243774, Average Wait reward is ==> -2.4675583839416504\n",
      "Average Choice reward is ==> -0.8794386982917786\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1577)\n",
      "Episode * 210 * And Number of steps is ==> 430080\n",
      "Average Cross reward is ==> -0.007322532124817371, Average Wait reward is ==> -2.316483974456787\n",
      "Average Choice reward is ==> -0.8986531496047974\n",
      "Number Cross is ==> 2720 and Number Wait is ==> 1440 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9692)\n",
      "Episode * 211 * And Number of steps is ==> 432128\n",
      "Average Cross reward is ==> -0.007286661304533482, Average Wait reward is ==> -2.210646867752075\n",
      "Average Choice reward is ==> -0.8957899212837219\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8050)\n",
      "Episode * 212 * And Number of steps is ==> 434176\n",
      "Average Cross reward is ==> -0.007185223046690226, Average Wait reward is ==> -2.0622165203094482\n",
      "Average Choice reward is ==> -0.9046539068222046\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9435)\n",
      "Episode * 213 * And Number of steps is ==> 436224\n",
      "Average Cross reward is ==> -0.007019722368568182, Average Wait reward is ==> -2.026998996734619\n",
      "Average Choice reward is ==> -0.9152315855026245\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9416)\n",
      "Episode * 214 * And Number of steps is ==> 438272\n",
      "Average Cross reward is ==> -0.006936089135706425, Average Wait reward is ==> -1.8637405633926392\n",
      "Average Choice reward is ==> -0.907254695892334\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0134)\n",
      "Episode * 215 * And Number of steps is ==> 440320\n",
      "Average Cross reward is ==> -0.0068833655677735806, Average Wait reward is ==> -1.83780837059021\n",
      "Average Choice reward is ==> -0.9105684161186218\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8266)\n",
      "Episode * 216 * And Number of steps is ==> 442368\n",
      "Average Cross reward is ==> -0.006850170437246561, Average Wait reward is ==> -1.7751728296279907\n",
      "Average Choice reward is ==> -0.9049240350723267\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9547)\n",
      "Episode * 217 * And Number of steps is ==> 444416\n",
      "Average Cross reward is ==> -0.006822614464908838, Average Wait reward is ==> -1.7015306949615479\n",
      "Average Choice reward is ==> -0.9239581823348999\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8504)\n",
      "Episode * 218 * And Number of steps is ==> 446464\n",
      "Average Cross reward is ==> -0.006666277535259724, Average Wait reward is ==> -1.767584204673767\n",
      "Average Choice reward is ==> -0.9266141653060913\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9001)\n",
      "Episode * 219 * And Number of steps is ==> 448512\n",
      "Average Cross reward is ==> -0.0065633393824100494, Average Wait reward is ==> -1.7917064428329468\n",
      "Average Choice reward is ==> -0.9362252354621887\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8358)\n",
      "Episode * 220 * And Number of steps is ==> 450560\n",
      "Average Cross reward is ==> -0.006471806671470404, Average Wait reward is ==> -1.7250944375991821\n",
      "Average Choice reward is ==> -0.9040314555168152\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.6241)\n",
      "Episode * 221 * And Number of steps is ==> 452608\n",
      "Average Cross reward is ==> -0.006390911526978016, Average Wait reward is ==> -1.7206532955169678\n",
      "Average Choice reward is ==> -0.8695214986801147\n",
      "Number Cross is ==> 1440 and Number Wait is ==> 2720 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1379)\n",
      "Episode * 222 * And Number of steps is ==> 454656\n",
      "Average Cross reward is ==> -0.006399671547114849, Average Wait reward is ==> -1.7440630197525024\n",
      "Average Choice reward is ==> -0.9028100967407227\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9075)\n",
      "Episode * 223 * And Number of steps is ==> 456704\n",
      "Average Cross reward is ==> -0.0064309039153158665, Average Wait reward is ==> -1.7258121967315674\n",
      "Average Choice reward is ==> -0.8992085456848145\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.6844)\n",
      "Episode * 224 * And Number of steps is ==> 458752\n",
      "Average Cross reward is ==> -0.0064664543606340885, Average Wait reward is ==> -1.7714426517486572\n",
      "Average Choice reward is ==> -0.8734883069992065\n",
      "Number Cross is ==> 1520 and Number Wait is ==> 2640 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9849)\n",
      "Episode * 225 * And Number of steps is ==> 460800\n",
      "Average Cross reward is ==> -0.0064827268943190575, Average Wait reward is ==> -1.7733089923858643\n",
      "Average Choice reward is ==> -0.8706424832344055\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1386)\n",
      "Episode * 226 * And Number of steps is ==> 462848\n",
      "Average Cross reward is ==> -0.00646653026342392, Average Wait reward is ==> -1.8926435708999634\n",
      "Average Choice reward is ==> -0.9018387794494629\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.6877)\n",
      "Episode * 227 * And Number of steps is ==> 464896\n",
      "Average Cross reward is ==> -0.006466091610491276, Average Wait reward is ==> -1.84157395362854\n",
      "Average Choice reward is ==> -0.8751352429389954\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9325)\n",
      "Episode * 228 * And Number of steps is ==> 466944\n",
      "Average Cross reward is ==> -0.006432751659303904, Average Wait reward is ==> -1.7749162912368774\n",
      "Average Choice reward is ==> -0.8833462595939636\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8086)\n",
      "Episode * 229 * And Number of steps is ==> 468992\n",
      "Average Cross reward is ==> -0.006430331617593765, Average Wait reward is ==> -1.7311499118804932\n",
      "Average Choice reward is ==> -0.8741973638534546\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8794)\n",
      "Episode * 230 * And Number of steps is ==> 471040\n",
      "Average Cross reward is ==> -0.006494789384305477, Average Wait reward is ==> -1.7404632568359375\n",
      "Average Choice reward is ==> -0.8785614967346191\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7209)\n",
      "Episode * 231 * And Number of steps is ==> 473088\n",
      "Average Cross reward is ==> -0.006481744349002838, Average Wait reward is ==> -1.6825729608535767\n",
      "Average Choice reward is ==> -0.888242244720459\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1000)\n",
      "Episode * 232 * And Number of steps is ==> 475136\n",
      "Average Cross reward is ==> -0.006486174650490284, Average Wait reward is ==> -1.6528860330581665\n",
      "Average Choice reward is ==> -0.8844553232192993\n",
      "Number Cross is ==> 2640 and Number Wait is ==> 1520 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7070)\n",
      "Episode * 233 * And Number of steps is ==> 477184\n",
      "Average Cross reward is ==> -0.006453665904700756, Average Wait reward is ==> -1.6464712619781494\n",
      "Average Choice reward is ==> -0.864398181438446\n",
      "Number Cross is ==> 1520 and Number Wait is ==> 2640 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0769)\n",
      "Episode * 234 * And Number of steps is ==> 479232\n",
      "Average Cross reward is ==> -0.0064249164424836636, Average Wait reward is ==> -1.6007792949676514\n",
      "Average Choice reward is ==> -0.9036468267440796\n",
      "Number Cross is ==> 2560 and Number Wait is ==> 1600 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8821)\n",
      "Episode * 235 * And Number of steps is ==> 481280\n",
      "Average Cross reward is ==> -0.006432157009840012, Average Wait reward is ==> -1.6230356693267822\n",
      "Average Choice reward is ==> -0.8933588862419128\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.6571)\n",
      "Episode * 236 * And Number of steps is ==> 483328\n",
      "Average Cross reward is ==> -0.006390220485627651, Average Wait reward is ==> -1.4943900108337402\n",
      "Average Choice reward is ==> -0.8452141880989075\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9013)\n",
      "Episode * 237 * And Number of steps is ==> 485376\n",
      "Average Cross reward is ==> -0.006385485175997019, Average Wait reward is ==> -1.5221506357192993\n",
      "Average Choice reward is ==> -0.8665808439254761\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9427)\n",
      "Episode * 238 * And Number of steps is ==> 487424\n",
      "Average Cross reward is ==> -0.006426615174859762, Average Wait reward is ==> -1.5155388116836548\n",
      "Average Choice reward is ==> -0.8675976991653442\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7013)\n",
      "Episode * 239 * And Number of steps is ==> 489472\n",
      "Average Cross reward is ==> -0.006367441266775131, Average Wait reward is ==> -1.5117335319519043\n",
      "Average Choice reward is ==> -0.8568680882453918\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7417)\n",
      "Episode * 240 * And Number of steps is ==> 491520\n",
      "Average Cross reward is ==> -0.006358332931995392, Average Wait reward is ==> -1.518789529800415\n",
      "Average Choice reward is ==> -0.8430938720703125\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9756)\n",
      "Episode * 241 * And Number of steps is ==> 493568\n",
      "Average Cross reward is ==> -0.00635654479265213, Average Wait reward is ==> -1.5603841543197632\n",
      "Average Choice reward is ==> -0.8685658574104309\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7057)\n",
      "Episode * 242 * And Number of steps is ==> 495616\n",
      "Average Cross reward is ==> -0.006366070359945297, Average Wait reward is ==> -1.5721787214279175\n",
      "Average Choice reward is ==> -0.8291386365890503\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9934)\n",
      "Episode * 243 * And Number of steps is ==> 497664\n",
      "Average Cross reward is ==> -0.0066354223527014256, Average Wait reward is ==> -1.5954816341400146\n",
      "Average Choice reward is ==> -0.8577804565429688\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8797)\n",
      "Episode * 244 * And Number of steps is ==> 499712\n",
      "Average Cross reward is ==> -0.006873433478176594, Average Wait reward is ==> -1.6047083139419556\n",
      "Average Choice reward is ==> -0.8380619287490845\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9326)\n",
      "Episode * 245 * And Number of steps is ==> 501760\n",
      "Average Cross reward is ==> -0.0068225739523768425, Average Wait reward is ==> -1.6068226099014282\n",
      "Average Choice reward is ==> -0.8431184887886047\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3159)\n",
      "Episode * 246 * And Number of steps is ==> 503808\n",
      "Average Cross reward is ==> -0.006937488913536072, Average Wait reward is ==> -1.6207828521728516\n",
      "Average Choice reward is ==> -0.9089964032173157\n",
      "Number Cross is ==> 2800 and Number Wait is ==> 1360 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8414)\n",
      "Episode * 247 * And Number of steps is ==> 505856\n",
      "Average Cross reward is ==> -0.006901315413415432, Average Wait reward is ==> -1.636840581893921\n",
      "Average Choice reward is ==> -0.9030026197433472\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9408)\n",
      "Episode * 248 * And Number of steps is ==> 507904\n",
      "Average Cross reward is ==> -0.006820281036198139, Average Wait reward is ==> -1.735089659690857\n",
      "Average Choice reward is ==> -0.9028156399726868\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8760)\n",
      "Episode * 249 * And Number of steps is ==> 509952\n",
      "Average Cross reward is ==> -0.006838181521743536, Average Wait reward is ==> -1.854614019393921\n",
      "Average Choice reward is ==> -0.920279860496521\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1253)\n",
      "Episode * 250 * And Number of steps is ==> 512000\n",
      "Average Cross reward is ==> -0.006762759294360876, Average Wait reward is ==> -1.8489086627960205\n",
      "Average Choice reward is ==> -0.9586392641067505\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9342)\n",
      "Episode * 251 * And Number of steps is ==> 514048\n",
      "Average Cross reward is ==> -0.006714036222547293, Average Wait reward is ==> -1.8024343252182007\n",
      "Average Choice reward is ==> -0.9544985890388489\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9588)\n",
      "Episode * 252 * And Number of steps is ==> 516096\n",
      "Average Cross reward is ==> -0.006615451071411371, Average Wait reward is ==> -1.8208945989608765\n",
      "Average Choice reward is ==> -0.979803204536438\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1054)\n",
      "Episode * 253 * And Number of steps is ==> 518144\n",
      "Average Cross reward is ==> -0.006281369365751743, Average Wait reward is ==> -1.844368577003479\n",
      "Average Choice reward is ==> -0.9910076260566711\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9177)\n",
      "Episode * 254 * And Number of steps is ==> 520192\n",
      "Average Cross reward is ==> -0.005961030721664429, Average Wait reward is ==> -1.8479158878326416\n",
      "Average Choice reward is ==> -0.9947997331619263\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1932)\n",
      "Episode * 255 * And Number of steps is ==> 522240\n",
      "Average Cross reward is ==> -0.005927539896219969, Average Wait reward is ==> -1.8858613967895508\n",
      "Average Choice reward is ==> -1.0208593606948853\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1462)\n",
      "Episode * 256 * And Number of steps is ==> 524288\n",
      "Average Cross reward is ==> -0.0058562494814395905, Average Wait reward is ==> -1.8804107904434204\n",
      "Average Choice reward is ==> -1.0038928985595703\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4182)\n",
      "Episode * 257 * And Number of steps is ==> 526336\n",
      "Average Cross reward is ==> -0.005839408840984106, Average Wait reward is ==> -1.8651149272918701\n",
      "Average Choice reward is ==> -1.0615780353546143\n",
      "Number Cross is ==> 2720 and Number Wait is ==> 1440 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2162)\n",
      "Episode * 258 * And Number of steps is ==> 528384\n",
      "Average Cross reward is ==> -0.0058576809242367744, Average Wait reward is ==> -1.781174898147583\n",
      "Average Choice reward is ==> -1.089120626449585\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1683)\n",
      "Episode * 259 * And Number of steps is ==> 530432\n",
      "Average Cross reward is ==> -0.0058281803503632545, Average Wait reward is ==> -1.8283954858779907\n",
      "Average Choice reward is ==> -1.1183557510375977\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1215)\n",
      "Episode * 260 * And Number of steps is ==> 532480\n",
      "Average Cross reward is ==> -0.005826353095471859, Average Wait reward is ==> -1.8896663188934326\n",
      "Average Choice reward is ==> -1.1179816722869873\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8591)\n",
      "Episode * 261 * And Number of steps is ==> 534528\n",
      "Average Cross reward is ==> -0.005824434570968151, Average Wait reward is ==> -1.933281660079956\n",
      "Average Choice reward is ==> -1.1104742288589478\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1882)\n",
      "Episode * 262 * And Number of steps is ==> 536576\n",
      "Average Cross reward is ==> -0.005808166228234768, Average Wait reward is ==> -1.9990686178207397\n",
      "Average Choice reward is ==> -1.1334151029586792\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2946)\n",
      "Episode * 263 * And Number of steps is ==> 538624\n",
      "Average Cross reward is ==> -0.005779947154223919, Average Wait reward is ==> -1.9369370937347412\n",
      "Average Choice reward is ==> -1.152336835861206\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1689)\n",
      "Episode * 264 * And Number of steps is ==> 540672\n",
      "Average Cross reward is ==> -0.00577952153980732, Average Wait reward is ==> -2.005488872528076\n",
      "Average Choice reward is ==> -1.177464246749878\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2191)\n",
      "Episode * 265 * And Number of steps is ==> 542720\n",
      "Average Cross reward is ==> -0.005735129117965698, Average Wait reward is ==> -1.9839067459106445\n",
      "Average Choice reward is ==> -1.1800544261932373\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0969)\n",
      "Episode * 266 * And Number of steps is ==> 544768\n",
      "Average Cross reward is ==> -0.00570562994107604, Average Wait reward is ==> -2.1177542209625244\n",
      "Average Choice reward is ==> -1.175123929977417\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2941)\n",
      "Episode * 267 * And Number of steps is ==> 546816\n",
      "Average Cross reward is ==> -0.005653745494782925, Average Wait reward is ==> -2.0981507301330566\n",
      "Average Choice reward is ==> -1.1627159118652344\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4829)\n",
      "Episode * 268 * And Number of steps is ==> 548864\n",
      "Average Cross reward is ==> -0.005597817711532116, Average Wait reward is ==> -2.0649168491363525\n",
      "Average Choice reward is ==> -1.1893889904022217\n",
      "Number Cross is ==> 2800 and Number Wait is ==> 1360 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2128)\n",
      "Episode * 269 * And Number of steps is ==> 550912\n",
      "Average Cross reward is ==> -0.005584849044680595, Average Wait reward is ==> -1.8944898843765259\n",
      "Average Choice reward is ==> -1.1938358545303345\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1154)\n",
      "Episode * 270 * And Number of steps is ==> 552960\n",
      "Average Cross reward is ==> -0.005608745850622654, Average Wait reward is ==> -1.8499844074249268\n",
      "Average Choice reward is ==> -1.1932249069213867\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8604)\n",
      "Episode * 271 * And Number of steps is ==> 555008\n",
      "Average Cross reward is ==> -0.00558337289839983, Average Wait reward is ==> -1.8342514038085938\n",
      "Average Choice reward is ==> -1.1933518648147583\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9144)\n",
      "Episode * 272 * And Number of steps is ==> 557056\n",
      "Average Cross reward is ==> -0.005616478621959686, Average Wait reward is ==> -1.7332741022109985\n",
      "Average Choice reward is ==> -1.1659772396087646\n",
      "Number Cross is ==> 1760 and Number Wait is ==> 2400 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1731)\n",
      "Episode * 273 * And Number of steps is ==> 559104\n",
      "Average Cross reward is ==> -0.00576761644333601, Average Wait reward is ==> -1.7476952075958252\n",
      "Average Choice reward is ==> -1.1538244485855103\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1646)\n",
      "Episode * 274 * And Number of steps is ==> 561152\n",
      "Average Cross reward is ==> -0.00577921699732542, Average Wait reward is ==> -1.738147497177124\n",
      "Average Choice reward is ==> -1.1533937454223633\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8280)\n",
      "Episode * 275 * And Number of steps is ==> 563200\n",
      "Average Cross reward is ==> -0.005819533485919237, Average Wait reward is ==> -1.6832059621810913\n",
      "Average Choice reward is ==> -1.1142823696136475\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9900)\n",
      "Episode * 276 * And Number of steps is ==> 565248\n",
      "Average Cross reward is ==> -0.005819438956677914, Average Wait reward is ==> -1.5191787481307983\n",
      "Average Choice reward is ==> -1.103590488433838\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1058)\n",
      "Episode * 277 * And Number of steps is ==> 567296\n",
      "Average Cross reward is ==> -0.005880787502974272, Average Wait reward is ==> -1.5209085941314697\n",
      "Average Choice reward is ==> -1.0847514867782593\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8714)\n",
      "Episode * 278 * And Number of steps is ==> 569344\n",
      "Average Cross reward is ==> -0.0059169079177081585, Average Wait reward is ==> -1.5374647378921509\n",
      "Average Choice reward is ==> -1.0235992670059204\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0805)\n",
      "Episode * 279 * And Number of steps is ==> 571392\n",
      "Average Cross reward is ==> -0.005895719863474369, Average Wait reward is ==> -1.5479071140289307\n",
      "Average Choice reward is ==> -1.0103743076324463\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7097)\n",
      "Episode * 280 * And Number of steps is ==> 573440\n",
      "Average Cross reward is ==> -0.0058554899878799915, Average Wait reward is ==> -1.5131219625473022\n",
      "Average Choice reward is ==> -0.9698008298873901\n",
      "Number Cross is ==> 1360 and Number Wait is ==> 2800 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0882)\n",
      "Episode * 281 * And Number of steps is ==> 575488\n",
      "Average Cross reward is ==> -0.005884057842195034, Average Wait reward is ==> -1.4899823665618896\n",
      "Average Choice reward is ==> -0.9925867915153503\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0554)\n",
      "Episode * 282 * And Number of steps is ==> 577536\n",
      "Average Cross reward is ==> -0.00590524123981595, Average Wait reward is ==> -1.5540626049041748\n",
      "Average Choice reward is ==> -1.006686806678772\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7590)\n",
      "Episode * 283 * And Number of steps is ==> 579584\n",
      "Average Cross reward is ==> -0.005763551685959101, Average Wait reward is ==> -1.536932110786438\n",
      "Average Choice reward is ==> -0.9652799367904663\n",
      "Number Cross is ==> 1440 and Number Wait is ==> 2720 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0980)\n",
      "Episode * 284 * And Number of steps is ==> 581632\n",
      "Average Cross reward is ==> -0.0057020047679543495, Average Wait reward is ==> -1.7482359409332275\n",
      "Average Choice reward is ==> -0.9586173295974731\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1724)\n",
      "Episode * 285 * And Number of steps is ==> 583680\n",
      "Average Cross reward is ==> -0.0057649859227240086, Average Wait reward is ==> -1.7703536748886108\n",
      "Average Choice reward is ==> -0.9930586814880371\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9566)\n",
      "Episode * 286 * And Number of steps is ==> 585728\n",
      "Average Cross reward is ==> -0.0057831862941384315, Average Wait reward is ==> -1.7764863967895508\n",
      "Average Choice reward is ==> -0.9897167086601257\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0609)\n",
      "Episode * 287 * And Number of steps is ==> 587776\n",
      "Average Cross reward is ==> -0.005823476705700159, Average Wait reward is ==> -1.765188455581665\n",
      "Average Choice reward is ==> -0.9852315783500671\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1505)\n",
      "Episode * 288 * And Number of steps is ==> 589824\n",
      "Average Cross reward is ==> -0.005945227108895779, Average Wait reward is ==> -1.7600195407867432\n",
      "Average Choice reward is ==> -1.013139009475708\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.4935)\n",
      "Episode * 289 * And Number of steps is ==> 591872\n",
      "Average Cross reward is ==> -0.005956933833658695, Average Wait reward is ==> -1.7528297901153564\n",
      "Average Choice reward is ==> -1.0544391870498657\n",
      "Number Cross is ==> 2880 and Number Wait is ==> 1280 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8548)\n",
      "Episode * 290 * And Number of steps is ==> 593920\n",
      "Average Cross reward is ==> -0.0059500401839613914, Average Wait reward is ==> -1.7693064212799072\n",
      "Average Choice reward is ==> -1.068947434425354\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9903)\n",
      "Episode * 291 * And Number of steps is ==> 595968\n",
      "Average Cross reward is ==> -0.0059145474806427956, Average Wait reward is ==> -1.7491424083709717\n",
      "Average Choice reward is ==> -1.0591485500335693\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1396)\n",
      "Episode * 292 * And Number of steps is ==> 598016\n",
      "Average Cross reward is ==> -0.005866867955774069, Average Wait reward is ==> -1.6747926473617554\n",
      "Average Choice reward is ==> -1.0675594806671143\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1132)\n",
      "Episode * 293 * And Number of steps is ==> 600064\n",
      "Average Cross reward is ==> -0.005890063010156155, Average Wait reward is ==> -1.653499960899353\n",
      "Average Choice reward is ==> -1.1029775142669678\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2099)\n",
      "Episode * 294 * And Number of steps is ==> 602112\n",
      "Average Cross reward is ==> -0.005928002297878265, Average Wait reward is ==> -1.351402759552002\n",
      "Average Choice reward is ==> -1.1141712665557861\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2712)\n",
      "Episode * 295 * And Number of steps is ==> 604160\n",
      "Average Cross reward is ==> -0.005827484652400017, Average Wait reward is ==> -1.355017900466919\n",
      "Average Choice reward is ==> -1.1240482330322266\n",
      "Number Cross is ==> 2400 and Number Wait is ==> 1760 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9336)\n",
      "Episode * 296 * And Number of steps is ==> 606208\n",
      "Average Cross reward is ==> -0.0058180601336061954, Average Wait reward is ==> -1.3297663927078247\n",
      "Average Choice reward is ==> -1.121747612953186\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9086)\n",
      "Episode * 297 * And Number of steps is ==> 608256\n",
      "Average Cross reward is ==> -0.005819045472890139, Average Wait reward is ==> -1.3834102153778076\n",
      "Average Choice reward is ==> -1.1065125465393066\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1115)\n",
      "Episode * 298 * And Number of steps is ==> 610304\n",
      "Average Cross reward is ==> -0.005707326345145702, Average Wait reward is ==> -1.3844350576400757\n",
      "Average Choice reward is ==> -1.1026087999343872\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1793)\n",
      "Episode * 299 * And Number of steps is ==> 612352\n",
      "Average Cross reward is ==> -0.0057472046464681625, Average Wait reward is ==> -1.4576196670532227\n",
      "Average Choice reward is ==> -1.0711809396743774\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9905)\n",
      "Episode * 300 * And Number of steps is ==> 614400\n",
      "Average Cross reward is ==> -0.005784016568213701, Average Wait reward is ==> -1.4623245000839233\n",
      "Average Choice reward is ==> -1.0847578048706055\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2352)\n",
      "Episode * 301 * And Number of steps is ==> 616448\n",
      "Average Cross reward is ==> -0.005796828307211399, Average Wait reward is ==> -1.4935492277145386\n",
      "Average Choice reward is ==> -1.109256625175476\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1405)\n",
      "Episode * 302 * And Number of steps is ==> 618496\n",
      "Average Cross reward is ==> -0.005830370355397463, Average Wait reward is ==> -1.4935160875320435\n",
      "Average Choice reward is ==> -1.1093486547470093\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0447)\n",
      "Episode * 303 * And Number of steps is ==> 620544\n",
      "Average Cross reward is ==> -0.005861735437065363, Average Wait reward is ==> -1.5834769010543823\n",
      "Average Choice reward is ==> -1.1024969816207886\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0458)\n",
      "Episode * 304 * And Number of steps is ==> 622592\n",
      "Average Cross reward is ==> -0.005895341280847788, Average Wait reward is ==> -1.5764105319976807\n",
      "Average Choice reward is ==> -1.0860825777053833\n",
      "Number Cross is ==> 2000 and Number Wait is ==> 2160 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.3067)\n",
      "Episode * 305 * And Number of steps is ==> 624640\n",
      "Average Cross reward is ==> -0.005931846797466278, Average Wait reward is ==> -1.5615781545639038\n",
      "Average Choice reward is ==> -1.0896334648132324\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0222)\n",
      "Episode * 306 * And Number of steps is ==> 626688\n",
      "Average Cross reward is ==> -0.006008615251630545, Average Wait reward is ==> -1.6663068532943726\n",
      "Average Choice reward is ==> -1.098497748374939\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.7634)\n",
      "Episode * 307 * And Number of steps is ==> 628736\n",
      "Average Cross reward is ==> -0.005932672880589962, Average Wait reward is ==> -1.6302201747894287\n",
      "Average Choice reward is ==> -1.0839780569076538\n",
      "Number Cross is ==> 1440 and Number Wait is ==> 2720 \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8611)\n",
      "Episode * 308 * And Number of steps is ==> 630784\n",
      "Average Cross reward is ==> -0.0058922902680933475, Average Wait reward is ==> -1.6680015325546265\n",
      "Average Choice reward is ==> -1.0589367151260376\n",
      "Number Cross is ==> 1680 and Number Wait is ==> 2480 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1873)\n",
      "Episode * 309 * And Number of steps is ==> 632832\n",
      "Average Cross reward is ==> -0.005847160704433918, Average Wait reward is ==> -1.6044423580169678\n",
      "Average Choice reward is ==> -1.0597432851791382\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1161)\n",
      "Episode * 310 * And Number of steps is ==> 634880\n",
      "Average Cross reward is ==> -0.005863221827894449, Average Wait reward is ==> -1.5951259136199951\n",
      "Average Choice reward is ==> -1.0722973346710205\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9843)\n",
      "Episode * 311 * And Number of steps is ==> 636928\n",
      "Average Cross reward is ==> -0.00600656820461154, Average Wait reward is ==> -1.5901057720184326\n",
      "Average Choice reward is ==> -1.0472056865692139\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.0114)\n",
      "Episode * 312 * And Number of steps is ==> 638976\n",
      "Average Cross reward is ==> -0.006035728845745325, Average Wait reward is ==> -1.7017320394515991\n",
      "Average Choice reward is ==> -1.0342974662780762\n",
      "Number Cross is ==> 1840 and Number Wait is ==> 2320 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.9907)\n",
      "Episode * 313 * And Number of steps is ==> 641024\n",
      "Average Cross reward is ==> -0.006022449117153883, Average Wait reward is ==> -1.6145156621932983\n",
      "Average Choice reward is ==> -1.0288927555084229\n",
      "Number Cross is ==> 1920 and Number Wait is ==> 2240 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2087)\n",
      "Episode * 314 * And Number of steps is ==> 643072\n",
      "Average Cross reward is ==> -0.00597876263782382, Average Wait reward is ==> -1.6676044464111328\n",
      "Average Choice reward is ==> -1.045181393623352\n",
      "Number Cross is ==> 2240 and Number Wait is ==> 1920 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1571)\n",
      "Episode * 315 * And Number of steps is ==> 645120\n",
      "Average Cross reward is ==> -0.005950035061687231, Average Wait reward is ==> -1.8024415969848633\n",
      "Average Choice reward is ==> -1.0302221775054932\n",
      "Number Cross is ==> 2080 and Number Wait is ==> 2080 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.1727)\n",
      "Episode * 316 * And Number of steps is ==> 647168\n",
      "Average Cross reward is ==> -0.005829325877130032, Average Wait reward is ==> -1.8628864288330078\n",
      "Average Choice reward is ==> -1.045271635055542\n",
      "Number Cross is ==> 2160 and Number Wait is ==> 2000 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2456)\n",
      "Episode * 317 * And Number of steps is ==> 649216\n",
      "Average Cross reward is ==> -0.00580455269664526, Average Wait reward is ==> -1.8310842514038086\n",
      "Average Choice reward is ==> -1.0934994220733643\n",
      "Number Cross is ==> 2480 and Number Wait is ==> 1680 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2250)\n",
      "Episode * 318 * And Number of steps is ==> 651264\n",
      "Average Cross reward is ==> -0.005804038606584072, Average Wait reward is ==> -1.8317314386367798\n",
      "Average Choice reward is ==> -1.1298969984054565\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Mauvais signal vert \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-1.2765)\n",
      "Episode * 319 * And Number of steps is ==> 653312\n",
      "Average Cross reward is ==> -0.0057823993265628815, Average Wait reward is ==> -1.9900503158569336\n",
      "Average Choice reward is ==> -1.1388123035430908\n",
      "Number Cross is ==> 2320 and Number Wait is ==> 1840 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State torch.Size([52, 17])\n",
      "State distrib torch.Size([52, 17])\n",
      "torch.Size([26])\n",
      "torch.Size([26])\n",
      "Cross not empty\n",
      "Wait not empty\n",
      "Mean of choices tensor(-0.8257)\n",
      "Episode * 320 * And Number of steps is ==> 655360\n",
      "Average Cross reward is ==> -0.0057220784947276115, Average Wait reward is ==> -1.9760068655014038\n",
      "Average Choice reward is ==> -1.1097767353057861\n",
      "Number Cross is ==> 1600 and Number Wait is ==> 2560 \n",
      "Small mistake - priority ? \n",
      "Small mistake - priority ? \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[1;32m----> 5\u001b[0m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m algo\u001b[38;5;241m.\u001b[39msaving()\n\u001b[0;32m      7\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n",
      "Cell \u001b[1;32mIn[9], line 1117\u001b[0m, in \u001b[0;36mAlgo_PPO.train\u001b[1;34m(self, nb_loop)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m   1116\u001b[0m random_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m-> 1117\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterations_rand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_net_cross\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_net_wait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_net_choice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov_mat_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1119\u001b[0m rtgs_batch_cross, rtgs_batch_wait, rtgs_batch_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout\u001b[38;5;241m.\u001b[39mfutur_rewards()\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m#print(rtgs_batch_cross.shape)\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;66;03m#print(rtgs_batch_wait.shape)\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m#print(rtgs_batch_choice.shape)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 478\u001b[0m, in \u001b[0;36mEnv_rollout.iterations_rand\u001b[1;34m(self, actor_net_cross, actor_net_wait, actor_net_choice, actor_distrib, cov_mat, cov_mat_d, batch_size, random_rate, select_param)\u001b[0m\n\u001b[0;32m    475\u001b[0m     new_prev_state_all_d_light\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mappend(new_prev_state_all_d_light,\n\u001b[0;32m    476\u001b[0m                                          new_prev_state_all_d[i\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnb_ped\u001b[38;5;241m+\u001b[39mclosest_ped])\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(select_param):\n\u001b[1;32m--> 478\u001b[0m         prev_state_distrib \u001b[38;5;241m=\u001b[39m \u001b[43mmodify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters_state\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnb_ped\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnb_car\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnb_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclosest_ped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_obs_distrib\u001b[38;5;241m.\u001b[39mextend(prev_state_distrib\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    480\u001b[0m action_d\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39maction_all_d\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 916\u001b[0m, in \u001b[0;36mmodify\u001b[1;34m(state_distrib, nb_ped, nb_car, nb_lane, id_car, id_ped)\u001b[0m\n\u001b[0;32m    913\u001b[0m             cars[(i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m(id_car\u001b[38;5;241m<\u001b[39mi))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m=\u001b[39m(ped_pos[id_ped][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39mcar_pos[i])\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m    914\u001b[0m             \u001b[38;5;66;03m#cars[(i+1*(id_car<i))*6+3]=delta_l(10.0 ,car_pos[i],ped_pos[i][0]) not dl but light\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;66;03m#print(\"Second \",cars)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m crossing, dist_start\u001b[38;5;241m=\u001b[39m\u001b[43mis_in_cross\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_car\u001b[49m\u001b[43m,\u001b[49m\u001b[43mped_pos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_ped\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mped_direction\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_ped\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43menv_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnb_lane\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m end_cross, dist_end\u001b[38;5;241m=\u001b[39mleave_cross(id_car,ped_pos[id_ped][\u001b[38;5;241m1\u001b[39m],ped_direction[id_ped],env_size,nb_lane) \n\u001b[0;32m    918\u001b[0m peds\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 752\u001b[0m, in \u001b[0;36mis_in_cross\u001b[1;34m(car_line, ped_pos, ped_dir, cross_lines, lines)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_in_cross\u001b[39m(car_line, ped_pos, ped_dir, cross_lines, lines):\n\u001b[0;32m    751\u001b[0m     cross\u001b[38;5;241m=\u001b[39m (cross_lines\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39mlines\n\u001b[1;32m--> 752\u001b[0m     line_start, line_end \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mcross_lines\u001b[49m)\u001b[38;5;241m+\u001b[39mcross\u001b[38;5;241m*\u001b[39m(car_line), (\u001b[38;5;241m-\u001b[39mcross_lines)\u001b[38;5;241m+\u001b[39mcross\u001b[38;5;241m*\u001b[39m(car_line\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    753\u001b[0m     dist_to_start\u001b[38;5;241m=\u001b[39m(ped_pos\u001b[38;5;241m-\u001b[39mline_start)\u001b[38;5;241m*\u001b[39m(ped_dir\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m (line_end\u001b[38;5;241m-\u001b[39mped_pos)\u001b[38;5;241m*\u001b[39m(ped_dir\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (ped_pos\u001b[38;5;241m>\u001b[39mline_start \u001b[38;5;129;01mand\u001b[39;00m ped_pos\u001b[38;5;241m<\u001b[39mline_end),dist_to_start\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PPO\\lib\\site-packages\\torch\\fx\\traceback.py:41\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PPO\\lib\\traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 211\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PPO\\lib\\traceback.py:362\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    359\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    360\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 362\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PPO\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "import time\n",
    "start = time.process_time()\n",
    "algo.train(500)\n",
    "algo.saving()\n",
    "end = time.process_time()\n",
    "print(\"Running time: \"+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1ea3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[[1,2,3]]\n",
    "b=[[4,5,6]]\n",
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcfeb6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffab4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#algo.loading(111,1000)\n",
    "\n",
    "algo.loading(122,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27274e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51fa94b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "`np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "\u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'numpy.ndarray'>\u001b[0m\n",
      "divide by zero encountered in scalar divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small mistake - priority ? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n"
     ]
    }
   ],
   "source": [
    "#Stock an evaluation sample\n",
    "car_feat_size=6\n",
    "env_feat_size=3\n",
    "ped_feat_size=8#.evaluate(10)\n",
    "#states, actions, rewards_c, rewards_d, time_stop = algo.evaluate(10)#,random_distrib=False)#evaluate_dataset(100)\n",
    "states, actions, rewards_c, rewards_d, time_stop = algo.evaluate(20,random_distrib=False)\n",
    "#ep_action=states[:,0]\n",
    "#ep_speed_car=states[:,1]\n",
    "#ep_pos_car=states[:,2]\n",
    "#ep_speed_ped=states[:,3]\n",
    "#ep_pos_ped=states[:,4]\n",
    "#ep_cross=states[:,9]\n",
    "ep_reward_d=rewards_d\n",
    "ep_reward_c=rewards_c\n",
    "#ep_light=actions[:,1]\n",
    "\n",
    "lim_car=env.observation_space[\"car\"].shape[0]#env.nb_car*car_feat_size\n",
    "lim_env=env.observation_space[\"env\"].shape[0]#env.nb_ped*ped_feat_size\n",
    "lim_ped=env.observation_space[\"ped\"].shape[0]\n",
    "ep_car = states[:,:lim_car]\n",
    "ep_car = ep_car.reshape(-1,env.nb_car,int(lim_car/env.nb_car))\n",
    "ep_env = states[:,lim_car:lim_car+lim_env]\n",
    "ep_env = ep_env.reshape(-1,lim_env)\n",
    "ep_ped = states[:,lim_car+lim_env:lim_car+lim_env+lim_ped]\n",
    "ep_ped = ep_ped.reshape((-1,env.nb_ped,int(lim_ped/env.nb_ped)))\n",
    "ep_cross=ep_env[:,0]\n",
    "t=0\n",
    "u=0\n",
    "#t_init=t\n",
    "#print(ep_reward_c.shape)\n",
    "#print(ep_reward_d.shape)\n",
    "#print(actions)\n",
    "#ep_reward_d.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f55c1919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(time_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cab3451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.65, 0.05, 0.1 , 0.1 , 0.  , 0.05, 0.  , 0.  , 0.  , 0.05]),\n",
       " array([0.        , 0.24000001, 0.48000002, 0.72000003, 0.96000004,\n",
       "        1.20000005, 1.44000006, 1.68000007, 1.92000008, 2.16000009,\n",
       "        2.4000001 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import PercentFormatter\n",
    "plt.title(\"Histogram of pedestrian waiting time on sidewalk\")\n",
    "\n",
    "plt.xlabel('Waiting time')\n",
    "plt.ylabel('Percentage')\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "plt.hist(time_stop, bins=10, weights=np.ones(len(time_stop)) / len(time_stop))\n",
    "#plt.savefig(\"HDRL_hist.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3145612",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisplay_Data/analyse_yield_122_car_0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, ep_car[:,\u001b[38;5;241m0\u001b[39m], delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisplay_Data/analyse_yield_122_ped_0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, ep_ped[:,\u001b[38;5;241m0\u001b[39m], delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisplay_Data/analyse_yield_122_car_1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mep_car\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisplay_Data/analyse_yield_122_env.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, ep_env, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"Display_Data/analyse_yield_122_car_0.csv\", ep_car[:,0], delimiter=\",\")\n",
    "np.savetxt(\"Display_Data/analyse_yield_122_ped_0.csv\", ep_ped[:,0], delimiter=\",\")\n",
    "np.savetxt(\"Display_Data/analyse_yield_122_car_1.csv\", ep_car[:,1], delimiter=\",\")\n",
    "np.savetxt(\"Display_Data/analyse_yield_122_env.csv\", ep_env, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "503623f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light :  tensor(-1.)\n",
      "Reward discrete  tensor([-1.0224])\n",
      "tensor(-19.4953)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing Vehicle Acceleration Diagram, Vehicle Speed Diagram, Vehicle and Pedestrian Position Diagram\n",
    "#All three over time in an episode\n",
    "#t=0\n",
    "if(t+1>=len(ep_cross)):\n",
    "    t=0\n",
    "    u=0\n",
    "t_init=t\n",
    "x_car=[t_init]*env.nb_car\n",
    "x_ped1=[t_init]*env.nb_ped\n",
    "x_ped2=[t_init]*env.nb_ped\n",
    "while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "    for i in range(env.nb_ped):\n",
    "        direction=ep_ped[t_init,i,1]/abs(ep_ped[t_init,i,1])\n",
    "        if(ep_ped[t,i,3]*direction<=-ep_cross[t_init] and ep_ped[t+1,i,3]*direction>-ep_cross[t_init]):\n",
    "            x_ped1[i]=t\n",
    "        if(ep_ped[t,i,3]*direction<=ep_cross[t_init] and ep_ped[t+1,i,3]*direction>ep_cross[t_init]):\n",
    "            x_ped2[i]=t\n",
    "    \n",
    "    for i in range(env.nb_car):\n",
    "        if(ep_car[t,i,3]<ep_ped[t,0,2] and ep_car[t+1,i,3]>ep_ped[t+1,0,2]): #car finish crossing\n",
    "            x_car[i]=t\n",
    "    t+=1\n",
    "    \n",
    "for i in range(env.nb_car):\n",
    "    if(x_car[i]==t_init):\n",
    "        x_car[i]=t\n",
    "cross_lines=ep_env[t_init,0]\n",
    "cross=int((ep_env[t_init,0]*2)/ep_env[t_init,2])\n",
    "\n",
    "ep_time=[i*0.3 for i in range(t-t_init+1)]\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3,figsize=(20, 5))\n",
    "ax1.set_title('Car Acceleration')\n",
    "ax1.set_xlabel(\"Time (s)\")\n",
    "ax1.set_ylabel(\"Acceleration (m/s2)\")\n",
    "ax1.set_ylim(-4.1,2.1)\n",
    "ax1.set_xlim(0,24)\n",
    "for id_car in range(env.nb_car):\n",
    "    ax1.plot(ep_time, ep_car[t_init:t+1,id_car,0],label='car'+str(id_car)) #-ep_cross[t_init]\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "\n",
    "ax3.set_title('Car and Pedestrian Position')\n",
    "ax3.set_xlabel(\"Time (s)\")\n",
    "ax3.set_ylabel(\"Position (m)\")\n",
    "for id_car in range(env.nb_car):\n",
    "    ax3.axvline(x=(x_car[id_car]-t_init)*0.3, color='g', linestyle='-.',label='car arrival')\n",
    "    #print(ep_car[(x_car[id_car]-1):x_car[id_car]+1,0,3])\n",
    "    #print(ep_ped[(x_car[id_car]-1):x_car[id_car]+1,0,3])\n",
    "    #print(ep_env[(x_car[id_car])])\n",
    "    ax3.plot(ep_time, ep_car[t_init:t+1,id_car,3],label='car '+str(id_car)+' (axis x)') #-ep_cross[t_init] -ep_ped[t_init:t+1,0,2]\n",
    "    print(\"light : \",ep_car[t_init+1,id_car,4])\n",
    "    #print(\"line : \",ep_car[t_init+1,id_car,5])\n",
    "for id_ped in range(env.nb_ped):\n",
    "    ax3.plot(ep_time, ep_ped[t_init:t+1,id_ped,3],label='pedestrian '+str(id_ped)+' (axis y)')\n",
    "    direction=ep_ped[t_init,id_ped,1]/abs(ep_ped[t_init,id_ped,1])\n",
    "    if direction:\n",
    "        ax3.axvline(x=(x_ped1[id_ped]-t_init)*0.3,ymin=float(-cross_lines),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "        ax3.axvline(x=(x_ped2[id_ped]-t_init)*0.3,ymin=float(-cross_lines),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "    else:\n",
    "        ax3.axvline(x=(x_ped1[id_ped]-t_init)*0.3,ymin=float(cross_lines-cross),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "        ax3.axvline(x=(x_ped2[id_ped]-t_init)*0.3,ymin=float(cross_lines-cross),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "    ax3.fill_between([(x_ped1[id_ped]-t_init)*0.3,(x_ped2[id_ped]-t_init)*0.3],-20,20, color='b', alpha=0.1,label='pedestrian in crosswalk')\n",
    "    #ax2.fill_between([(x_ped1-t_init)*0.3,(x_ped2-t_init)*0.3], min(ep_pos_car[t_init],ep_pos_ped[t_init]), min(max(ep_pos_car[min_t+t_init],ep_pos_ped[min_t+t_init]),30), color='r', alpha=0.1,label='pedestrian in crosswalk')\n",
    "ax3.set_ylim(-20,20)\n",
    "ax3.set_xlim(0,15)\n",
    "cross_size=2.0*ep_env[t_init,0]/ep_env[t_init,2]\n",
    "for i in range(int(ep_env[t_init,2])+1):\n",
    "    ax3.axhline(y=-ep_cross[t_init] + i*cross_size , color='r', linestyle='-.')\n",
    "#ax2.axhline(y=0.0, color='b', linestyle='-.')\n",
    "#ax2.axhline(y=10.0, color='b', linestyle='-.')\n",
    "ax3.legend()\n",
    "ax3.grid()\n",
    "\n",
    "ax2.set_title('Car Speed')\n",
    "ax2.set_xlabel(\"Time (s)\")\n",
    "ax2.set_ylabel(\"Speed (m/s)\")\n",
    "for id_car in range(env.nb_car):\n",
    "    ax2.plot(ep_time, ep_car[t_init:t+1,id_car,1],label='car '+str(id_car)) #-ep_cross[t_init]\n",
    "#ax3.plot(ep_time, ep_speed_car[t_init:t+1],color='r')\n",
    "ax2.axhline(y=ep_car[t_init,0,1], color='r', linestyle='-.')\n",
    "ax2.axhline(y=0, color='r', linestyle='-.')\n",
    "ax2.set_xlim(0,27)\n",
    "ax2.legend()\n",
    "ax2.grid()\n",
    "#ax4.set_title('Pedestrian Speed')\n",
    "#ax4.set_xlabel(\"Time (s)\")\n",
    "#ax4.set_ylabel(\"Speed (m/s)\")\n",
    "#for id_ped in range(env.nb_ped):\n",
    "#    ax4.plot(ep_time, abs(ep_ped[t_init:t+1,id_ped,1]),label='pedestrian '+str(id_ped))\n",
    "    #ep_ped[t_init:t+1,id_ped,7]*\n",
    "##ax4.set_xlim(0,15)\n",
    "#ax4.legend()\n",
    "#fig.savefig(\"Display_Data/Sauvegarde_\"+str(is_loading_c)+\"_\"+str(int(ep_car[t_init+1,0,4]))+\"_\"+str(int(ep_car[t_init+1,1,4]))+\".pdf\")    \n",
    "#print(ep_reward_d)\n",
    "print(\"Reward discrete \",ep_reward_d[u])\n",
    "t+=1\n",
    "u+=1\n",
    "print(ep_car[t_init,0,3])\n",
    "#print(ep_car[t_init,1,3])\n",
    "#print(ep_reward_d[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cdfbcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La vitesse moyenne (voiture) est de 9.08 m/s et son écart-type est de 1.64 m/s\n",
      "\n",
      "L'accélération moyenne (voiture) est de 0.29 m/s2 et son écart-type est de 0.65 m/s2\n",
      "\n",
      "La vitesse moyenne (piéton) est de 1.23 m/s et son écart-type est de 0.39 m/s\n",
      "\n",
      "The average CO2 emission is 36126.03mg and its standard deviation is 12202.71 mg\n",
      "La vitesse moyenne (voiture 1) est de 8.53 m/s et son écart-type est de 1.88 m/s\n",
      "\n",
      "Les temps moyens:\n",
      "voiture 1: 7.67 s\n",
      "voiture 1 std:  tensor(1.6678)\n",
      "voiture all: 5.63 s\n",
      "voiture all std:  tensor(3.1117)\n",
      "piéton: 6.38 s\n",
      "piéton std:  tensor(1.4756)\n",
      "Yield decision:  0.65\n",
      "Go first decision:  0.35\n",
      "Le temps moyen d'attente du pieton:  0.27899999999999997\n",
      "Le temps std d'attente du pieton:  0.4915882423329508\n",
      "Scenario 11:  0.39\n",
      "Scenario -1-1:  0.09\n",
      "Scenario -1 1:  0.29\n",
      "Scenario 1 -1:  0.23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "LDV = pd.read_csv('LDV.csv', sep=';',names=[\"sp\",\"acc\",\"step\",\"em_name\",\"em_val\"])\n",
    "LDV.pop('step')\n",
    "m = LDV == 0.0\n",
    "LDV['acc'] = LDV['acc'].replace(1.27676e-15,0.0)\n",
    "LDV['acc'] = LDV['acc'].astype(float)\n",
    "LDV_array = np.array(LDV.values)\n",
    "\n",
    "def info_co2(ep_car,ep_cross,LDV):\n",
    "    \"\"\"\n",
    "        Evaluate the CO2 emission per episode \n",
    "        :param states: state list\n",
    "        :param LDV: CO2 emission chart\n",
    "    \"\"\"\n",
    "    t=0\n",
    "    total_emission=[]\n",
    "    while t+1<len(ep_cross):\n",
    "        t_init=t\n",
    "        emission_val=[]\n",
    "        for car_i in range(env.nb_car):\n",
    "            while  t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                acc=math.trunc(((ep_car[t,car_i,0].item()//0.2)*0.2)*10.)/10.\n",
    "                speed=math.trunc(((ep_car[t,car_i,1].item()//0.5)*0.5)*10.)/10.\n",
    "                cond=(LDV.sp==speed)&(LDV.acc==acc)&(LDV.em_name==\"CO2\")\n",
    "                res=LDV[cond]['em_val'].item() *0.3\n",
    "                emission_val.append(res)\n",
    "                t+=1\n",
    "            total_emission.append(np.sum(np.array(emission_val),axis=0))\n",
    "        t+=1\n",
    "    torch_total_emission=np.array(total_emission)\n",
    "    total_emission_mean=np.mean(torch_total_emission)\n",
    "    total_emission_std=np.std(torch_total_emission)\n",
    "    print(\"\\nThe average CO2 emission is {:.2f}mg and its standard deviation is {:.2f} mg\".format(total_emission_mean.item(),total_emission_std.item()))\n",
    "    \n",
    "def get_average(ep_car,ep_ped,ep_cross):\n",
    "    ep_time=states[:,9]\n",
    "    #Info vitesse voiture\n",
    "    mean_speed=torch.mean(ep_car[:,0,1])\n",
    "    sqrt_speed=torch.std(ep_car[:,0,1])\n",
    "    print(\"La vitesse moyenne (voiture) est de {:.2f} m/s et son écart-type est de {:.2f} m/s\".format(mean_speed.item(),sqrt_speed.item()))\n",
    "    #Info accélération voiture RMQ: très peu représentatif...\n",
    "    mean_acc=torch.mean(torch.abs(ep_car[:,0,0]))\n",
    "    sqrt_acc=torch.std(ep_car[:,0,0])\n",
    "    print(\"\\nL'accélération moyenne (voiture) est de {:.2f} m/s2 et son écart-type est de {:.2f} m/s2\".format(mean_acc.item(),sqrt_acc.item()))\n",
    "    mean_speed_p=torch.mean(torch.abs(ep_ped[:,0,1]))\n",
    "    sqrt_speed_p=torch.std(torch.abs(ep_ped[:,0,1]))\n",
    "    print(\"\\nLa vitesse moyenne (piéton) est de {:.2f} m/s et son écart-type est de {:.2f} m/s\".format(mean_speed_p.item(),sqrt_speed_p.item()))    \n",
    "    #CO2 info\n",
    "    info_co2(ep_car,ep_cross,LDV) #CO2 info\n",
    "    #temps passage voiture\n",
    "    temp_cars=[]\n",
    "    all_temp_cars=[]\n",
    "    temp_peds=[]\n",
    "    decisions=[]\n",
    "    ped_direction=[]\n",
    "    waiting_times=[]\n",
    "    speed_cars=[]\n",
    "    all_decisions=[]\n",
    "    t=0\n",
    "    while t+1<len(ep_cross):\n",
    "        # respectivement: temps passage voiture / piéton\n",
    "        t_init=t\n",
    "        t_end=t\n",
    "        #if(1 in ep_car[t_init+1,:,4]):\n",
    "        #temp_ped=np.array([0.]*env.nb_ped)\n",
    "        for ped_i in range(env.nb_ped):\n",
    "            waiting_time=0\n",
    "            t=t_init\n",
    "            while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                if(ep_ped[t,ped_i,3])==ep_cross[t]:\n",
    "                    waiting_time+=0.3\n",
    "                if(ep_ped[t,ped_i,3]*ep_ped[t,ped_i,8]<ep_cross[t] and ep_ped[t+1,ped_i,3]*ep_ped[t+1,ped_i,8]>=ep_cross[t+1]):\n",
    "                    temp_peds.append((t-t_init)*0.3)\n",
    "                t+=1\n",
    "            waiting_times.append(waiting_time)\n",
    "            ped_direction.append(int(-ep_ped[t_init,ped_i,8]/2. +0.5))\n",
    "            t_end=max(t_end,t)\n",
    "       # temp_peds.append(temp_ped)\n",
    "        #temp_car=np.array([0.]*env.nb_car)\n",
    "        for car_i in range(env.nb_car):\n",
    "            t=t_init\n",
    "            while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                decision=ep_car[t,car_i,4]\n",
    "                if(ep_car[t_init+1,car_i,4]==1):\n",
    "                    speed_cars.append(ep_car[t,car_i,1])\n",
    "                if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0):\n",
    "                    all_temp_cars.append((t-t_init)*0.3)\n",
    "                if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0)and (ep_car[t_init+1,car_i,4]==1):\n",
    "                    temp_cars.append((t-t_init)*0.3)\n",
    "                    #speed_cars.append(ep_car[t,car_i,1])\n",
    "                t+=1\n",
    "            decisions.append(decision)\n",
    "            t_end=max(t_end,t)\n",
    "        #temp_cars.append(temp_car)\n",
    "            #temps.append([(t-t_init)*0.3,temps_i[0],temps_i[1]])\n",
    "        t=t_end+1\n",
    "    #total_temps=torch.tensor([temps]).reshape((-1,3))\n",
    "    mean_speed_cars=torch.mean(torch.tensor(speed_cars).flatten())\n",
    "    sqrt_speed_cars=torch.std(torch.tensor(speed_cars).flatten())\n",
    "    mean_temp_cars=torch.mean(torch.tensor(temp_cars).flatten())\n",
    "    mean_all_temp_cars=torch.mean(torch.tensor(all_temp_cars).flatten())\n",
    "    mean_temp_peds=torch.mean(torch.tensor(temp_peds).flatten())\n",
    "    decisions_tensor=torch.tensor(decisions).reshape(-1,env.nb_car)\n",
    "    scenario=torch.sum(decisions_tensor, axis=1)\n",
    "    print(\"La vitesse moyenne (voiture 1) est de {:.2f} m/s et son écart-type est de {:.2f} m/s\".format(mean_speed_cars.item(),sqrt_speed_cars.item()))\n",
    "\n",
    "    print(\"\\nLes temps moyens:\")\n",
    "    print(\"voiture 1: {:.2f} s\".format(mean_temp_cars))\n",
    "    print(\"voiture 1 std: \", torch.std(torch.tensor(temp_cars)))\n",
    "    print(\"voiture all: {:.2f} s\".format(mean_all_temp_cars))\n",
    "    print(\"voiture all std: \", torch.std(torch.tensor(all_temp_cars)))\n",
    "    print(\"piéton: {:.2f} s\".format(mean_temp_peds))\n",
    "    print(\"piéton std: \", torch.std(torch.tensor(temp_peds)))\n",
    "    print(\"Yield decision: \", sum([1 for dec in np.array(decisions) if dec ==1])/len(decisions))\n",
    "    print(\"Go first decision: \", sum([1 for dec in np.array(decisions) if dec ==-1])/len(decisions))\n",
    "    print(\"Le temps moyen d'attente du pieton: \", np.mean(waiting_times))\n",
    "    print(\"Le temps std d'attente du pieton: \", np.std(waiting_times))\n",
    "    if(env.nb_car==2):\n",
    "        size_scenario=len(decisions_tensor)\n",
    "        print(\"Scenario 11: \", sum([1 for i in range(size_scenario) if sum(decisions_tensor[i]) ==2])/len(scenario))\n",
    "        print(\"Scenario -1-1: \", sum([1 for i in range(size_scenario) if sum(decisions_tensor[i]) ==-2])/len(scenario))\n",
    "        print(\"Scenario -1 1: \", sum([1 for i in range(size_scenario) if decisions_tensor[i][ped_direction[i]] ==-1 and decisions_tensor[i][1-ped_direction[i]]==1])/len(scenario))\n",
    "        print(\"Scenario 1 -1: \", sum([1 for i in range(size_scenario) if decisions_tensor[i][ped_direction[i]] ==1 and decisions_tensor[i][1-ped_direction[i]]==-1])/len(scenario))\n",
    "    #print(torch.std(total_temps,dim=0))\n",
    "get_average(ep_car,ep_ped,ep_cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ddf45e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La vitesse moyenne (voiture) est de 8.81 m/s et son écart-type est de 1.95 m/s\n",
      "\n",
      "L'accélération moyenne (voiture) est de 0.44 m/s2 et son écart-type est de 0.91 m/s2\n",
      "\n",
      "La vitesse moyenne (piéton) est de 1.23 m/s et son écart-type est de 0.44 m/s\n",
      "\n",
      "The average CO2 emission is 37196.98mg and its standard deviation is 7290.43 mg\n",
      "La vitesse moyenne (voiture 1) est de 8.18 m/s et son écart-type est de 2.18 m/s\n",
      "\n",
      "Les temps moyens:\n",
      "voiture 1: 7.46 s\n",
      "voiture 1 std:  tensor(1.6797)\n",
      "voiture all: 5.65 s\n",
      "voiture all std:  3.0874189073302962\n",
      "piéton: 6.53 s\n",
      "piéton std:  tensor(1.8504)\n",
      "Yield decision:  0.69\n",
      "Go first decision:  0.31\n",
      "Le temps moyen d'attente du pieton:  0.33659999999999995\n",
      "Le temps std d'attente du pieton:  0.607832575632468\n",
      "Scenario 1 1:  0.497\n",
      "Scenario -1 -1:  0.117\n",
      "Scenario -1 1:  0.213\n",
      "Scenario 1 -1:  0.173\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "LDV = pd.read_csv('LDV.csv', sep=';',names=[\"sp\",\"acc\",\"step\",\"em_name\",\"em_val\"])\n",
    "LDV.pop('step')\n",
    "m = LDV == 0.0\n",
    "LDV['acc'] = LDV['acc'].replace(1.27676e-15,0.0)\n",
    "LDV['acc'] = LDV['acc'].astype(float)\n",
    "LDV_array = np.array(LDV.values)\n",
    "\n",
    "def info_co2(ep_car,ep_cross,LDV):\n",
    "    \"\"\"\n",
    "        Evaluate the CO2 emission per episode \n",
    "        :param states: state list\n",
    "        :param LDV: CO2 emission chart\n",
    "    \"\"\"\n",
    "    t=0\n",
    "    total_emission=[]\n",
    "    while t+1<len(ep_cross):\n",
    "        t_init=t\n",
    "        emission_val=[]\n",
    "        for car_i in range(env.nb_car):\n",
    "            while  t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                acc=math.trunc(((ep_car[t,car_i,0].item()//0.2)*0.2)*10.)/10.\n",
    "                speed=math.trunc(((ep_car[t,car_i,1].item()//0.5)*0.5)*10.)/10.\n",
    "                cond=(LDV.sp==speed)&(LDV.acc==acc)&(LDV.em_name==\"CO2\")\n",
    "                res=LDV[cond]['em_val'].item() *0.3\n",
    "                emission_val.append(res)\n",
    "                t+=1\n",
    "            total_emission.append(np.sum(np.array(emission_val),axis=0))\n",
    "        t+=1\n",
    "    torch_total_emission=np.array(total_emission)\n",
    "    total_emission_mean=np.mean(torch_total_emission)\n",
    "    total_emission_std=np.std(torch_total_emission)\n",
    "    print(\"\\nThe average CO2 emission is {:.2f}mg and its standard deviation is {:.2f} mg\".format(total_emission_mean.item(),total_emission_std.item()))\n",
    "    \n",
    "def get_average(ep_car,ep_ped,ep_cross):\n",
    "    ep_time=states[:,9]\n",
    "    #Info vitesse voiture\n",
    "    mean_speed=torch.mean(ep_car[:,0,1])\n",
    "    sqrt_speed=torch.std(ep_car[:,0,1])\n",
    "    print(\"La vitesse moyenne (voiture) est de {:.2f} m/s et son écart-type est de {:.2f} m/s\".format(mean_speed.item(),sqrt_speed.item()))\n",
    "    #Info accélération voiture RMQ: très peu représentatif...\n",
    "    mean_acc=torch.mean(torch.abs(ep_car[:,0,0]))\n",
    "    sqrt_acc=torch.std(ep_car[:,0,0])\n",
    "    print(\"\\nL'accélération moyenne (voiture) est de {:.2f} m/s2 et son écart-type est de {:.2f} m/s2\".format(mean_acc.item(),sqrt_acc.item()))\n",
    "    mean_speed_p=torch.mean(torch.abs(ep_ped[:,0,1]))\n",
    "    sqrt_speed_p=torch.std(torch.abs(ep_ped[:,0,1]))\n",
    "    print(\"\\nLa vitesse moyenne (piéton) est de {:.2f} m/s et son écart-type est de {:.2f} m/s\".format(mean_speed_p.item(),sqrt_speed_p.item()))    \n",
    "    #CO2 info\n",
    "    info_co2(ep_car,ep_cross,LDV) #CO2 info\n",
    "    #temps passage voiture\n",
    "    temp_cars=[]\n",
    "    all_temp_cars=[]\n",
    "    temp_peds=[]\n",
    "    decisions=[]\n",
    "    speed_cars=[]\n",
    "    all_decisions=[]\n",
    "    waiting_times=[]\n",
    "    t=0\n",
    "    while t+1<len(ep_cross):\n",
    "        # respectivement: temps passage voiture / piéton\n",
    "        t_init=t\n",
    "        t_end=t\n",
    "        #if(1 in ep_car[t_init+1,:,4]):\n",
    "        \n",
    "        #temp_ped=np.array([0.]*env.nb_ped)\n",
    "        for ped_i in range(env.nb_ped):\n",
    "            waiting_time=0\n",
    "            t=t_init\n",
    "            while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                if(ep_ped[t,ped_i,3])==ep_cross[t]:\n",
    "                    waiting_time+=0.3\n",
    "                if(ep_ped[t,ped_i,3]*ep_ped[t,ped_i,8]<ep_cross[t] and ep_ped[t+1,ped_i,3]*ep_ped[t+1,ped_i,8]>=ep_cross[t+1]):\n",
    "                    temp_peds.append((t-t_init)*0.3)\n",
    "                t+=1\n",
    "            waiting_times.append(waiting_time)\n",
    "            t_end=max(t_end,t)\n",
    "       # temp_peds.append(temp_ped)\n",
    "        #temp_car=np.array([0.]*env.nb_car)\n",
    "        for car_i in range(env.nb_car):\n",
    "            t=t_init\n",
    "            #if(1 in ep_car[t_init+1,:,4]):\n",
    "            while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                decision=ep_car[t,car_i,4]\n",
    "                if(ep_car[t_init+1,car_i,4]==1):\n",
    "                    speed_cars.append(ep_car[t,car_i,1])\n",
    "                if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0):\n",
    "                    all_temp_cars.append((t-t_init)*0.3)\n",
    "                if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0) and (ep_car[t_init+1,car_i,4]==1):\n",
    "                    temp_cars.append((t-t_init)*0.3)\n",
    "                t+=1\n",
    "            if(ep_car[t_init+1,car_i,4]==1):\n",
    "                decisions.append(decision)\n",
    "            all_decisions.append(decision)\n",
    "            t_end=max(t_end,t)\n",
    "        #temp_cars.append(temp_car)\n",
    "            #temps.append([(t-t_init)*0.3,temps_i[0],temps_i[1]])\n",
    "        t=t_end+1\n",
    "    #total_temps=torch.tensor([temps]).reshape((-1,3))\n",
    "    mean_speed_cars=torch.mean(torch.tensor(speed_cars).flatten())\n",
    "    sqrt_speed_cars=torch.std(torch.tensor(speed_cars).flatten())\n",
    "    mean_temp_cars=torch.mean(torch.tensor(temp_cars).flatten())\n",
    "    mean_all_temp_cars=np.mean(np.array(all_temp_cars).flatten())\n",
    "    mean_temp_peds=torch.mean(torch.tensor(temp_peds).flatten())\n",
    "    #decisions_tensor=torch.tensor(decisions).flatten()#.reshape(-1,env.nb_car)\n",
    "    all_decisions_tensor=torch.tensor(all_decisions).reshape(-1,env.nb_car)\n",
    "    #print(all_decisions_tensor)\n",
    "    #scenario=torch.sum(decisions_tensor, axis=1)\n",
    "    all_scenario=torch.sum(all_decisions_tensor, axis=1)\n",
    "    print(\"La vitesse moyenne (voiture 1) est de {:.2f} m/s et son écart-type est de {:.2f} m/s\".format(mean_speed_cars.item(),sqrt_speed_cars.item()))\n",
    "    print(\"\\nLes temps moyens:\")\n",
    "    print(\"voiture 1: {:.2f} s\".format(mean_temp_cars))\n",
    "    print(\"voiture 1 std: \", torch.std(torch.tensor(temp_cars)))\n",
    "    print(\"voiture all: {:.2f} s\".format(mean_all_temp_cars))\n",
    "    print(\"voiture all std: \", np.std(np.array(all_temp_cars)))\n",
    "    print(\"piéton: {:.2f} s\".format(mean_temp_peds))\n",
    "    print(\"piéton std: \", torch.std(torch.tensor(temp_peds)))\n",
    "    print(\"Yield decision: \", sum([1 for dec in np.array(all_decisions) if dec ==1])/len(all_decisions))\n",
    "    print(\"Go first decision: \", sum([1 for dec in np.array(all_decisions) if dec ==-1])/len(all_decisions))\n",
    "    print(\"Le temps moyen d'attente du pieton: \", np.mean(waiting_times))\n",
    "    print(\"Le temps std d'attente du pieton: \", np.std(waiting_times))\n",
    "    print(\"Scenario 1 1: \", sum([1 for sce in (all_decisions_tensor) if sum(sce) ==2])/len(all_scenario))\n",
    "    print(\"Scenario -1 -1: \", sum([1 for sce in (all_decisions_tensor) if sum(sce) ==-2])/len(all_scenario))\n",
    "    print(\"Scenario -1 1: \", sum([1 for sce in (all_decisions_tensor) if sce[0] ==-1 and sce[1]==1])/len(all_scenario))\n",
    "    print(\"Scenario 1 -1: \", sum([1 for sce in (all_decisions_tensor) if sce[0] ==1 and sce[1]==-1])/len(all_scenario))\n",
    "    #print(torch.std(total_temps,dim=0))\n",
    "get_average(ep_car,ep_ped,ep_cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2166e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.199999999999999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.pedestrian[0].waiting_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c91542fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "ep_time=[i*0.3 for i in range(t-t_init+1)]\n",
    "fig, ( ax4, ax5, ax6, ax7) = plt.subplots(1, 4,figsize=(20, 8))\n",
    "\n",
    "ax4.set_title('Delta')\n",
    "ax4.set_xlabel(\"Time (s)\")\n",
    "ax4.set_ylabel(\"\")\n",
    "for id_ped in range(env.nb_ped):\n",
    "    ax4.plot(ep_time, ep_ped[t_init:t+1,id_ped,4],label='pedestrian'+str(id_ped))\n",
    "ax4.legend()\n",
    "    \n",
    "    \n",
    "ax5.set_title('Pedestrian position axe X')\n",
    "ax5.set_xlabel(\"Time (s)\")\n",
    "ax5.set_ylabel(\"Speed (m/s)\")\n",
    "for id_ped in range(env.nb_ped):\n",
    "    ax5.plot(ep_time, ep_ped[t_init:t+1,id_ped,1],label='pedestrian'+str(id_ped))\n",
    "ax5.legend()\n",
    "ax5.set_xlim(0,15)\n",
    "#ax5.set_title('DL')\n",
    "#ax5.set_xlabel(\"Time (s)\")\n",
    "#ax5.set_ylabel(\"Value \")\n",
    "#ax5.plot(ep_time, states[t_init:t+1,5 ])#ep_reward[t_init:t+1])#ep_reward[t_init:t+1],color='r')\n",
    "#ax5.axhline(y=0, color='r', linestyle='-.')\n",
    "\n",
    "ax6.set_title('Reward')\n",
    "ax6.set_xlabel(\"Time (s)\")\n",
    "ax6.set_ylabel(\"Value\")\n",
    "for id_car in range(env.nb_car):\n",
    "    ax6.plot(ep_time,ep_reward_c[t_init:t+1][:,id_car],label='car'+str(id_car))#ep_reward[t_init:t+1])#ep_reward[t_init:t+1],color='r')\n",
    "ax6.legend()\n",
    "#print(ep_reward_d)\n",
    "ax7.set_title('Light')\n",
    "ax7.set_xlabel(\"Time (s)\")\n",
    "ax7.set_ylabel(\"Light\")\n",
    "for id_car in range(env.nb_car):\n",
    "    ax7.plot(ep_time,ep_car[t_init:t+1,id_car,4],label='car'+str(id_car))#,color='black')#ep_reward[t_init:t+1])#ep_reward[t_init:t+1],color='r')\n",
    "    #ax7.scatter(ep_time,ep_car[t_init:t+1,id_car,4],c=ep_car[t_init:t+1,id_car,4],cmap='RdYlGn')\n",
    "    ax7\n",
    "    ax7.legend()\n",
    "#print(ep_reward_d)\n",
    "t+=1\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "954d93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    " \n",
    "def save_object(obj):\n",
    "    try:\n",
    "        with open(\"test_data_acc6.pickle\", \"wb\") as f:\n",
    "            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as ex:\n",
    "        print(\"Error during pickling object (Possibly unsupported):\", ex)\n",
    "dataset=[]\n",
    "for i in range(1000):\n",
    "    env.reset()\n",
    "    dataset.append(copy.deepcopy(env))\n",
    "save_object(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
